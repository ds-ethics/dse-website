<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jorge Roa">
<meta name="author" content="Carlo Greß">
<meta name="author" content="Hannah Schweren">
<meta name="dcterms.date" content="2023-12-05">

<title>{{&lt; fa solid scale-balanced &gt;}} Ethics &lt;span style='font-size: 18px;'&gt;✕&lt;/span&gt; Data Science {{&lt; fa solid code-branch &gt;}} – quarto-input427f8707a31b2905</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/animate-4.1.1/animate.min.css" rel="stylesheet">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<!-- Primary Meta Tags -->
<title>Hertie Coding Club - Everybody can learn to code</title>
<meta name="title" content="Hertie Coding Club - Everybody can learn to code">
<meta name="description" content="Welcome to the Hertie Coding Club! Our goal as a club is to help everyone and between us learn coding skills and show that coding is for everyone, no matter our background.">

<!-- Open Graph / Facebook -->
<meta property="og:type" content="website">
<meta property="og:url" content="https://www.hertiecodingclub.com">
<meta property="og:title" content=" Ethics ✕ Data Science  - Bias in AI: detection and mitigation">
<meta property="og:description" content="Enable users to detect and mitigate bias, using the example of the COMPAS Recidivism Risk Score Data and Analysis Dataset. Users will be equiped with concrete strategies to first detect, and secondly mitigate bias">
<!-- Primary Meta Tags -->
<title>Hertie Coding Club - RStudio 101</title>
<meta name="title" content="Hertie Coding Club - Enable Multithread with data.table in Mac/Intel chips">
<meta name="description" content="Learn the basics of R: open a project, setting a working directory and navigate RStudio interface">

<!-- Open Graph / Facebook -->
<meta property="og:type" content="website">
<meta property="og:url" content="https://www.hertiecodingclub.com/learn/rstudio/rstudio101/">
<meta property="og:title" content="Hertie Coding Club - RStudio 101">
<meta property="og:description" content="Learn the basics of R: open a project, setting a working directory and navigate RStudio interface">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<style>:root{--animate-duration:3s;--animate-delay:2s;--animate-repeat:1}</style>
<style>:root{--animate-duration:3s;--animate-delay:2s;--animate-repeat:1}</style>
<style>:root{--animate-duration:3s;--animate-delay:2s;--animate-repeat:1}</style>
<style>:root{--animate-duration:3s;--animate-delay:2s;--animate-repeat:1}</style>
<style>:root{--animate-duration:3s;--animate-delay:2s;--animate-repeat:1}</style>
<style>:root{--animate-duration:3s;--animate-delay:2s;--animate-repeat:1}</style>
<style>:root{--animate-duration:3s;--animate-delay:2s;--animate-repeat:1}</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title"><i class="fa-solid fa-scale-balanced" aria-label="scale-balanced"></i> Ethics <span style="font-size: 18px;">✕</span> Data Science <i class="fa-solid fa-code-branch" aria-label="code-branch"></i></span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> <i class="bi bi-house-fill" role="img">
</i> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../ethics/ethics.html"> 
<span class="menu-text"><i class="fa-solid fa-scale-balanced" aria-label="scale-balanced"></i> Ethics</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../data_science/data_science.html"> 
<span class="menu-text"><i class="fa-solid fa-laptop-code" aria-label="laptop-code"></i> Data Science</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../for_instructors/instructors.html"> 
<span class="menu-text"><i class="fa-solid fa-landmark" aria-label="landmark"></i> For instructors</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../references/reference.html"> 
<span class="menu-text"><i class="fa-solid fa-newspaper" aria-label="newspaper"></i> References</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about/about_us.html"> 
<span class="menu-text"><i class="fa-solid fa-hand-point-up" aria-label="hand-point-up"></i> About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title"><span class="animate__animated animate__fadeInDown" style="display: inline-block;">Bias in AI: detection and mitigation</span></h1>
            <p class="subtitle lead"><span class="animate__animated animate__fadeInDown" style="display: inline-block;">Enable users to detect and mitigate bias, using the example of the COMPAS Recidivism Risk Score Data and Analysis Dataset. Users will be equiped with concrete strategies to first detect, and secondly mitigate bias</span></p>
                                <div class="quarto-categories">
                <div class="quarto-category">Advanced</div>
                <div class="quarto-category">Bias in AI</div>
                <div class="quarto-category">Mitigation</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-contents">
               <p>Jorge Roa </p>
               <p>Carlo Greß </p>
               <p>Hannah Schweren </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 5, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">Overview</a>
  <ul class="collapse">
  <li><a href="#background-and-prerequisites" id="toc-background-and-prerequisites" class="nav-link" data-scroll-target="#background-and-prerequisites">Background and Prerequisites</a></li>
  </ul></li>
  <li><a href="#data-description" id="toc-data-description" class="nav-link" data-scroll-target="#data-description">Data Description</a></li>
  <li><a href="#part-1-data-exploration-and-bias-detection" id="toc-part-1-data-exploration-and-bias-detection" class="nav-link" data-scroll-target="#part-1-data-exploration-and-bias-detection">Part 1: Data Exploration and Bias Detection</a>
  <ul class="collapse">
  <li><a href="#data-download" id="toc-data-download" class="nav-link" data-scroll-target="#data-download">1.1 Data Download</a></li>
  <li><a href="#exploratory-data-visualization" id="toc-exploratory-data-visualization" class="nav-link" data-scroll-target="#exploratory-data-visualization">Exploratory Data Visualization</a>
  <ul class="collapse">
  <li><a href="#distribution-of-defendants-by-demographics-race-age-sex-and-risk-scores" id="toc-distribution-of-defendants-by-demographics-race-age-sex-and-risk-scores" class="nav-link" data-scroll-target="#distribution-of-defendants-by-demographics-race-age-sex-and-risk-scores">Distribution of Defendants by Demographics (Race, Age, Sex) and Risk Scores</a></li>
  </ul></li>
  <li><a href="#distribution-of-defendants-by-demographics-and-recidivism" id="toc-distribution-of-defendants-by-demographics-and-recidivism" class="nav-link" data-scroll-target="#distribution-of-defendants-by-demographics-and-recidivism">Distribution of Defendants by Demographics and Recidivism</a></li>
  <li><a href="#introducing-the-aequitas-library" id="toc-introducing-the-aequitas-library" class="nav-link" data-scroll-target="#introducing-the-aequitas-library">Introducing the Aequitas-Library</a></li>
  <li><a href="#calculating-the-bias-using-disparity" id="toc-calculating-the-bias-using-disparity" class="nav-link" data-scroll-target="#calculating-the-bias-using-disparity">Calculating the bias using disparity</a></li>
  </ul></li>
  <li><a href="#part-2-neural-network-classifier-for-fair-data-distribution" id="toc-part-2-neural-network-classifier-for-fair-data-distribution" class="nav-link" data-scroll-target="#part-2-neural-network-classifier-for-fair-data-distribution">Part 2: Neural Network Classifier for Fair Data Distribution</a>
  <ul class="collapse">
  <li><a href="#loading-the-data" id="toc-loading-the-data" class="nav-link" data-scroll-target="#loading-the-data">Loading the data</a></li>
  </ul></li>
  <li><a href="#metric-plot" id="toc-metric-plot" class="nav-link" data-scroll-target="#metric-plot">Metric Plot</a></li>
  <li><a href="#part-3-mitigating-bias" id="toc-part-3-mitigating-bias" class="nav-link" data-scroll-target="#part-3-mitigating-bias">Part 3: Mitigating bias</a>
  <ul class="collapse">
  <li><a href="#data-download-1" id="toc-data-download-1" class="nav-link" data-scroll-target="#data-download-1">3.1 Data Download</a></li>
  <li><a href="#data-preprocessing" id="toc-data-preprocessing" class="nav-link" data-scroll-target="#data-preprocessing">3.1 Data Preprocessing</a></li>
  <li><a href="#preprocessing-mitigation-techniques" id="toc-preprocessing-mitigation-techniques" class="nav-link" data-scroll-target="#preprocessing-mitigation-techniques">3.3 Preprocessing Mitigation Techniques</a></li>
  <li><a href="#ratio-of-african-american-to-caucasians-on-the-original-data-vs.-in-the-precicted-outcomes" id="toc-ratio-of-african-american-to-caucasians-on-the-original-data-vs.-in-the-precicted-outcomes" class="nav-link" data-scroll-target="#ratio-of-african-american-to-caucasians-on-the-original-data-vs.-in-the-precicted-outcomes">Ratio of African-American to Caucasians on the original data vs.&nbsp;in the precicted outcomes</a>
  <ul class="collapse">
  <li><a href="#using-disparate-impact-repairing-preprocessing" id="toc-using-disparate-impact-repairing-preprocessing" class="nav-link" data-scroll-target="#using-disparate-impact-repairing-preprocessing">3.3.1 Using Disparate Impact Repairing (preprocessing)</a></li>
  </ul></li>
  <li><a href="#reweighting-the-data-preprocessing" id="toc-reweighting-the-data-preprocessing" class="nav-link" data-scroll-target="#reweighting-the-data-preprocessing">3.3.2 Reweighting the Data (Preprocessing)</a></li>
  <li><a href="#train-logistic-regression-with-reweighed-dataset" id="toc-train-logistic-regression-with-reweighed-dataset" class="nav-link" data-scroll-target="#train-logistic-regression-with-reweighed-dataset">Train Logistic Regression with reweighed dataset</a></li>
  <li><a href="#post-processing-mitigation-strategy" id="toc-post-processing-mitigation-strategy" class="nav-link" data-scroll-target="#post-processing-mitigation-strategy">Post-processing Mitigation Strategy</a>
  <ul class="collapse">
  <li><a href="#reject-option-classification" id="toc-reject-option-classification" class="nav-link" data-scroll-target="#reject-option-classification">Reject Option Classification</a></li>
  </ul></li>
  <li><a href="#results-and-discussion" id="toc-results-and-discussion" class="nav-link" data-scroll-target="#results-and-discussion">Results and Discussion</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations">Limitations</a></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next Steps</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p><br></p>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This notebook offers a detailed guide that includes both code and explanations aimed at enabling users to identify and counteract bias within data, specifically using the COMPAS Recidivism Risk Score Data and Analysis Dataset as a case study. It provides users with practical strategies to first detect and then mitigate bias, laying a foundational approach for handling biases effectively in algorithmic processes. The tutorial is designed as an introductory step towards fostering an understanding of the biases that can infiltrate algorithms and promoting the development of ethical AI practices. This is particularly critical in contexts where algorithmic decisions intersect with policy-making, potentially influencing societal outcomes. Through this guide, users will not only learn to recognize biases but also implement measures to address these biases, thereby enhancing the fairness and integrity of AI systems in public and private sectors.</p>
<p><br></p>
</section>
<section id="overview" class="level1">
<h1>Overview</h1>
<p>The COMPAS dataset, used by an algorithm predicting recidivism risk, has become a key example in the study of algorithmic bias and fairness. It includes demographic and criminal history data. Analyses revealed racial disparities in risk assessments, with the algorithm tending to overestimate recidivism risk for Black defendants and underestimate it for White defendants.</p>
<p>This tutorial is divided into three parts:</p>
<p>1.- <em>Introduction to Bias Detection Metrics</em>: We will introduce different metrics to detect bias, providing a smooth introduction to the topic and helping users gain a better understanding of the issue.</p>
<p>2.- <em>Replication of Biased Output with a Feed Forward Neural Network</em>: In this step, we will replicate the biased output using a Feed Forward Neural Network. This hands-on exercise will provide users with practical experience in generating predictions and raise awarness for the biased output.</p>
<p>3.<em>-Mitigation of Detected Bias</em>: The grand finale and most important part of our tutorial! Users will learn effective strategies to mitigate the detected bias. This step is crucial for ethical deep learning, and the tutorial aims to equip users with essential skills dealing with biased results.</p>
<p>By completing this tutorial, users will acquire valuable skills for future data endeavors. It serves as a foundational step to train users and raise awareness of fairness issues in Deep Learning.</p>
<p><br></p>
<section id="background-and-prerequisites" class="level2">
<h2 class="anchored" data-anchor-id="background-and-prerequisites">Background and Prerequisites</h2>
<p>This tutorial is designed for users with a basic understanding of Python and Deep Learning. Users should have a foundational understanding of key concepts in machine learning and neural networks. Familiarity with Python is essential. Additionally, a grasp of linear algebra and calculus will be beneficial for understanding the mathematical underpinnings of deep learning algorithms.</p>
<ul>
<li><p>A solid understanding of model training is crucial, as well as knowledge of common machine learning libraries such as <code>Keras</code> and <code>scikit-learn</code>. Users should also be aware of the ethical and policy considerations surrounding machine learning applications, particularly in relation to bias and fairness.</p></li>
<li><p>Lastly, a conceptual understanding of how neural networks operate, including layers, activation functions, and backpropagation, will enhance the learning experience of the user. Overall, a basic background in machine learning fundamentals will help users to engage more effectively with our tutorial.</p></li>
</ul>
<div id="f49e1cc2" class="cell" data-message="false" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install pandas numpy matplotlib</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install Aequitas</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install keras_tuner</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install aif360</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install BlackBoxAuditing</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install tensorflow</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="32eb0ac0" class="cell" data-message="false" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data visualization</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">"white"</span>, palette<span class="op">=</span><span class="st">"muted"</span>, color_codes<span class="op">=</span><span class="va">True</span>, context<span class="op">=</span><span class="st">"talk"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython <span class="im">import</span> display</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Data manipulation</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Aequitas library used to audit models for discrimination and bias</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> aequitas.group <span class="im">import</span> Group</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> aequitas.bias <span class="im">import</span> Bias</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> aequitas.fairness <span class="im">import</span> Fairness</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> aequitas.plotting <span class="im">import</span> Plot</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings<span class="op">;</span> warnings.simplefilter(<span class="st">'ignore'</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Machine and deep learning libraries</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Input, Dense, Dropout</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Model</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> keras_tuner <span class="im">as</span> kt</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> Input, Model</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Dense, Dropout</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.utils.class_weight <span class="im">import</span> compute_class_weight</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, roc_auc_score</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler, StandardScaler</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score, recall_score, f1_score, confusion_matrix</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a><span class="co"># AI fairness library</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> aif360.algorithms.preprocessing <span class="im">import</span> DisparateImpactRemover</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> aif360.datasets <span class="im">import</span> StandardDataset <span class="im">as</span> Dataset</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> aif360.metrics <span class="im">import</span> BinaryLabelDatasetMetric</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> aif360.algorithms.postprocessing.reject_option_classification <span class="im">import</span> RejectOptionClassification</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> aif360.algorithms.preprocessing.reweighing <span class="im">import</span> Reweighing</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> OrderedDict</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> aif360.metrics <span class="im">import</span> ClassificationMetric</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="data-description" class="level1">
<h1>Data Description</h1>
<p>In this tutorial we are working with the COMPAS Recidivism Risk Score Data and Analysis (Source: Pro Publica, https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis) This dataset is a classical example for bias in machine learning. We specifically liked using this dataset as an example because it reveils the possible harmfull negative impact on real world decisions, that algorithms can have and the resulting policy responsibility.</p>
<p>The tabular dataset is used in U.S. court proceedings to evaluate the probability of a defendant reoffending. It is available in csv format for free and contains the following information (Source: https://mlr3fairness.mlr-org.com/reference/compas.html#pre-processing) :</p>
<ul>
<li><p>(integer) <strong>age</strong> : The age of defendants.</p></li>
<li><p>(factor) <strong>c_charge_degree</strong> : The charge degree of defendants. F: Felony M: Misdemeanor</p></li>
<li><p>(factor) <strong>race</strong>: The race of defendants.</p></li>
<li><p>(factor) <strong>age_cat</strong>: The age category of defendants.</p></li>
<li><p>(factor) <strong>score_text</strong>: The score category of defendants.</p></li>
<li><p>(factor) <strong>sex</strong>: The sex of defendants.</p></li>
<li><p>(integer) <strong>priors_count</strong>: The prior criminal records of defendants.</p></li>
<li><p>(integer) <strong>days_b_screening_arrest</strong>: The count of days between screening date and (original) arrest date. If they are too far apart, that may - indicate an error. If the value is negative, that indicate the screening date happened before the arrest date.</p></li>
<li><p>(integer) <strong>decile_score</strong>: Indicate the risk of recidivism (Min=1, Max=10)</p></li>
<li><p>(integer) <strong>is_recid</strong>: Binary variable indicate whether defendant is rearrested at any time.</p></li>
<li><p>(factor) <strong>two_year_recid</strong>: Binary variable indicate whether defendant is rearrested at within two years.</p></li>
<li><p>(numeric) <strong>length_of_stay</strong>: The count of days stay in jail.</p></li>
</ul>
<p>In the course of the tutorial, we’ll also work with a version of the COMPAS data, that was processed to work well with the aequitas package - this version of the dataset can be found in this Github repository: https://github.com/dssg/aequitas/tree/master/examples/data. Here, only a subset of the variables is considered, but it includes all important variables for demonstrating the package’s benefits. It includes:</p>
<ul>
<li><p>(integer) <strong>entity_id</strong>: ID variable</p></li>
<li><p>(integer) <strong>score</strong>: Risk score of defendants, binary</p></li>
<li><p>(factor) <strong>label_value</strong>: Binary variable indicate whether defendant is rearrested</p></li>
<li><p>(factor) <em>race</em>: The race of defendants.</p></li>
<li><p>(factor) <strong>sex</strong>: The sex of defendants</p></li>
<li><p>(factor) <strong>age_cat</strong>: The age category of defendants</p></li>
</ul>
<p><br></p>
</section>
<section id="part-1-data-exploration-and-bias-detection" class="level1">
<h1>Part 1: Data Exploration and Bias Detection</h1>
<p><strong>Note that the first part of this tutorial is largely based on the documentation of the aequitas-library (https://dssg.github.io/aequitas/examples/compas_demo.html?highlight=xtab). Since the COMPAS data is a widely-known and commonly used data set for showing issues with biased data, the authors used it for demonstrating the library’s core functions. Instead of linking the documentation, we decided to include the most important features of the library in the first part of our tutorial, partially adapting some code. More, we adjusted some codes in order to show the metrics that were most important to us for demonstrating bias in the compas data.</strong></p>
<p><br></p>
<p>For a first overview of the data, we load it directly from GitHub. Note that we use a version of the Compas data here that is explicitly well-suited for the Aequitas library, with a restricted number of columns and slightly deviating variable names. From printing the first 5 rows, we can retrieve that an ID variable, a (binary) risk score, a (binary) recidivism indicator, and three demographic variables (race, sex, age) are included.</p>
<section id="data-download" class="level2">
<h2 class="anchored" data-anchor-id="data-download">1.1 Data Download</h2>
<div id="ffb2ae2d" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>df_compas_aeq <span class="op">=</span> pd.read_csv(<span class="st">"https://raw.githubusercontent.com/dssg/aequitas/master/examples/data/compas_for_aequitas.csv"</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>df_compas_aeq.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">entity_id</th>
<th data-quarto-table-cell-role="th">score</th>
<th data-quarto-table-cell-role="th">label_value</th>
<th data-quarto-table-cell-role="th">race</th>
<th data-quarto-table-cell-role="th">sex</th>
<th data-quarto-table-cell-role="th">age_cat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>0.0</td>
<td>0</td>
<td>Other</td>
<td>Male</td>
<td>Greater than 45</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>3</td>
<td>0.0</td>
<td>1</td>
<td>African-American</td>
<td>Male</td>
<td>25 - 45</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>4</td>
<td>0.0</td>
<td>1</td>
<td>African-American</td>
<td>Male</td>
<td>Less than 25</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>5</td>
<td>1.0</td>
<td>0</td>
<td>African-American</td>
<td>Male</td>
<td>Less than 25</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>6</td>
<td>0.0</td>
<td>0</td>
<td>Other</td>
<td>Male</td>
<td>25 - 45</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="exploratory-data-visualization" class="level2">
<h2 class="anchored" data-anchor-id="exploratory-data-visualization">Exploratory Data Visualization</h2>
<section id="distribution-of-defendants-by-demographics-race-age-sex-and-risk-scores" class="level3">
<h3 class="anchored" data-anchor-id="distribution-of-defendants-by-demographics-race-age-sex-and-risk-scores">Distribution of Defendants by Demographics (Race, Age, Sex) and Risk Scores</h3>
<p><br></p>
<p>As a first step, we are exploring the distribution of our defendant data with regards to demographic characteristics and the calculated risk scores. As we can see, African-Americans, Caucasians, males, and defendants aged 25-45 are the subgroups that are highly represented in the data. Additionally, we can already see from the plots that African-Americans and defendants aged under 25 are the only subgroups where the majority has been assigned a high risk score.</p>
<div id="9ff70afc" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>Reds_palette <span class="op">=</span> sns.diverging_palette(<span class="dv">204</span>, <span class="dv">0</span>, n<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a figure with 3 subplots (3 rows, 1 column)</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">3</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">16</span>))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># race</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>by_race <span class="op">=</span> sns.countplot(</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    ax<span class="op">=</span>axes[<span class="dv">0</span>],</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"race"</span>,</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span><span class="st">"score"</span>,</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>df_compas_aeq,</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    palette<span class="op">=</span>Reds_palette</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">"Distribution of Defendants by Race and Risk Score (Decile)"</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">"Race"</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">"Count"</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend(loc<span class="op">=</span><span class="st">'upper right'</span>, title<span class="op">=</span><span class="st">'Risk Score Decile'</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(<span class="va">True</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co"># sex</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>by_sex <span class="op">=</span> sns.countplot(</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    ax<span class="op">=</span>axes[<span class="dv">1</span>],</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"sex"</span>,</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span><span class="st">"score"</span>,</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>df_compas_aeq,</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    palette<span class="op">=</span>Reds_palette</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Add title and labels</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">"Distribution of Defendants by Sex and Risk Score (Decile)"</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">"Sex"</span>)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">"Count"</span>)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="co"># sex</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend(loc<span class="op">=</span><span class="st">'upper right'</span>, title<span class="op">=</span><span class="st">'Risk Score'</span>)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(<span class="va">True</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Create countplot for age</span></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>by_age <span class="op">=</span> sns.countplot(</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>    ax<span class="op">=</span>axes[<span class="dv">2</span>],</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"age_cat"</span>,</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span><span class="st">"score"</span>,</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>df_compas_aeq,</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>    palette<span class="op">=</span>Reds_palette</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">"Distribution of Defendants by Age and Risk Score (Decile)"</span>)</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">"Age Category"</span>)</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">"Count"</span>)</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].legend(loc<span class="op">=</span><span class="st">'upper right'</span>, title<span class="op">=</span><span class="st">'Risk Score'</span>)</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].grid(<span class="va">True</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-6-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="index_files/figure-html/cell-6-output-1.png" width="739" height="1504" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p><br></p>
</section>
</section>
<section id="distribution-of-defendants-by-demographics-and-recidivism" class="level2">
<h2 class="anchored" data-anchor-id="distribution-of-defendants-by-demographics-and-recidivism">Distribution of Defendants by Demographics and Recidivism</h2>
<p>Next, we are looking at the same demographic subgroups and whether the defendants actually committed crime again. We can already see, that there seems to be a mismatch between the assigned risk scores and the recidivism patterns.</p>
<div id="baaf731a" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>coolwarm_two_colors <span class="op">=</span> sns.color_palette(<span class="st">"coolwarm"</span>, n_colors<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>coolwarm_palette <span class="op">=</span> sns.color_palette(<span class="st">"coolwarm"</span>, as_cmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a figure with 3 subplots (3 rows, 1 column)</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">3</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">16</span>))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create countplot for race</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>label_by_race <span class="op">=</span> sns.countplot(</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    ax<span class="op">=</span>axes[<span class="dv">0</span>],</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"race"</span>,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span><span class="st">"label_value"</span>,</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>df_compas_aeq,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    palette<span class="op">=</span>coolwarm_two_colors</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Add title and labels for race</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">"Levels of recidivism by Race"</span>)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">"Race"</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">"Count"</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(<span class="va">True</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend(loc<span class="op">=</span><span class="st">'upper right'</span>, title<span class="op">=</span><span class="st">'Recidivism'</span>)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Create countplot for sex</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>label_by_sex <span class="op">=</span> sns.countplot(</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    ax<span class="op">=</span>axes[<span class="dv">1</span>],</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"sex"</span>,</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span><span class="st">"label_value"</span>,</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>df_compas_aeq,</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    palette<span class="op">=</span>coolwarm_two_colors</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Add title and labels for sex</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">"Levels of recidivism by Sex"</span>)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">"Sex"</span>)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">"Count"</span>)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(<span class="va">True</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend(loc<span class="op">=</span><span class="st">'upper right'</span>, title<span class="op">=</span><span class="st">'Recidivism'</span>)</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Create countplot for age category</span></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>label_by_age <span class="op">=</span> sns.countplot(</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>    ax<span class="op">=</span>axes[<span class="dv">2</span>],</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span><span class="st">"age_cat"</span>,</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>    hue<span class="op">=</span><span class="st">"label_value"</span>,</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>df_compas_aeq,</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    palette<span class="op">=</span>coolwarm_two_colors</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Add title and labels for age category</span></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">"Levels of recidivism by Age Category"</span>)</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">"Age Category"</span>)</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">"Count"</span>)</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].grid(<span class="va">True</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].legend(loc<span class="op">=</span><span class="st">'upper right'</span>, title<span class="op">=</span><span class="st">'Recidivism'</span>)</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust layout</span></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-7-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="index_files/figure-html/cell-7-output-1.png" width="735" height="1503" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="introducing-the-aequitas-library" class="level2">
<h2 class="anchored" data-anchor-id="introducing-the-aequitas-library">Introducing the Aequitas-Library</h2>
<p>After eyeballing our data set and noticing that there might be some fairness issues, we can now use the Aequitas library to calculate common metrics that indicate biases in subgroups. More specifically, we are using the library’s Group() class that evaluates biases across all demographic subgroups in the dataset. Note here that the library requires the input data to have columns named “score” and “label_value”. These columns are by default used to calculate the bias metrics.</p>
<p>In order to use Aequitas for your purposes, you should rename the columns that you want to check for potential biases to “score” and “label_value”. Additionally, at least one column needs to include grouping information (in our example, several demographic variables). ID variables as entity_id are by default not treated as grouping variables.</p>
<p>The following code chunk calculates these metrices for all demographic subgroups using the get_crosstabs function, based on the risk score and the label_value, which indicates the recidivism.</p>
<div id="301ab5ee" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> Group()</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>xtab, _ <span class="op">=</span> g.get_crosstabs(df_compas_aeq)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>xtab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="7">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">model_id</th>
<th data-quarto-table-cell-role="th">score_threshold</th>
<th data-quarto-table-cell-role="th">k</th>
<th data-quarto-table-cell-role="th">attribute_name</th>
<th data-quarto-table-cell-role="th">attribute_value</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">tpr</th>
<th data-quarto-table-cell-role="th">tnr</th>
<th data-quarto-table-cell-role="th">for</th>
<th data-quarto-table-cell-role="th">fdr</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">pprev</th>
<th data-quarto-table-cell-role="th">fp</th>
<th data-quarto-table-cell-role="th">fn</th>
<th data-quarto-table-cell-role="th">tn</th>
<th data-quarto-table-cell-role="th">tp</th>
<th data-quarto-table-cell-role="th">group_label_pos</th>
<th data-quarto-table-cell-role="th">group_label_neg</th>
<th data-quarto-table-cell-role="th">group_size</th>
<th data-quarto-table-cell-role="th">total_entities</th>
<th data-quarto-table-cell-role="th">prev</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>binary 0/1</td>
<td>3317</td>
<td>race</td>
<td>African-American</td>
<td>0.638258</td>
<td>0.720147</td>
<td>0.551532</td>
<td>0.349540</td>
<td>0.370285</td>
<td>...</td>
<td>0.588203</td>
<td>805</td>
<td>532</td>
<td>990</td>
<td>1369</td>
<td>1901</td>
<td>1795</td>
<td>3696</td>
<td>7214</td>
<td>0.514340</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0</td>
<td>binary 0/1</td>
<td>3317</td>
<td>race</td>
<td>Asian</td>
<td>0.843750</td>
<td>0.666667</td>
<td>0.913043</td>
<td>0.125000</td>
<td>0.250000</td>
<td>...</td>
<td>0.250000</td>
<td>2</td>
<td>3</td>
<td>21</td>
<td>6</td>
<td>9</td>
<td>23</td>
<td>32</td>
<td>7214</td>
<td>0.281250</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0</td>
<td>binary 0/1</td>
<td>3317</td>
<td>race</td>
<td>Caucasian</td>
<td>0.669927</td>
<td>0.522774</td>
<td>0.765457</td>
<td>0.288125</td>
<td>0.408665</td>
<td>...</td>
<td>0.348003</td>
<td>349</td>
<td>461</td>
<td>1139</td>
<td>505</td>
<td>966</td>
<td>1488</td>
<td>2454</td>
<td>7214</td>
<td>0.393643</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0</td>
<td>binary 0/1</td>
<td>3317</td>
<td>race</td>
<td>Hispanic</td>
<td>0.660911</td>
<td>0.443966</td>
<td>0.785185</td>
<td>0.288591</td>
<td>0.457895</td>
<td>...</td>
<td>0.298273</td>
<td>87</td>
<td>129</td>
<td>318</td>
<td>103</td>
<td>232</td>
<td>405</td>
<td>637</td>
<td>7214</td>
<td>0.364207</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0</td>
<td>binary 0/1</td>
<td>3317</td>
<td>race</td>
<td>Native American</td>
<td>0.777778</td>
<td>0.900000</td>
<td>0.625000</td>
<td>0.166667</td>
<td>0.250000</td>
<td>...</td>
<td>0.666667</td>
<td>3</td>
<td>1</td>
<td>5</td>
<td>9</td>
<td>10</td>
<td>8</td>
<td>18</td>
<td>7214</td>
<td>0.555556</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>0</td>
<td>binary 0/1</td>
<td>3317</td>
<td>race</td>
<td>Other</td>
<td>0.665782</td>
<td>0.323308</td>
<td>0.852459</td>
<td>0.302013</td>
<td>0.455696</td>
<td>...</td>
<td>0.209549</td>
<td>36</td>
<td>90</td>
<td>208</td>
<td>43</td>
<td>133</td>
<td>244</td>
<td>377</td>
<td>7214</td>
<td>0.352785</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>0</td>
<td>binary 0/1</td>
<td>3317</td>
<td>sex</td>
<td>Female</td>
<td>0.653763</td>
<td>0.608434</td>
<td>0.678930</td>
<td>0.242537</td>
<td>0.487310</td>
<td>...</td>
<td>0.423656</td>
<td>288</td>
<td>195</td>
<td>609</td>
<td>303</td>
<td>498</td>
<td>897</td>
<td>1395</td>
<td>7214</td>
<td>0.356989</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>0</td>
<td>binary 0/1</td>
<td>3317</td>
<td>sex</td>
<td>Male</td>
<td>0.653721</td>
<td>0.629132</td>
<td>0.675799</td>
<td>0.330100</td>
<td>0.364637</td>
<td>...</td>
<td>0.468465</td>
<td>994</td>
<td>1021</td>
<td>2072</td>
<td>1732</td>
<td>2753</td>
<td>3066</td>
<td>5819</td>
<td>7214</td>
<td>0.473105</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>0</td>
<td>binary 0/1</td>
<td>3317</td>
<td>age_cat</td>
<td>25 - 45</td>
<td>0.647846</td>
<td>0.626257</td>
<td>0.666216</td>
<td>0.323112</td>
<td>0.385135</td>
<td>...</td>
<td>0.468240</td>
<td>741</td>
<td>706</td>
<td>1479</td>
<td>1183</td>
<td>1889</td>
<td>2220</td>
<td>4109</td>
<td>7214</td>
<td>0.459723</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>0</td>
<td>binary 0/1</td>
<td>3317</td>
<td>age_cat</td>
<td>Greater than 45</td>
<td>0.704315</td>
<td>0.427711</td>
<td>0.832096</td>
<td>0.241117</td>
<td>0.459391</td>
<td>...</td>
<td>0.250000</td>
<td>181</td>
<td>285</td>
<td>897</td>
<td>213</td>
<td>498</td>
<td>1078</td>
<td>1576</td>
<td>7214</td>
<td>0.315990</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>0</td>
<td>binary 0/1</td>
<td>3317</td>
<td>age_cat</td>
<td>Less than 25</td>
<td>0.617397</td>
<td>0.739583</td>
<td>0.458647</td>
<td>0.424528</td>
<td>0.360360</td>
<td>...</td>
<td>0.653368</td>
<td>360</td>
<td>225</td>
<td>305</td>
<td>639</td>
<td>864</td>
<td>665</td>
<td>1529</td>
<td>7214</td>
<td>0.565075</td>
</tr>
</tbody>
</table>

<p>11 rows × 27 columns</p>
</div>
</div>
</div>
</div>
<p><br></p>
<p>Additionally, we can use list_absolute_metrics() for an improved overview grouped by the demographics and with rounded values for the metrics.</p>
<p><br></p>
<div id="d77c8935" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>absolute_metrics <span class="op">=</span> g.list_absolute_metrics(xtab)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>xtab[[<span class="st">'attribute_name'</span>, <span class="st">'attribute_value'</span>] <span class="op">+</span> absolute_metrics].<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="8">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">attribute_name</th>
<th data-quarto-table-cell-role="th">attribute_value</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">tpr</th>
<th data-quarto-table-cell-role="th">tnr</th>
<th data-quarto-table-cell-role="th">for</th>
<th data-quarto-table-cell-role="th">fdr</th>
<th data-quarto-table-cell-role="th">fpr</th>
<th data-quarto-table-cell-role="th">fnr</th>
<th data-quarto-table-cell-role="th">npv</th>
<th data-quarto-table-cell-role="th">precision</th>
<th data-quarto-table-cell-role="th">ppr</th>
<th data-quarto-table-cell-role="th">pprev</th>
<th data-quarto-table-cell-role="th">prev</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>race</td>
<td>African-American</td>
<td>0.64</td>
<td>0.72</td>
<td>0.55</td>
<td>0.35</td>
<td>0.37</td>
<td>0.45</td>
<td>0.28</td>
<td>0.65</td>
<td>0.63</td>
<td>0.66</td>
<td>0.59</td>
<td>0.51</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>race</td>
<td>Asian</td>
<td>0.84</td>
<td>0.67</td>
<td>0.91</td>
<td>0.12</td>
<td>0.25</td>
<td>0.09</td>
<td>0.33</td>
<td>0.88</td>
<td>0.75</td>
<td>0.00</td>
<td>0.25</td>
<td>0.28</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>race</td>
<td>Caucasian</td>
<td>0.67</td>
<td>0.52</td>
<td>0.77</td>
<td>0.29</td>
<td>0.41</td>
<td>0.23</td>
<td>0.48</td>
<td>0.71</td>
<td>0.59</td>
<td>0.26</td>
<td>0.35</td>
<td>0.39</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>race</td>
<td>Hispanic</td>
<td>0.66</td>
<td>0.44</td>
<td>0.79</td>
<td>0.29</td>
<td>0.46</td>
<td>0.21</td>
<td>0.56</td>
<td>0.71</td>
<td>0.54</td>
<td>0.06</td>
<td>0.30</td>
<td>0.36</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>race</td>
<td>Native American</td>
<td>0.78</td>
<td>0.90</td>
<td>0.62</td>
<td>0.17</td>
<td>0.25</td>
<td>0.38</td>
<td>0.10</td>
<td>0.83</td>
<td>0.75</td>
<td>0.00</td>
<td>0.67</td>
<td>0.56</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>race</td>
<td>Other</td>
<td>0.67</td>
<td>0.32</td>
<td>0.85</td>
<td>0.30</td>
<td>0.46</td>
<td>0.15</td>
<td>0.68</td>
<td>0.70</td>
<td>0.54</td>
<td>0.02</td>
<td>0.21</td>
<td>0.35</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>sex</td>
<td>Female</td>
<td>0.65</td>
<td>0.61</td>
<td>0.68</td>
<td>0.24</td>
<td>0.49</td>
<td>0.32</td>
<td>0.39</td>
<td>0.76</td>
<td>0.51</td>
<td>0.18</td>
<td>0.42</td>
<td>0.36</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>sex</td>
<td>Male</td>
<td>0.65</td>
<td>0.63</td>
<td>0.68</td>
<td>0.33</td>
<td>0.36</td>
<td>0.32</td>
<td>0.37</td>
<td>0.67</td>
<td>0.64</td>
<td>0.82</td>
<td>0.47</td>
<td>0.47</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>age_cat</td>
<td>25 - 45</td>
<td>0.65</td>
<td>0.63</td>
<td>0.67</td>
<td>0.32</td>
<td>0.39</td>
<td>0.33</td>
<td>0.37</td>
<td>0.68</td>
<td>0.61</td>
<td>0.58</td>
<td>0.47</td>
<td>0.46</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>age_cat</td>
<td>Greater than 45</td>
<td>0.70</td>
<td>0.43</td>
<td>0.83</td>
<td>0.24</td>
<td>0.46</td>
<td>0.17</td>
<td>0.57</td>
<td>0.76</td>
<td>0.54</td>
<td>0.12</td>
<td>0.25</td>
<td>0.32</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>age_cat</td>
<td>Less than 25</td>
<td>0.62</td>
<td>0.74</td>
<td>0.46</td>
<td>0.42</td>
<td>0.36</td>
<td>0.54</td>
<td>0.26</td>
<td>0.58</td>
<td>0.64</td>
<td>0.30</td>
<td>0.65</td>
<td>0.57</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p><br></p>
<p>Next, we can use the information on the metrics that have been calculated by the previous chunk to plot the present biases. For that purpose, the <code>Plot()</code> class is used and stored in a variable. Afterwards, this variable can be used to plot the metrics of interest. The next code chunk exemplarily plots the <strong>false positive rate</strong> for all subgroups. In the context of our data, false positive cases are present when defendants are classified high risk although they did not recidivate. As we can see from the plot below, these cases are especially present amoung younger as well as among African- and Native Americans.</p>
<p>Additionally, the colors by default indicate how many respondents are included in the respective subgroup. The exact number can also be retrieved from the bar labels. Referring to the group sizes, you can see that the two races with they highest FPR are of significantly different size: While there are only 18 Native Americans included in our data, a total of nearly 3,700 African-American defendants are present.</p>
<div id="b2ae0141" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>aqp <span class="op">=</span> Plot()</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>fpr <span class="op">=</span> aqp.plot_group_metric(xtab, <span class="st">'fpr'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-10-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="index_files/figure-html/cell-10-output-1.png" width="862" height="481" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p><br></p>
<p>For better readability, and when only interested in the rates rather then the absolute numbers, we can switch the axes and rotate the x-axis labels:</p>
<p><br></p>
<div id="2d79ad3d" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>xtab_df <span class="op">=</span> xtab[[<span class="st">'attribute_name'</span>, <span class="st">'attribute_value'</span>] <span class="op">+</span> absolute_metrics].<span class="bu">round</span>(<span class="dv">2</span>).set_index([<span class="st">'attribute_name'</span>, <span class="st">'attribute_value'</span>])</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>xtab_df <span class="op">=</span> xtab_df.reset_index()</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a figure for the plot</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">6</span>))</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a bar plot for FPR</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.barplot(x<span class="op">=</span><span class="st">'attribute_value'</span>, y<span class="op">=</span><span class="st">'fpr'</span>, hue<span class="op">=</span><span class="st">'attribute_name'</span>, data<span class="op">=</span>xtab_df, palette<span class="op">=</span><span class="st">'coolwarm'</span>, dodge<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>ax.set_xticklabels(ax.get_xticklabels(), rotation<span class="op">=</span><span class="dv">60</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Add title and labels</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'False Positive Rate (FPR) by Attribute'</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Attribute Value'</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'FPR'</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Rotate x-axis labels for better readability</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">60</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the plot</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-11-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="index_files/figure-html/cell-11-output-1.png" width="764" height="689" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p><br></p>
<p>Besides the FPR, the Aequitas package calculated several further helpful metrices that illustrate biases. In the following code chunk, we present four metrices in total:</p>
<ul>
<li><p>The Predicted Positive Rate (PPR): Proportion of positively predicted defendants</p></li>
<li><p>Predictive Prevalence (PPrev): Positive predicition at higher prevalence in relation to group size</p></li>
<li><p>False Negative Rate: Negative risk predictions, positive score</p></li>
<li><p>False Positive Rate: Positive risk predicition, negative score</p></li>
</ul>
<p>We can see that African-Americans and males are largely predicted as having a high-risk score (PPR), which also holds true when considering group size (PPrev), although here, also younger defendants are highly represented. We already discussed FPR, showing that African-Americans are often misclassified as high risk. Looking at the FNR, we can see that African-Americans rather rarely are misclassified as low-risk, while this seems to be especially true with older defendants.</p>
<div id="bfdd69c2" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">4</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">30</span>))  <span class="co"># 4 rows, 1 column</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>palette <span class="op">=</span> sns.color_palette(<span class="st">"ocean_r"</span>, n_colors<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># PPR Plot in the first row (0)</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span><span class="st">'attribute_value'</span>, y<span class="op">=</span><span class="st">'ppr'</span>, hue<span class="op">=</span><span class="st">'attribute_name'</span>, data<span class="op">=</span>xtab_df, palette<span class="op">=</span>palette, ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Positive Predictive Rate (PPR) by Attribute'</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Attribute Value'</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'PPR'</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend(loc<span class="op">=</span><span class="st">'upper right'</span>, title<span class="op">=</span><span class="st">'Category'</span>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co"># PPrev Plot in the second row (1)</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span><span class="st">'attribute_value'</span>, y<span class="op">=</span><span class="st">'pprev'</span>, hue<span class="op">=</span><span class="st">'attribute_name'</span>, data<span class="op">=</span>xtab_df, palette<span class="op">=</span>palette, ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Predictive Prevalence (PPrev) by Attribute'</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Attribute Value'</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'PPrev'</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend(loc<span class="op">=</span><span class="st">'upper center'</span>, title<span class="op">=</span><span class="st">'Category'</span>)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="co"># FNR Plot in the third row (2)</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span><span class="st">'attribute_value'</span>, y<span class="op">=</span><span class="st">'fnr'</span>, hue<span class="op">=</span><span class="st">'attribute_name'</span>, data<span class="op">=</span>xtab_df, palette<span class="op">=</span>palette, ax<span class="op">=</span>axes[<span class="dv">2</span>])</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'False Negative Rate (FNR) by Attribute'</span>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'Attribute Value'</span>)</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">'FNR'</span>)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].legend(loc<span class="op">=</span><span class="st">'upper left'</span>, title<span class="op">=</span><span class="st">'Category'</span>)</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a><span class="co"># FPR Plot in the fourth row (3)</span></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span><span class="st">'attribute_value'</span>, y<span class="op">=</span><span class="st">'fpr'</span>, hue<span class="op">=</span><span class="st">'attribute_name'</span>, data<span class="op">=</span>xtab_df, palette<span class="op">=</span>palette, ax<span class="op">=</span>axes[<span class="dv">3</span>])</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">3</span>].set_title(<span class="st">'False Positive Rate (FPR) by Attribute'</span>)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">3</span>].set_xlabel(<span class="st">'Attribute Value'</span>)</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">3</span>].set_ylabel(<span class="st">'FPR'</span>)</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">3</span>].tick_params(axis<span class="op">=</span><span class="st">'x'</span>, rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">3</span>].legend(loc<span class="op">=</span><span class="st">'upper center'</span>, title<span class="op">=</span><span class="st">'Category'</span>)</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust the layout</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the combined plot</span></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-12-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="index_files/figure-html/cell-12-output-1.png" width="735" height="2847" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="calculating-the-bias-using-disparity" class="level2">
<h2 class="anchored" data-anchor-id="calculating-the-bias-using-disparity">Calculating the bias using disparity</h2>
<p>Lastly, the Aequitas package lets us compare subgroups by calculating disparaties as a ratio of the desired metric.</p>
<p>For example, the disparity of the false positive ratio for black and white defendants can be calculated like this:</p>
<p><span class="math inline">\(\text{Disparity}_{FPR} = \frac{FPR{\text{black}}}{FPR{\text{white}}}\)</span></p>
<p>To easily calculate the disparity values for all metrices, we use the <code>Bias()</code> class of the Aquitas package and calculate a confusion matrix. Note that for each subgroup, you will need to assign a reference category. Here, we chose to compare all included subgroups to Caucasians, males, and defendants aged 25-45.</p>
<div id="19e4568c" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Bias()</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>bdf <span class="op">=</span> b.get_disparity_predefined_groups(xtab, original_df<span class="op">=</span>df_compas_aeq, ref_groups_dict<span class="op">=</span>{<span class="st">'race'</span>:<span class="st">'Caucasian'</span>, <span class="st">'sex'</span>:<span class="st">'Male'</span>, <span class="st">'age_cat'</span>:<span class="st">'25 - 45'</span>}, alpha<span class="op">=</span><span class="fl">0.05</span>, mask_significance<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>bdf.style</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="12">
<div>
<style type="text/css">
</style>

<table id="T_a6577" data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_a6577_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">model_id</th>
<th id="T_a6577_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">score_threshold</th>
<th id="T_a6577_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">k</th>
<th id="T_a6577_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">attribute_name</th>
<th id="T_a6577_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">attribute_value</th>
<th id="T_a6577_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">accuracy</th>
<th id="T_a6577_level0_col6" class="col_heading level0 col6" data-quarto-table-cell-role="th">tpr</th>
<th id="T_a6577_level0_col7" class="col_heading level0 col7" data-quarto-table-cell-role="th">tnr</th>
<th id="T_a6577_level0_col8" class="col_heading level0 col8" data-quarto-table-cell-role="th">for</th>
<th id="T_a6577_level0_col9" class="col_heading level0 col9" data-quarto-table-cell-role="th">fdr</th>
<th id="T_a6577_level0_col10" class="col_heading level0 col10" data-quarto-table-cell-role="th">fpr</th>
<th id="T_a6577_level0_col11" class="col_heading level0 col11" data-quarto-table-cell-role="th">fnr</th>
<th id="T_a6577_level0_col12" class="col_heading level0 col12" data-quarto-table-cell-role="th">npv</th>
<th id="T_a6577_level0_col13" class="col_heading level0 col13" data-quarto-table-cell-role="th">precision</th>
<th id="T_a6577_level0_col14" class="col_heading level0 col14" data-quarto-table-cell-role="th">pp</th>
<th id="T_a6577_level0_col15" class="col_heading level0 col15" data-quarto-table-cell-role="th">pn</th>
<th id="T_a6577_level0_col16" class="col_heading level0 col16" data-quarto-table-cell-role="th">ppr</th>
<th id="T_a6577_level0_col17" class="col_heading level0 col17" data-quarto-table-cell-role="th">pprev</th>
<th id="T_a6577_level0_col18" class="col_heading level0 col18" data-quarto-table-cell-role="th">fp</th>
<th id="T_a6577_level0_col19" class="col_heading level0 col19" data-quarto-table-cell-role="th">fn</th>
<th id="T_a6577_level0_col20" class="col_heading level0 col20" data-quarto-table-cell-role="th">tn</th>
<th id="T_a6577_level0_col21" class="col_heading level0 col21" data-quarto-table-cell-role="th">tp</th>
<th id="T_a6577_level0_col22" class="col_heading level0 col22" data-quarto-table-cell-role="th">group_label_pos</th>
<th id="T_a6577_level0_col23" class="col_heading level0 col23" data-quarto-table-cell-role="th">group_label_neg</th>
<th id="T_a6577_level0_col24" class="col_heading level0 col24" data-quarto-table-cell-role="th">group_size</th>
<th id="T_a6577_level0_col25" class="col_heading level0 col25" data-quarto-table-cell-role="th">total_entities</th>
<th id="T_a6577_level0_col26" class="col_heading level0 col26" data-quarto-table-cell-role="th">prev</th>
<th id="T_a6577_level0_col27" class="col_heading level0 col27" data-quarto-table-cell-role="th">ppr_disparity</th>
<th id="T_a6577_level0_col28" class="col_heading level0 col28" data-quarto-table-cell-role="th">pprev_disparity</th>
<th id="T_a6577_level0_col29" class="col_heading level0 col29" data-quarto-table-cell-role="th">precision_disparity</th>
<th id="T_a6577_level0_col30" class="col_heading level0 col30" data-quarto-table-cell-role="th">fdr_disparity</th>
<th id="T_a6577_level0_col31" class="col_heading level0 col31" data-quarto-table-cell-role="th">for_disparity</th>
<th id="T_a6577_level0_col32" class="col_heading level0 col32" data-quarto-table-cell-role="th">fpr_disparity</th>
<th id="T_a6577_level0_col33" class="col_heading level0 col33" data-quarto-table-cell-role="th">fnr_disparity</th>
<th id="T_a6577_level0_col34" class="col_heading level0 col34" data-quarto-table-cell-role="th">tpr_disparity</th>
<th id="T_a6577_level0_col35" class="col_heading level0 col35" data-quarto-table-cell-role="th">tnr_disparity</th>
<th id="T_a6577_level0_col36" class="col_heading level0 col36" data-quarto-table-cell-role="th">npv_disparity</th>
<th id="T_a6577_level0_col37" class="col_heading level0 col37" data-quarto-table-cell-role="th">ppr_ref_group_value</th>
<th id="T_a6577_level0_col38" class="col_heading level0 col38" data-quarto-table-cell-role="th">pprev_ref_group_value</th>
<th id="T_a6577_level0_col39" class="col_heading level0 col39" data-quarto-table-cell-role="th">precision_ref_group_value</th>
<th id="T_a6577_level0_col40" class="col_heading level0 col40" data-quarto-table-cell-role="th">fdr_ref_group_value</th>
<th id="T_a6577_level0_col41" class="col_heading level0 col41" data-quarto-table-cell-role="th">for_ref_group_value</th>
<th id="T_a6577_level0_col42" class="col_heading level0 col42" data-quarto-table-cell-role="th">fpr_ref_group_value</th>
<th id="T_a6577_level0_col43" class="col_heading level0 col43" data-quarto-table-cell-role="th">fnr_ref_group_value</th>
<th id="T_a6577_level0_col44" class="col_heading level0 col44" data-quarto-table-cell-role="th">tpr_ref_group_value</th>
<th id="T_a6577_level0_col45" class="col_heading level0 col45" data-quarto-table-cell-role="th">tnr_ref_group_value</th>
<th id="T_a6577_level0_col46" class="col_heading level0 col46" data-quarto-table-cell-role="th">npv_ref_group_value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_a6577_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">0</td>
<td id="T_a6577_row0_col0" class="data row0 col0">0</td>
<td id="T_a6577_row0_col1" class="data row0 col1">binary 0/1</td>
<td id="T_a6577_row0_col2" class="data row0 col2">3317</td>
<td id="T_a6577_row0_col3" class="data row0 col3">race</td>
<td id="T_a6577_row0_col4" class="data row0 col4">African-American</td>
<td id="T_a6577_row0_col5" class="data row0 col5">0.638258</td>
<td id="T_a6577_row0_col6" class="data row0 col6">0.720147</td>
<td id="T_a6577_row0_col7" class="data row0 col7">0.551532</td>
<td id="T_a6577_row0_col8" class="data row0 col8">0.349540</td>
<td id="T_a6577_row0_col9" class="data row0 col9">0.370285</td>
<td id="T_a6577_row0_col10" class="data row0 col10">0.448468</td>
<td id="T_a6577_row0_col11" class="data row0 col11">0.279853</td>
<td id="T_a6577_row0_col12" class="data row0 col12">0.650460</td>
<td id="T_a6577_row0_col13" class="data row0 col13">0.629715</td>
<td id="T_a6577_row0_col14" class="data row0 col14">2174</td>
<td id="T_a6577_row0_col15" class="data row0 col15">1522</td>
<td id="T_a6577_row0_col16" class="data row0 col16">0.655412</td>
<td id="T_a6577_row0_col17" class="data row0 col17">0.588203</td>
<td id="T_a6577_row0_col18" class="data row0 col18">805</td>
<td id="T_a6577_row0_col19" class="data row0 col19">532</td>
<td id="T_a6577_row0_col20" class="data row0 col20">990</td>
<td id="T_a6577_row0_col21" class="data row0 col21">1369</td>
<td id="T_a6577_row0_col22" class="data row0 col22">1901</td>
<td id="T_a6577_row0_col23" class="data row0 col23">1795</td>
<td id="T_a6577_row0_col24" class="data row0 col24">3696</td>
<td id="T_a6577_row0_col25" class="data row0 col25">7214</td>
<td id="T_a6577_row0_col26" class="data row0 col26">0.514340</td>
<td id="T_a6577_row0_col27" class="data row0 col27">2.545667</td>
<td id="T_a6577_row0_col28" class="data row0 col28">1.690224</td>
<td id="T_a6577_row0_col29" class="data row0 col29">1.064904</td>
<td id="T_a6577_row0_col30" class="data row0 col30">0.906085</td>
<td id="T_a6577_row0_col31" class="data row0 col31">1.213154</td>
<td id="T_a6577_row0_col32" class="data row0 col32">1.912093</td>
<td id="T_a6577_row0_col33" class="data row0 col33">0.586416</td>
<td id="T_a6577_row0_col34" class="data row0 col34">1.377549</td>
<td id="T_a6577_row0_col35" class="data row0 col35">0.720526</td>
<td id="T_a6577_row0_col36" class="data row0 col36">0.913728</td>
<td id="T_a6577_row0_col37" class="data row0 col37">Caucasian</td>
<td id="T_a6577_row0_col38" class="data row0 col38">Caucasian</td>
<td id="T_a6577_row0_col39" class="data row0 col39">Caucasian</td>
<td id="T_a6577_row0_col40" class="data row0 col40">Caucasian</td>
<td id="T_a6577_row0_col41" class="data row0 col41">Caucasian</td>
<td id="T_a6577_row0_col42" class="data row0 col42">Caucasian</td>
<td id="T_a6577_row0_col43" class="data row0 col43">Caucasian</td>
<td id="T_a6577_row0_col44" class="data row0 col44">Caucasian</td>
<td id="T_a6577_row0_col45" class="data row0 col45">Caucasian</td>
<td id="T_a6577_row0_col46" class="data row0 col46">Caucasian</td>
</tr>
<tr class="even">
<td id="T_a6577_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">1</td>
<td id="T_a6577_row1_col0" class="data row1 col0">0</td>
<td id="T_a6577_row1_col1" class="data row1 col1">binary 0/1</td>
<td id="T_a6577_row1_col2" class="data row1 col2">3317</td>
<td id="T_a6577_row1_col3" class="data row1 col3">race</td>
<td id="T_a6577_row1_col4" class="data row1 col4">Asian</td>
<td id="T_a6577_row1_col5" class="data row1 col5">0.843750</td>
<td id="T_a6577_row1_col6" class="data row1 col6">0.666667</td>
<td id="T_a6577_row1_col7" class="data row1 col7">0.913043</td>
<td id="T_a6577_row1_col8" class="data row1 col8">0.125000</td>
<td id="T_a6577_row1_col9" class="data row1 col9">0.250000</td>
<td id="T_a6577_row1_col10" class="data row1 col10">0.086957</td>
<td id="T_a6577_row1_col11" class="data row1 col11">0.333333</td>
<td id="T_a6577_row1_col12" class="data row1 col12">0.875000</td>
<td id="T_a6577_row1_col13" class="data row1 col13">0.750000</td>
<td id="T_a6577_row1_col14" class="data row1 col14">8</td>
<td id="T_a6577_row1_col15" class="data row1 col15">24</td>
<td id="T_a6577_row1_col16" class="data row1 col16">0.002412</td>
<td id="T_a6577_row1_col17" class="data row1 col17">0.250000</td>
<td id="T_a6577_row1_col18" class="data row1 col18">2</td>
<td id="T_a6577_row1_col19" class="data row1 col19">3</td>
<td id="T_a6577_row1_col20" class="data row1 col20">21</td>
<td id="T_a6577_row1_col21" class="data row1 col21">6</td>
<td id="T_a6577_row1_col22" class="data row1 col22">9</td>
<td id="T_a6577_row1_col23" class="data row1 col23">23</td>
<td id="T_a6577_row1_col24" class="data row1 col24">32</td>
<td id="T_a6577_row1_col25" class="data row1 col25">7214</td>
<td id="T_a6577_row1_col26" class="data row1 col26">0.281250</td>
<td id="T_a6577_row1_col27" class="data row1 col27">0.009368</td>
<td id="T_a6577_row1_col28" class="data row1 col28">0.718384</td>
<td id="T_a6577_row1_col29" class="data row1 col29">1.268317</td>
<td id="T_a6577_row1_col30" class="data row1 col30">0.611748</td>
<td id="T_a6577_row1_col31" class="data row1 col31">0.433839</td>
<td id="T_a6577_row1_col32" class="data row1 col32">0.370749</td>
<td id="T_a6577_row1_col33" class="data row1 col33">0.698482</td>
<td id="T_a6577_row1_col34" class="data row1 col34">1.275248</td>
<td id="T_a6577_row1_col35" class="data row1 col35">1.192808</td>
<td id="T_a6577_row1_col36" class="data row1 col36">1.229148</td>
<td id="T_a6577_row1_col37" class="data row1 col37">Caucasian</td>
<td id="T_a6577_row1_col38" class="data row1 col38">Caucasian</td>
<td id="T_a6577_row1_col39" class="data row1 col39">Caucasian</td>
<td id="T_a6577_row1_col40" class="data row1 col40">Caucasian</td>
<td id="T_a6577_row1_col41" class="data row1 col41">Caucasian</td>
<td id="T_a6577_row1_col42" class="data row1 col42">Caucasian</td>
<td id="T_a6577_row1_col43" class="data row1 col43">Caucasian</td>
<td id="T_a6577_row1_col44" class="data row1 col44">Caucasian</td>
<td id="T_a6577_row1_col45" class="data row1 col45">Caucasian</td>
<td id="T_a6577_row1_col46" class="data row1 col46">Caucasian</td>
</tr>
<tr class="odd">
<td id="T_a6577_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">2</td>
<td id="T_a6577_row2_col0" class="data row2 col0">0</td>
<td id="T_a6577_row2_col1" class="data row2 col1">binary 0/1</td>
<td id="T_a6577_row2_col2" class="data row2 col2">3317</td>
<td id="T_a6577_row2_col3" class="data row2 col3">race</td>
<td id="T_a6577_row2_col4" class="data row2 col4">Caucasian</td>
<td id="T_a6577_row2_col5" class="data row2 col5">0.669927</td>
<td id="T_a6577_row2_col6" class="data row2 col6">0.522774</td>
<td id="T_a6577_row2_col7" class="data row2 col7">0.765457</td>
<td id="T_a6577_row2_col8" class="data row2 col8">0.288125</td>
<td id="T_a6577_row2_col9" class="data row2 col9">0.408665</td>
<td id="T_a6577_row2_col10" class="data row2 col10">0.234543</td>
<td id="T_a6577_row2_col11" class="data row2 col11">0.477226</td>
<td id="T_a6577_row2_col12" class="data row2 col12">0.711875</td>
<td id="T_a6577_row2_col13" class="data row2 col13">0.591335</td>
<td id="T_a6577_row2_col14" class="data row2 col14">854</td>
<td id="T_a6577_row2_col15" class="data row2 col15">1600</td>
<td id="T_a6577_row2_col16" class="data row2 col16">0.257462</td>
<td id="T_a6577_row2_col17" class="data row2 col17">0.348003</td>
<td id="T_a6577_row2_col18" class="data row2 col18">349</td>
<td id="T_a6577_row2_col19" class="data row2 col19">461</td>
<td id="T_a6577_row2_col20" class="data row2 col20">1139</td>
<td id="T_a6577_row2_col21" class="data row2 col21">505</td>
<td id="T_a6577_row2_col22" class="data row2 col22">966</td>
<td id="T_a6577_row2_col23" class="data row2 col23">1488</td>
<td id="T_a6577_row2_col24" class="data row2 col24">2454</td>
<td id="T_a6577_row2_col25" class="data row2 col25">7214</td>
<td id="T_a6577_row2_col26" class="data row2 col26">0.393643</td>
<td id="T_a6577_row2_col27" class="data row2 col27">1.000000</td>
<td id="T_a6577_row2_col28" class="data row2 col28">1.000000</td>
<td id="T_a6577_row2_col29" class="data row2 col29">1.000000</td>
<td id="T_a6577_row2_col30" class="data row2 col30">1.000000</td>
<td id="T_a6577_row2_col31" class="data row2 col31">1.000000</td>
<td id="T_a6577_row2_col32" class="data row2 col32">1.000000</td>
<td id="T_a6577_row2_col33" class="data row2 col33">1.000000</td>
<td id="T_a6577_row2_col34" class="data row2 col34">1.000000</td>
<td id="T_a6577_row2_col35" class="data row2 col35">1.000000</td>
<td id="T_a6577_row2_col36" class="data row2 col36">1.000000</td>
<td id="T_a6577_row2_col37" class="data row2 col37">Caucasian</td>
<td id="T_a6577_row2_col38" class="data row2 col38">Caucasian</td>
<td id="T_a6577_row2_col39" class="data row2 col39">Caucasian</td>
<td id="T_a6577_row2_col40" class="data row2 col40">Caucasian</td>
<td id="T_a6577_row2_col41" class="data row2 col41">Caucasian</td>
<td id="T_a6577_row2_col42" class="data row2 col42">Caucasian</td>
<td id="T_a6577_row2_col43" class="data row2 col43">Caucasian</td>
<td id="T_a6577_row2_col44" class="data row2 col44">Caucasian</td>
<td id="T_a6577_row2_col45" class="data row2 col45">Caucasian</td>
<td id="T_a6577_row2_col46" class="data row2 col46">Caucasian</td>
</tr>
<tr class="even">
<td id="T_a6577_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">3</td>
<td id="T_a6577_row3_col0" class="data row3 col0">0</td>
<td id="T_a6577_row3_col1" class="data row3 col1">binary 0/1</td>
<td id="T_a6577_row3_col2" class="data row3 col2">3317</td>
<td id="T_a6577_row3_col3" class="data row3 col3">race</td>
<td id="T_a6577_row3_col4" class="data row3 col4">Hispanic</td>
<td id="T_a6577_row3_col5" class="data row3 col5">0.660911</td>
<td id="T_a6577_row3_col6" class="data row3 col6">0.443966</td>
<td id="T_a6577_row3_col7" class="data row3 col7">0.785185</td>
<td id="T_a6577_row3_col8" class="data row3 col8">0.288591</td>
<td id="T_a6577_row3_col9" class="data row3 col9">0.457895</td>
<td id="T_a6577_row3_col10" class="data row3 col10">0.214815</td>
<td id="T_a6577_row3_col11" class="data row3 col11">0.556034</td>
<td id="T_a6577_row3_col12" class="data row3 col12">0.711409</td>
<td id="T_a6577_row3_col13" class="data row3 col13">0.542105</td>
<td id="T_a6577_row3_col14" class="data row3 col14">190</td>
<td id="T_a6577_row3_col15" class="data row3 col15">447</td>
<td id="T_a6577_row3_col16" class="data row3 col16">0.057281</td>
<td id="T_a6577_row3_col17" class="data row3 col17">0.298273</td>
<td id="T_a6577_row3_col18" class="data row3 col18">87</td>
<td id="T_a6577_row3_col19" class="data row3 col19">129</td>
<td id="T_a6577_row3_col20" class="data row3 col20">318</td>
<td id="T_a6577_row3_col21" class="data row3 col21">103</td>
<td id="T_a6577_row3_col22" class="data row3 col22">232</td>
<td id="T_a6577_row3_col23" class="data row3 col23">405</td>
<td id="T_a6577_row3_col24" class="data row3 col24">637</td>
<td id="T_a6577_row3_col25" class="data row3 col25">7214</td>
<td id="T_a6577_row3_col26" class="data row3 col26">0.364207</td>
<td id="T_a6577_row3_col27" class="data row3 col27">0.222482</td>
<td id="T_a6577_row3_col28" class="data row3 col28">0.857099</td>
<td id="T_a6577_row3_col29" class="data row3 col29">0.916748</td>
<td id="T_a6577_row3_col30" class="data row3 col30">1.120464</td>
<td id="T_a6577_row3_col31" class="data row3 col31">1.001616</td>
<td id="T_a6577_row3_col32" class="data row3 col32">0.915887</td>
<td id="T_a6577_row3_col33" class="data row3 col33">1.165140</td>
<td id="T_a6577_row3_col34" class="data row3 col34">0.849249</td>
<td id="T_a6577_row3_col35" class="data row3 col35">1.025773</td>
<td id="T_a6577_row3_col36" class="data row3 col36">0.999346</td>
<td id="T_a6577_row3_col37" class="data row3 col37">Caucasian</td>
<td id="T_a6577_row3_col38" class="data row3 col38">Caucasian</td>
<td id="T_a6577_row3_col39" class="data row3 col39">Caucasian</td>
<td id="T_a6577_row3_col40" class="data row3 col40">Caucasian</td>
<td id="T_a6577_row3_col41" class="data row3 col41">Caucasian</td>
<td id="T_a6577_row3_col42" class="data row3 col42">Caucasian</td>
<td id="T_a6577_row3_col43" class="data row3 col43">Caucasian</td>
<td id="T_a6577_row3_col44" class="data row3 col44">Caucasian</td>
<td id="T_a6577_row3_col45" class="data row3 col45">Caucasian</td>
<td id="T_a6577_row3_col46" class="data row3 col46">Caucasian</td>
</tr>
<tr class="odd">
<td id="T_a6577_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">4</td>
<td id="T_a6577_row4_col0" class="data row4 col0">0</td>
<td id="T_a6577_row4_col1" class="data row4 col1">binary 0/1</td>
<td id="T_a6577_row4_col2" class="data row4 col2">3317</td>
<td id="T_a6577_row4_col3" class="data row4 col3">race</td>
<td id="T_a6577_row4_col4" class="data row4 col4">Native American</td>
<td id="T_a6577_row4_col5" class="data row4 col5">0.777778</td>
<td id="T_a6577_row4_col6" class="data row4 col6">0.900000</td>
<td id="T_a6577_row4_col7" class="data row4 col7">0.625000</td>
<td id="T_a6577_row4_col8" class="data row4 col8">0.166667</td>
<td id="T_a6577_row4_col9" class="data row4 col9">0.250000</td>
<td id="T_a6577_row4_col10" class="data row4 col10">0.375000</td>
<td id="T_a6577_row4_col11" class="data row4 col11">0.100000</td>
<td id="T_a6577_row4_col12" class="data row4 col12">0.833333</td>
<td id="T_a6577_row4_col13" class="data row4 col13">0.750000</td>
<td id="T_a6577_row4_col14" class="data row4 col14">12</td>
<td id="T_a6577_row4_col15" class="data row4 col15">6</td>
<td id="T_a6577_row4_col16" class="data row4 col16">0.003618</td>
<td id="T_a6577_row4_col17" class="data row4 col17">0.666667</td>
<td id="T_a6577_row4_col18" class="data row4 col18">3</td>
<td id="T_a6577_row4_col19" class="data row4 col19">1</td>
<td id="T_a6577_row4_col20" class="data row4 col20">5</td>
<td id="T_a6577_row4_col21" class="data row4 col21">9</td>
<td id="T_a6577_row4_col22" class="data row4 col22">10</td>
<td id="T_a6577_row4_col23" class="data row4 col23">8</td>
<td id="T_a6577_row4_col24" class="data row4 col24">18</td>
<td id="T_a6577_row4_col25" class="data row4 col25">7214</td>
<td id="T_a6577_row4_col26" class="data row4 col26">0.555556</td>
<td id="T_a6577_row4_col27" class="data row4 col27">0.014052</td>
<td id="T_a6577_row4_col28" class="data row4 col28">1.915691</td>
<td id="T_a6577_row4_col29" class="data row4 col29">1.268317</td>
<td id="T_a6577_row4_col30" class="data row4 col30">0.611748</td>
<td id="T_a6577_row4_col31" class="data row4 col31">0.578453</td>
<td id="T_a6577_row4_col32" class="data row4 col32">1.598854</td>
<td id="T_a6577_row4_col33" class="data row4 col33">0.209544</td>
<td id="T_a6577_row4_col34" class="data row4 col34">1.721584</td>
<td id="T_a6577_row4_col35" class="data row4 col35">0.816506</td>
<td id="T_a6577_row4_col36" class="data row4 col36">1.170618</td>
<td id="T_a6577_row4_col37" class="data row4 col37">Caucasian</td>
<td id="T_a6577_row4_col38" class="data row4 col38">Caucasian</td>
<td id="T_a6577_row4_col39" class="data row4 col39">Caucasian</td>
<td id="T_a6577_row4_col40" class="data row4 col40">Caucasian</td>
<td id="T_a6577_row4_col41" class="data row4 col41">Caucasian</td>
<td id="T_a6577_row4_col42" class="data row4 col42">Caucasian</td>
<td id="T_a6577_row4_col43" class="data row4 col43">Caucasian</td>
<td id="T_a6577_row4_col44" class="data row4 col44">Caucasian</td>
<td id="T_a6577_row4_col45" class="data row4 col45">Caucasian</td>
<td id="T_a6577_row4_col46" class="data row4 col46">Caucasian</td>
</tr>
<tr class="even">
<td id="T_a6577_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">5</td>
<td id="T_a6577_row5_col0" class="data row5 col0">0</td>
<td id="T_a6577_row5_col1" class="data row5 col1">binary 0/1</td>
<td id="T_a6577_row5_col2" class="data row5 col2">3317</td>
<td id="T_a6577_row5_col3" class="data row5 col3">race</td>
<td id="T_a6577_row5_col4" class="data row5 col4">Other</td>
<td id="T_a6577_row5_col5" class="data row5 col5">0.665782</td>
<td id="T_a6577_row5_col6" class="data row5 col6">0.323308</td>
<td id="T_a6577_row5_col7" class="data row5 col7">0.852459</td>
<td id="T_a6577_row5_col8" class="data row5 col8">0.302013</td>
<td id="T_a6577_row5_col9" class="data row5 col9">0.455696</td>
<td id="T_a6577_row5_col10" class="data row5 col10">0.147541</td>
<td id="T_a6577_row5_col11" class="data row5 col11">0.676692</td>
<td id="T_a6577_row5_col12" class="data row5 col12">0.697987</td>
<td id="T_a6577_row5_col13" class="data row5 col13">0.544304</td>
<td id="T_a6577_row5_col14" class="data row5 col14">79</td>
<td id="T_a6577_row5_col15" class="data row5 col15">298</td>
<td id="T_a6577_row5_col16" class="data row5 col16">0.023817</td>
<td id="T_a6577_row5_col17" class="data row5 col17">0.209549</td>
<td id="T_a6577_row5_col18" class="data row5 col18">36</td>
<td id="T_a6577_row5_col19" class="data row5 col19">90</td>
<td id="T_a6577_row5_col20" class="data row5 col20">208</td>
<td id="T_a6577_row5_col21" class="data row5 col21">43</td>
<td id="T_a6577_row5_col22" class="data row5 col22">133</td>
<td id="T_a6577_row5_col23" class="data row5 col23">244</td>
<td id="T_a6577_row5_col24" class="data row5 col24">377</td>
<td id="T_a6577_row5_col25" class="data row5 col25">7214</td>
<td id="T_a6577_row5_col26" class="data row5 col26">0.352785</td>
<td id="T_a6577_row5_col27" class="data row5 col27">0.092506</td>
<td id="T_a6577_row5_col28" class="data row5 col28">0.602147</td>
<td id="T_a6577_row5_col29" class="data row5 col29">0.920466</td>
<td id="T_a6577_row5_col30" class="data row5 col30">1.115085</td>
<td id="T_a6577_row5_col31" class="data row5 col31">1.048203</td>
<td id="T_a6577_row5_col32" class="data row5 col32">0.629057</td>
<td id="T_a6577_row5_col33" class="data row5 col33">1.417970</td>
<td id="T_a6577_row5_col34" class="data row5 col34">0.618447</td>
<td id="T_a6577_row5_col35" class="data row5 col35">1.113660</td>
<td id="T_a6577_row5_col36" class="data row5 col36">0.980490</td>
<td id="T_a6577_row5_col37" class="data row5 col37">Caucasian</td>
<td id="T_a6577_row5_col38" class="data row5 col38">Caucasian</td>
<td id="T_a6577_row5_col39" class="data row5 col39">Caucasian</td>
<td id="T_a6577_row5_col40" class="data row5 col40">Caucasian</td>
<td id="T_a6577_row5_col41" class="data row5 col41">Caucasian</td>
<td id="T_a6577_row5_col42" class="data row5 col42">Caucasian</td>
<td id="T_a6577_row5_col43" class="data row5 col43">Caucasian</td>
<td id="T_a6577_row5_col44" class="data row5 col44">Caucasian</td>
<td id="T_a6577_row5_col45" class="data row5 col45">Caucasian</td>
<td id="T_a6577_row5_col46" class="data row5 col46">Caucasian</td>
</tr>
<tr class="odd">
<td id="T_a6577_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">6</td>
<td id="T_a6577_row6_col0" class="data row6 col0">0</td>
<td id="T_a6577_row6_col1" class="data row6 col1">binary 0/1</td>
<td id="T_a6577_row6_col2" class="data row6 col2">3317</td>
<td id="T_a6577_row6_col3" class="data row6 col3">sex</td>
<td id="T_a6577_row6_col4" class="data row6 col4">Female</td>
<td id="T_a6577_row6_col5" class="data row6 col5">0.653763</td>
<td id="T_a6577_row6_col6" class="data row6 col6">0.608434</td>
<td id="T_a6577_row6_col7" class="data row6 col7">0.678930</td>
<td id="T_a6577_row6_col8" class="data row6 col8">0.242537</td>
<td id="T_a6577_row6_col9" class="data row6 col9">0.487310</td>
<td id="T_a6577_row6_col10" class="data row6 col10">0.321070</td>
<td id="T_a6577_row6_col11" class="data row6 col11">0.391566</td>
<td id="T_a6577_row6_col12" class="data row6 col12">0.757463</td>
<td id="T_a6577_row6_col13" class="data row6 col13">0.512690</td>
<td id="T_a6577_row6_col14" class="data row6 col14">591</td>
<td id="T_a6577_row6_col15" class="data row6 col15">804</td>
<td id="T_a6577_row6_col16" class="data row6 col16">0.178173</td>
<td id="T_a6577_row6_col17" class="data row6 col17">0.423656</td>
<td id="T_a6577_row6_col18" class="data row6 col18">288</td>
<td id="T_a6577_row6_col19" class="data row6 col19">195</td>
<td id="T_a6577_row6_col20" class="data row6 col20">609</td>
<td id="T_a6577_row6_col21" class="data row6 col21">303</td>
<td id="T_a6577_row6_col22" class="data row6 col22">498</td>
<td id="T_a6577_row6_col23" class="data row6 col23">897</td>
<td id="T_a6577_row6_col24" class="data row6 col24">1395</td>
<td id="T_a6577_row6_col25" class="data row6 col25">7214</td>
<td id="T_a6577_row6_col26" class="data row6 col26">0.356989</td>
<td id="T_a6577_row6_col27" class="data row6 col27">0.216801</td>
<td id="T_a6577_row6_col28" class="data row6 col28">0.904348</td>
<td id="T_a6577_row6_col29" class="data row6 col29">0.806925</td>
<td id="T_a6577_row6_col30" class="data row6 col30">1.336425</td>
<td id="T_a6577_row6_col31" class="data row6 col31">0.734738</td>
<td id="T_a6577_row6_col32" class="data row6 col32">0.990343</td>
<td id="T_a6577_row6_col33" class="data row6 col33">1.055810</td>
<td id="T_a6577_row6_col34" class="data row6 col34">0.967101</td>
<td id="T_a6577_row6_col35" class="data row6 col35">1.004633</td>
<td id="T_a6577_row6_col36" class="data row6 col36">1.130710</td>
<td id="T_a6577_row6_col37" class="data row6 col37">Male</td>
<td id="T_a6577_row6_col38" class="data row6 col38">Male</td>
<td id="T_a6577_row6_col39" class="data row6 col39">Male</td>
<td id="T_a6577_row6_col40" class="data row6 col40">Male</td>
<td id="T_a6577_row6_col41" class="data row6 col41">Male</td>
<td id="T_a6577_row6_col42" class="data row6 col42">Male</td>
<td id="T_a6577_row6_col43" class="data row6 col43">Male</td>
<td id="T_a6577_row6_col44" class="data row6 col44">Male</td>
<td id="T_a6577_row6_col45" class="data row6 col45">Male</td>
<td id="T_a6577_row6_col46" class="data row6 col46">Male</td>
</tr>
<tr class="even">
<td id="T_a6577_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">7</td>
<td id="T_a6577_row7_col0" class="data row7 col0">0</td>
<td id="T_a6577_row7_col1" class="data row7 col1">binary 0/1</td>
<td id="T_a6577_row7_col2" class="data row7 col2">3317</td>
<td id="T_a6577_row7_col3" class="data row7 col3">sex</td>
<td id="T_a6577_row7_col4" class="data row7 col4">Male</td>
<td id="T_a6577_row7_col5" class="data row7 col5">0.653721</td>
<td id="T_a6577_row7_col6" class="data row7 col6">0.629132</td>
<td id="T_a6577_row7_col7" class="data row7 col7">0.675799</td>
<td id="T_a6577_row7_col8" class="data row7 col8">0.330100</td>
<td id="T_a6577_row7_col9" class="data row7 col9">0.364637</td>
<td id="T_a6577_row7_col10" class="data row7 col10">0.324201</td>
<td id="T_a6577_row7_col11" class="data row7 col11">0.370868</td>
<td id="T_a6577_row7_col12" class="data row7 col12">0.669900</td>
<td id="T_a6577_row7_col13" class="data row7 col13">0.635363</td>
<td id="T_a6577_row7_col14" class="data row7 col14">2726</td>
<td id="T_a6577_row7_col15" class="data row7 col15">3093</td>
<td id="T_a6577_row7_col16" class="data row7 col16">0.821827</td>
<td id="T_a6577_row7_col17" class="data row7 col17">0.468465</td>
<td id="T_a6577_row7_col18" class="data row7 col18">994</td>
<td id="T_a6577_row7_col19" class="data row7 col19">1021</td>
<td id="T_a6577_row7_col20" class="data row7 col20">2072</td>
<td id="T_a6577_row7_col21" class="data row7 col21">1732</td>
<td id="T_a6577_row7_col22" class="data row7 col22">2753</td>
<td id="T_a6577_row7_col23" class="data row7 col23">3066</td>
<td id="T_a6577_row7_col24" class="data row7 col24">5819</td>
<td id="T_a6577_row7_col25" class="data row7 col25">7214</td>
<td id="T_a6577_row7_col26" class="data row7 col26">0.473105</td>
<td id="T_a6577_row7_col27" class="data row7 col27">1.000000</td>
<td id="T_a6577_row7_col28" class="data row7 col28">1.000000</td>
<td id="T_a6577_row7_col29" class="data row7 col29">1.000000</td>
<td id="T_a6577_row7_col30" class="data row7 col30">1.000000</td>
<td id="T_a6577_row7_col31" class="data row7 col31">1.000000</td>
<td id="T_a6577_row7_col32" class="data row7 col32">1.000000</td>
<td id="T_a6577_row7_col33" class="data row7 col33">1.000000</td>
<td id="T_a6577_row7_col34" class="data row7 col34">1.000000</td>
<td id="T_a6577_row7_col35" class="data row7 col35">1.000000</td>
<td id="T_a6577_row7_col36" class="data row7 col36">1.000000</td>
<td id="T_a6577_row7_col37" class="data row7 col37">Male</td>
<td id="T_a6577_row7_col38" class="data row7 col38">Male</td>
<td id="T_a6577_row7_col39" class="data row7 col39">Male</td>
<td id="T_a6577_row7_col40" class="data row7 col40">Male</td>
<td id="T_a6577_row7_col41" class="data row7 col41">Male</td>
<td id="T_a6577_row7_col42" class="data row7 col42">Male</td>
<td id="T_a6577_row7_col43" class="data row7 col43">Male</td>
<td id="T_a6577_row7_col44" class="data row7 col44">Male</td>
<td id="T_a6577_row7_col45" class="data row7 col45">Male</td>
<td id="T_a6577_row7_col46" class="data row7 col46">Male</td>
</tr>
<tr class="odd">
<td id="T_a6577_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">8</td>
<td id="T_a6577_row8_col0" class="data row8 col0">0</td>
<td id="T_a6577_row8_col1" class="data row8 col1">binary 0/1</td>
<td id="T_a6577_row8_col2" class="data row8 col2">3317</td>
<td id="T_a6577_row8_col3" class="data row8 col3">age_cat</td>
<td id="T_a6577_row8_col4" class="data row8 col4">25 - 45</td>
<td id="T_a6577_row8_col5" class="data row8 col5">0.647846</td>
<td id="T_a6577_row8_col6" class="data row8 col6">0.626257</td>
<td id="T_a6577_row8_col7" class="data row8 col7">0.666216</td>
<td id="T_a6577_row8_col8" class="data row8 col8">0.323112</td>
<td id="T_a6577_row8_col9" class="data row8 col9">0.385135</td>
<td id="T_a6577_row8_col10" class="data row8 col10">0.333784</td>
<td id="T_a6577_row8_col11" class="data row8 col11">0.373743</td>
<td id="T_a6577_row8_col12" class="data row8 col12">0.676888</td>
<td id="T_a6577_row8_col13" class="data row8 col13">0.614865</td>
<td id="T_a6577_row8_col14" class="data row8 col14">1924</td>
<td id="T_a6577_row8_col15" class="data row8 col15">2185</td>
<td id="T_a6577_row8_col16" class="data row8 col16">0.580042</td>
<td id="T_a6577_row8_col17" class="data row8 col17">0.468240</td>
<td id="T_a6577_row8_col18" class="data row8 col18">741</td>
<td id="T_a6577_row8_col19" class="data row8 col19">706</td>
<td id="T_a6577_row8_col20" class="data row8 col20">1479</td>
<td id="T_a6577_row8_col21" class="data row8 col21">1183</td>
<td id="T_a6577_row8_col22" class="data row8 col22">1889</td>
<td id="T_a6577_row8_col23" class="data row8 col23">2220</td>
<td id="T_a6577_row8_col24" class="data row8 col24">4109</td>
<td id="T_a6577_row8_col25" class="data row8 col25">7214</td>
<td id="T_a6577_row8_col26" class="data row8 col26">0.459723</td>
<td id="T_a6577_row8_col27" class="data row8 col27">1.000000</td>
<td id="T_a6577_row8_col28" class="data row8 col28">1.000000</td>
<td id="T_a6577_row8_col29" class="data row8 col29">1.000000</td>
<td id="T_a6577_row8_col30" class="data row8 col30">1.000000</td>
<td id="T_a6577_row8_col31" class="data row8 col31">1.000000</td>
<td id="T_a6577_row8_col32" class="data row8 col32">1.000000</td>
<td id="T_a6577_row8_col33" class="data row8 col33">1.000000</td>
<td id="T_a6577_row8_col34" class="data row8 col34">1.000000</td>
<td id="T_a6577_row8_col35" class="data row8 col35">1.000000</td>
<td id="T_a6577_row8_col36" class="data row8 col36">1.000000</td>
<td id="T_a6577_row8_col37" class="data row8 col37">25 - 45</td>
<td id="T_a6577_row8_col38" class="data row8 col38">25 - 45</td>
<td id="T_a6577_row8_col39" class="data row8 col39">25 - 45</td>
<td id="T_a6577_row8_col40" class="data row8 col40">25 - 45</td>
<td id="T_a6577_row8_col41" class="data row8 col41">25 - 45</td>
<td id="T_a6577_row8_col42" class="data row8 col42">25 - 45</td>
<td id="T_a6577_row8_col43" class="data row8 col43">25 - 45</td>
<td id="T_a6577_row8_col44" class="data row8 col44">25 - 45</td>
<td id="T_a6577_row8_col45" class="data row8 col45">25 - 45</td>
<td id="T_a6577_row8_col46" class="data row8 col46">25 - 45</td>
</tr>
<tr class="even">
<td id="T_a6577_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">9</td>
<td id="T_a6577_row9_col0" class="data row9 col0">0</td>
<td id="T_a6577_row9_col1" class="data row9 col1">binary 0/1</td>
<td id="T_a6577_row9_col2" class="data row9 col2">3317</td>
<td id="T_a6577_row9_col3" class="data row9 col3">age_cat</td>
<td id="T_a6577_row9_col4" class="data row9 col4">Greater than 45</td>
<td id="T_a6577_row9_col5" class="data row9 col5">0.704315</td>
<td id="T_a6577_row9_col6" class="data row9 col6">0.427711</td>
<td id="T_a6577_row9_col7" class="data row9 col7">0.832096</td>
<td id="T_a6577_row9_col8" class="data row9 col8">0.241117</td>
<td id="T_a6577_row9_col9" class="data row9 col9">0.459391</td>
<td id="T_a6577_row9_col10" class="data row9 col10">0.167904</td>
<td id="T_a6577_row9_col11" class="data row9 col11">0.572289</td>
<td id="T_a6577_row9_col12" class="data row9 col12">0.758883</td>
<td id="T_a6577_row9_col13" class="data row9 col13">0.540609</td>
<td id="T_a6577_row9_col14" class="data row9 col14">394</td>
<td id="T_a6577_row9_col15" class="data row9 col15">1182</td>
<td id="T_a6577_row9_col16" class="data row9 col16">0.118782</td>
<td id="T_a6577_row9_col17" class="data row9 col17">0.250000</td>
<td id="T_a6577_row9_col18" class="data row9 col18">181</td>
<td id="T_a6577_row9_col19" class="data row9 col19">285</td>
<td id="T_a6577_row9_col20" class="data row9 col20">897</td>
<td id="T_a6577_row9_col21" class="data row9 col21">213</td>
<td id="T_a6577_row9_col22" class="data row9 col22">498</td>
<td id="T_a6577_row9_col23" class="data row9 col23">1078</td>
<td id="T_a6577_row9_col24" class="data row9 col24">1576</td>
<td id="T_a6577_row9_col25" class="data row9 col25">7214</td>
<td id="T_a6577_row9_col26" class="data row9 col26">0.315990</td>
<td id="T_a6577_row9_col27" class="data row9 col27">0.204782</td>
<td id="T_a6577_row9_col28" class="data row9 col28">0.533914</td>
<td id="T_a6577_row9_col29" class="data row9 col29">0.879232</td>
<td id="T_a6577_row9_col30" class="data row9 col30">1.192804</td>
<td id="T_a6577_row9_col31" class="data row9 col31">0.746232</td>
<td id="T_a6577_row9_col32" class="data row9 col32">0.503031</td>
<td id="T_a6577_row9_col33" class="data row9 col33">1.531238</td>
<td id="T_a6577_row9_col34" class="data row9 col34">0.682963</td>
<td id="T_a6577_row9_col35" class="data row9 col35">1.248989</td>
<td id="T_a6577_row9_col36" class="data row9 col36">1.121136</td>
<td id="T_a6577_row9_col37" class="data row9 col37">25 - 45</td>
<td id="T_a6577_row9_col38" class="data row9 col38">25 - 45</td>
<td id="T_a6577_row9_col39" class="data row9 col39">25 - 45</td>
<td id="T_a6577_row9_col40" class="data row9 col40">25 - 45</td>
<td id="T_a6577_row9_col41" class="data row9 col41">25 - 45</td>
<td id="T_a6577_row9_col42" class="data row9 col42">25 - 45</td>
<td id="T_a6577_row9_col43" class="data row9 col43">25 - 45</td>
<td id="T_a6577_row9_col44" class="data row9 col44">25 - 45</td>
<td id="T_a6577_row9_col45" class="data row9 col45">25 - 45</td>
<td id="T_a6577_row9_col46" class="data row9 col46">25 - 45</td>
</tr>
<tr class="odd">
<td id="T_a6577_level0_row10" class="row_heading level0 row10" data-quarto-table-cell-role="th">10</td>
<td id="T_a6577_row10_col0" class="data row10 col0">0</td>
<td id="T_a6577_row10_col1" class="data row10 col1">binary 0/1</td>
<td id="T_a6577_row10_col2" class="data row10 col2">3317</td>
<td id="T_a6577_row10_col3" class="data row10 col3">age_cat</td>
<td id="T_a6577_row10_col4" class="data row10 col4">Less than 25</td>
<td id="T_a6577_row10_col5" class="data row10 col5">0.617397</td>
<td id="T_a6577_row10_col6" class="data row10 col6">0.739583</td>
<td id="T_a6577_row10_col7" class="data row10 col7">0.458647</td>
<td id="T_a6577_row10_col8" class="data row10 col8">0.424528</td>
<td id="T_a6577_row10_col9" class="data row10 col9">0.360360</td>
<td id="T_a6577_row10_col10" class="data row10 col10">0.541353</td>
<td id="T_a6577_row10_col11" class="data row10 col11">0.260417</td>
<td id="T_a6577_row10_col12" class="data row10 col12">0.575472</td>
<td id="T_a6577_row10_col13" class="data row10 col13">0.639640</td>
<td id="T_a6577_row10_col14" class="data row10 col14">999</td>
<td id="T_a6577_row10_col15" class="data row10 col15">530</td>
<td id="T_a6577_row10_col16" class="data row10 col16">0.301176</td>
<td id="T_a6577_row10_col17" class="data row10 col17">0.653368</td>
<td id="T_a6577_row10_col18" class="data row10 col18">360</td>
<td id="T_a6577_row10_col19" class="data row10 col19">225</td>
<td id="T_a6577_row10_col20" class="data row10 col20">305</td>
<td id="T_a6577_row10_col21" class="data row10 col21">639</td>
<td id="T_a6577_row10_col22" class="data row10 col22">864</td>
<td id="T_a6577_row10_col23" class="data row10 col23">665</td>
<td id="T_a6577_row10_col24" class="data row10 col24">1529</td>
<td id="T_a6577_row10_col25" class="data row10 col25">7214</td>
<td id="T_a6577_row10_col26" class="data row10 col26">0.565075</td>
<td id="T_a6577_row10_col27" class="data row10 col27">0.519231</td>
<td id="T_a6577_row10_col28" class="data row10 col28">1.395369</td>
<td id="T_a6577_row10_col29" class="data row10 col29">1.040293</td>
<td id="T_a6577_row10_col30" class="data row10 col30">0.935673</td>
<td id="T_a6577_row10_col31" class="data row10 col31">1.313873</td>
<td id="T_a6577_row10_col32" class="data row10 col32">1.621868</td>
<td id="T_a6577_row10_col33" class="data row10 col33">0.696781</td>
<td id="T_a6577_row10_col34" class="data row10 col34">1.180958</td>
<td id="T_a6577_row10_col35" class="data row10 col35">0.688435</td>
<td id="T_a6577_row10_col36" class="data row10 col36">0.850173</td>
<td id="T_a6577_row10_col37" class="data row10 col37">25 - 45</td>
<td id="T_a6577_row10_col38" class="data row10 col38">25 - 45</td>
<td id="T_a6577_row10_col39" class="data row10 col39">25 - 45</td>
<td id="T_a6577_row10_col40" class="data row10 col40">25 - 45</td>
<td id="T_a6577_row10_col41" class="data row10 col41">25 - 45</td>
<td id="T_a6577_row10_col42" class="data row10 col42">25 - 45</td>
<td id="T_a6577_row10_col43" class="data row10 col43">25 - 45</td>
<td id="T_a6577_row10_col44" class="data row10 col44">25 - 45</td>
<td id="T_a6577_row10_col45" class="data row10 col45">25 - 45</td>
<td id="T_a6577_row10_col46" class="data row10 col46">25 - 45</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p><br></p>
<p>As before, we can now use this matrix for creating plots in order to visualize disparities between races. In the next plot, we are comparing our reference group to all other races, using the False Positive values (as these can be considered the most problematic in this application).</p>
<p>The size of the boxes indicates the group size, the color and the according scale indicate the disparity between the compared groups. The plot shows that compared to the Caucasian reference group, the False Positive rate for African-American defendants is nearly two times higher, indicating a clear sign of unfairness/bias.</p>
<div id="d6af0ffa" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>aqp.plot_disparity(bdf, group_metric<span class="op">=</span><span class="st">'fpr_disparity'</span>, attribute_name<span class="op">=</span><span class="st">'race'</span>, significance_alpha<span class="op">=</span><span class="fl">0.05</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-14-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="index_files/figure-html/cell-14-output-1.png" width="412" height="416" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>As an intermediate result, the aequitas-library works well for calculating key bias and fairness metrics and includes helpful functions for intuitively plotting the results. As this first part of the tutorial was aiming on giving a first glance at the data, it was largely built on the aequitas documentation. In the next part, we are shifting the focus away from bias detection and more towards bias mitigation. The second part introcudes a Neural Network that is trained for predicting recidivism and later tuned in order to find the optimal number of units and dropout rate.</p>
</section>
</section>
<section id="part-2-neural-network-classifier-for-fair-data-distribution" class="level1">
<h1>Part 2: Neural Network Classifier for Fair Data Distribution</h1>
<section id="loading-the-data" class="level3">
<h3 class="anchored" data-anchor-id="loading-the-data">Loading the data</h3>
<p>Not that in this version of the data, some more variables/alternative labels are included:</p>
<ul>
<li><p><strong>two_year_recid</strong>, indicating if the person has recidivated within two years</p></li>
<li><p><strong>target</strong>, the binary risk score</p></li>
<li><p>The charge degree of defendants where F: felony and M: misdemeanor</p></li>
<li><p><strong>juv_fel_count</strong>, containing the number of juvenile felonies</p></li>
<li><p><strong>juv_misd_count</strong>, containing the number of juvenile misdemeanors</p></li>
<li><p><strong>juv_other_count</strong>, containing the number of prior juvenile convictions which are not considered felonies or misdemeanors</p></li>
<li><p><strong>priors_count</strong>, containing the number of prior crimes committed</p></li>
</ul>
<div id="70e9066a" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>df_compas <span class="op">=</span> pd.read_csv(<span class="st">"https://raw.githubusercontent.com/jurjoroa/DeepLearning_bias_NLP/JorgeRoa/data_set.csv"</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>df_compas.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sex</th>
<th data-quarto-table-cell-role="th">age</th>
<th data-quarto-table-cell-role="th">race</th>
<th data-quarto-table-cell-role="th">juv_fel_count</th>
<th data-quarto-table-cell-role="th">juv_misd_count</th>
<th data-quarto-table-cell-role="th">juv_other_count</th>
<th data-quarto-table-cell-role="th">priors_count</th>
<th data-quarto-table-cell-role="th">charge_degree</th>
<th data-quarto-table-cell-role="th">target</th>
<th data-quarto-table-cell-role="th">two_year_recid</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>34</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>24</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>23</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>41</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>14</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0</td>
<td>39</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p><br></p>
<p>First, we are writing some functions that are later used for creating the accuracy and loss plots.</p>
<p><br></p>
</section>
</section>
<section id="metric-plot" class="level1">
<h1>Metric Plot</h1>
<div id="a6562ae4" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_metric(history, metric):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    train_metrics <span class="op">=</span> history.history[metric]</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    val_metrics <span class="op">=</span> history.history[<span class="st">'val_'</span><span class="op">+</span>metric]</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(train_metrics) <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, train_metrics, <span class="st">'bo-'</span>,marker<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, val_metrics, <span class="st">'ro-'</span>,marker<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Training and validation '</span><span class="op">+</span> metric)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Epochs"</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(metric)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    plt.legend([<span class="st">"train_"</span><span class="op">+</span>metric, <span class="st">'val_'</span><span class="op">+</span>metric])</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p>Next, we are defining function that we can use to fit our feed forward neural network. We are using ReLU-activation functions for the first three layers and a sigmoid activation function for the output layer (since we are dealing with a classification problem). Moreover, we are using binary crossentropy as our loss function and Adaptive Moment Estimation for minimizing the loss function. We tried to experiment with number of layers, the activation functions, and the droupout rates, but received quite similar results.</p>
<div id="4be65d88" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> nn_classifier(n_features):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> Input(shape <span class="op">=</span> (n_features,))</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    dense1 <span class="op">=</span> Dense(<span class="dv">40</span>, activation <span class="op">=</span> <span class="st">'relu'</span>)(inputs)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    dropout1 <span class="op">=</span> Dropout(<span class="fl">.4</span>)(dense1)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    dense2 <span class="op">=</span> Dense(<span class="dv">40</span>, activation <span class="op">=</span> <span class="st">'relu'</span>)(dropout1)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    dropout2 <span class="op">=</span> Dropout(<span class="fl">.3</span>)(dense2)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    dense3 <span class="op">=</span> Dense(<span class="dv">32</span>, activation <span class="op">=</span> <span class="st">'relu'</span>)(dropout2)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    dropout3 <span class="op">=</span> Dropout(<span class="fl">.3</span>)(dense3)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> Dense(<span class="dv">1</span>, activation <span class="op">=</span> <span class="st">'sigmoid'</span>)(dropout3)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Model(inputs <span class="op">=</span> [inputs], outputs <span class="op">=</span> [outputs])</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    opt <span class="op">=</span> Adam(learning_rate<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(loss <span class="op">=</span> <span class="st">'binary_crossentropy'</span>, optimizer <span class="op">=</span> opt, metrics <span class="op">=</span> [<span class="st">'accuracy'</span>])</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p>Before fitting our defined model, we need to conduct some more data manipulation steps and define our predictor and target features. First, we one hot encode categorial variables (here: the charge degree). Second, we exclude sex and race from the predictors. We define our target variable to be the binary score whether a defendant committed crime within two years after the first incident. Additionally, the data is normalized using MinMaxScaler().</p>
<p><br></p>
<div id="5307d3f5" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># One Hot encoding for categorical variable</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>charge_degree <span class="op">=</span> pd.get_dummies(df_compas[<span class="st">'charge_degree'</span>])</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>charge_degree.columns <span class="op">=</span> [<span class="st">'charge_degree_'</span> <span class="op">+</span> <span class="bu">str</span>(x) <span class="cf">for</span> x <span class="kw">in</span> charge_degree.columns]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>df_compas <span class="op">=</span> pd.concat([df_compas, charge_degree], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>df_compas.drop([<span class="st">'charge_degree'</span>], axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_compas.copy()</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Sensible attributes (we want to exclude them from training to avoid "intentional" bias)</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>Z_race <span class="op">=</span> X.pop(<span class="st">'race'</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>Z_sex <span class="op">=</span> X.pop(<span class="st">'sex'</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>Z_data <span class="op">=</span> {<span class="st">'race'</span>: Z_race, <span class="st">'sex'</span>: Z_sex}</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> pd.concat(Z_data, axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Target: COMPAS risk prediction, 1 = Risk of recidivism, 0 = No risk</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> X.pop(<span class="st">'target'</span>)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Actual observed criminal activity reported within 2 years from compas score,</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 1 = the person committed a crime</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 0 = Not a recidivist</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>y_factual <span class="op">=</span> X.pop(<span class="st">'two_year_recid'</span>)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>X.head()</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">7</span>)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test, y_factual_train, y_factual_test, Z_train, Z_test <span class="op">=</span> train_test_split(X, y, y_factual, Z, test_size <span class="op">=</span> <span class="fl">0.4</span>,</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>                                                                    stratify <span class="op">=</span> y, random_state <span class="op">=</span> <span class="dv">7</span>)</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize the data</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> MinMaxScaler().fit(X_train)</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>scale_df <span class="op">=</span> <span class="kw">lambda</span> df, scaler: pd.DataFrame(scaler.transform(df), columns <span class="op">=</span> df.columns, index <span class="op">=</span> df.index)</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X_train.pipe(scale_df, scaler)</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> X_test.pipe(scale_df, scaler)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p>Now, we can fit our model! We are training over 50 epochs.</p>
<p><br></p>
<div id="f6f9e830" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">7</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>clf_1 <span class="op">=</span> nn_classifier(n_features <span class="op">=</span> X_train.shape[<span class="dv">1</span>])</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> clf_1.fit(X_train, y_train.values, epochs <span class="op">=</span> <span class="dv">50</span>, verbose <span class="op">=</span> <span class="dv">2</span>,validation_data <span class="op">=</span> (X_test, y_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/50
116/116 - 1s - 6ms/step - accuracy: 0.5512 - loss: 0.6829 - val_accuracy: 0.5890 - val_loss: 0.6623
Epoch 2/50
116/116 - 0s - 868us/step - accuracy: 0.6266 - loss: 0.6455 - val_accuracy: 0.7053 - val_loss: 0.5914
Epoch 3/50
116/116 - 0s - 879us/step - accuracy: 0.6827 - loss: 0.5989 - val_accuracy: 0.7272 - val_loss: 0.5472
Epoch 4/50
116/116 - 0s - 866us/step - accuracy: 0.6967 - loss: 0.5773 - val_accuracy: 0.7297 - val_loss: 0.5403
Epoch 5/50
116/116 - 0s - 854us/step - accuracy: 0.7095 - loss: 0.5652 - val_accuracy: 0.7260 - val_loss: 0.5344
Epoch 6/50
116/116 - 0s - 871us/step - accuracy: 0.7187 - loss: 0.5539 - val_accuracy: 0.7264 - val_loss: 0.5326
Epoch 7/50
116/116 - 0s - 867us/step - accuracy: 0.7266 - loss: 0.5472 - val_accuracy: 0.7272 - val_loss: 0.5263
Epoch 8/50
116/116 - 0s - 831us/step - accuracy: 0.7317 - loss: 0.5428 - val_accuracy: 0.7289 - val_loss: 0.5244
Epoch 9/50
116/116 - 0s - 872us/step - accuracy: 0.7290 - loss: 0.5427 - val_accuracy: 0.7321 - val_loss: 0.5249
Epoch 10/50
116/116 - 0s - 856us/step - accuracy: 0.7331 - loss: 0.5333 - val_accuracy: 0.7252 - val_loss: 0.5282
Epoch 11/50
116/116 - 0s - 1ms/step - accuracy: 0.7341 - loss: 0.5379 - val_accuracy: 0.7285 - val_loss: 0.5220
Epoch 12/50
116/116 - 0s - 859us/step - accuracy: 0.7358 - loss: 0.5370 - val_accuracy: 0.7289 - val_loss: 0.5209
Epoch 13/50
116/116 - 0s - 863us/step - accuracy: 0.7377 - loss: 0.5343 - val_accuracy: 0.7325 - val_loss: 0.5217
Epoch 14/50
116/116 - 0s - 906us/step - accuracy: 0.7322 - loss: 0.5352 - val_accuracy: 0.7305 - val_loss: 0.5209
Epoch 15/50
116/116 - 0s - 884us/step - accuracy: 0.7404 - loss: 0.5331 - val_accuracy: 0.7260 - val_loss: 0.5205
Epoch 16/50
116/116 - 0s - 867us/step - accuracy: 0.7301 - loss: 0.5321 - val_accuracy: 0.7264 - val_loss: 0.5209
Epoch 17/50
116/116 - 0s - 856us/step - accuracy: 0.7336 - loss: 0.5303 - val_accuracy: 0.7321 - val_loss: 0.5179
Epoch 18/50
116/116 - 0s - 865us/step - accuracy: 0.7423 - loss: 0.5270 - val_accuracy: 0.7260 - val_loss: 0.5181
Epoch 19/50
116/116 - 0s - 864us/step - accuracy: 0.7328 - loss: 0.5264 - val_accuracy: 0.7256 - val_loss: 0.5206
Epoch 20/50
116/116 - 0s - 901us/step - accuracy: 0.7409 - loss: 0.5274 - val_accuracy: 0.7276 - val_loss: 0.5191
Epoch 21/50
116/116 - 0s - 856us/step - accuracy: 0.7333 - loss: 0.5299 - val_accuracy: 0.7309 - val_loss: 0.5188
Epoch 22/50
116/116 - 0s - 851us/step - accuracy: 0.7407 - loss: 0.5304 - val_accuracy: 0.7309 - val_loss: 0.5189
Epoch 23/50
116/116 - 0s - 937us/step - accuracy: 0.7360 - loss: 0.5321 - val_accuracy: 0.7325 - val_loss: 0.5186
Epoch 24/50
116/116 - 0s - 923us/step - accuracy: 0.7404 - loss: 0.5302 - val_accuracy: 0.7362 - val_loss: 0.5191
Epoch 25/50
116/116 - 0s - 861us/step - accuracy: 0.7450 - loss: 0.5291 - val_accuracy: 0.7285 - val_loss: 0.5189
Epoch 26/50
116/116 - 0s - 861us/step - accuracy: 0.7415 - loss: 0.5274 - val_accuracy: 0.7301 - val_loss: 0.5203
Epoch 27/50
116/116 - 0s - 836us/step - accuracy: 0.7409 - loss: 0.5289 - val_accuracy: 0.7289 - val_loss: 0.5182
Epoch 28/50
116/116 - 0s - 859us/step - accuracy: 0.7415 - loss: 0.5239 - val_accuracy: 0.7317 - val_loss: 0.5177
Epoch 29/50
116/116 - 0s - 864us/step - accuracy: 0.7374 - loss: 0.5290 - val_accuracy: 0.7337 - val_loss: 0.5180
Epoch 30/50
116/116 - 0s - 846us/step - accuracy: 0.7347 - loss: 0.5276 - val_accuracy: 0.7276 - val_loss: 0.5176
Epoch 31/50
116/116 - 0s - 842us/step - accuracy: 0.7366 - loss: 0.5224 - val_accuracy: 0.7366 - val_loss: 0.5205
Epoch 32/50
116/116 - 0s - 874us/step - accuracy: 0.7398 - loss: 0.5266 - val_accuracy: 0.7321 - val_loss: 0.5173
Epoch 33/50
116/116 - 0s - 846us/step - accuracy: 0.7415 - loss: 0.5247 - val_accuracy: 0.7305 - val_loss: 0.5164
Epoch 34/50
116/116 - 0s - 888us/step - accuracy: 0.7444 - loss: 0.5266 - val_accuracy: 0.7289 - val_loss: 0.5184
Epoch 35/50
116/116 - 0s - 821us/step - accuracy: 0.7320 - loss: 0.5333 - val_accuracy: 0.7272 - val_loss: 0.5194
Epoch 36/50
116/116 - 0s - 861us/step - accuracy: 0.7388 - loss: 0.5293 - val_accuracy: 0.7280 - val_loss: 0.5181
Epoch 37/50
116/116 - 0s - 845us/step - accuracy: 0.7366 - loss: 0.5277 - val_accuracy: 0.7301 - val_loss: 0.5171
Epoch 38/50
116/116 - 0s - 851us/step - accuracy: 0.7434 - loss: 0.5236 - val_accuracy: 0.7317 - val_loss: 0.5188
Epoch 39/50
116/116 - 0s - 846us/step - accuracy: 0.7366 - loss: 0.5286 - val_accuracy: 0.7333 - val_loss: 0.5169
Epoch 40/50
116/116 - 0s - 847us/step - accuracy: 0.7352 - loss: 0.5286 - val_accuracy: 0.7329 - val_loss: 0.5165
Epoch 41/50
116/116 - 0s - 845us/step - accuracy: 0.7409 - loss: 0.5232 - val_accuracy: 0.7346 - val_loss: 0.5195
Epoch 42/50
116/116 - 0s - 891us/step - accuracy: 0.7344 - loss: 0.5296 - val_accuracy: 0.7256 - val_loss: 0.5189
Epoch 43/50
116/116 - 0s - 837us/step - accuracy: 0.7420 - loss: 0.5231 - val_accuracy: 0.7289 - val_loss: 0.5168
Epoch 44/50
116/116 - 0s - 847us/step - accuracy: 0.7417 - loss: 0.5267 - val_accuracy: 0.7325 - val_loss: 0.5171
Epoch 45/50
116/116 - 0s - 865us/step - accuracy: 0.7363 - loss: 0.5272 - val_accuracy: 0.7346 - val_loss: 0.5188
Epoch 46/50
116/116 - 0s - 880us/step - accuracy: 0.7366 - loss: 0.5264 - val_accuracy: 0.7341 - val_loss: 0.5177
Epoch 47/50
116/116 - 0s - 839us/step - accuracy: 0.7398 - loss: 0.5246 - val_accuracy: 0.7313 - val_loss: 0.5166
Epoch 48/50
116/116 - 0s - 846us/step - accuracy: 0.7442 - loss: 0.5270 - val_accuracy: 0.7346 - val_loss: 0.5184
Epoch 49/50
116/116 - 0s - 861us/step - accuracy: 0.7371 - loss: 0.5256 - val_accuracy: 0.7289 - val_loss: 0.5173
Epoch 50/50
116/116 - 0s - 848us/step - accuracy: 0.7444 - loss: 0.5214 - val_accuracy: 0.7256 - val_loss: 0.5211</code></pre>
</div>
</div>
<p><br></p>
<p>From the output, we can already tell that the model improved over epochs, as loss decreased and accuracy increased. Let’s use our predefined plot_metric function to view the results:</p>
<p><br></p>
<div id="65454bbf" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>plot_metric(history, <span class="st">'loss'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-20-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="index_files/figure-html/cell-20-output-1.png" width="640" height="479" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p><br></p>
<div id="f16a5f7e" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>clf_1.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>, loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>plot_metric(history, <span class="st">'accuracy'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-21-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="index_files/figure-html/cell-21-output-1.png" width="627" height="479" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p><br></p>
<p>As we can se, the predicitions quickly approach an accuracy value of around 70 to 75 per cent in both training and validation. After 50 epochs, we are left with accuracy values around 75%. Next, we are adapting our NN-classifier using keras and try to find the optimal hyperparameters and see whether we are able to improve the performance. For that purpose, we are adapting the classifier and experiment with varying values for the number of units in each layer, the dropout rates, and the learning rate.</p>
<p><br></p>
<div id="d52e5ad6" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> nn_classifier(hp, n_features):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> Input(shape<span class="op">=</span>(n_features,))</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> inputs</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Tuning the number of units in the first dense layer</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    hp_units1 <span class="op">=</span> hp.Int(<span class="st">'units1'</span>, min_value<span class="op">=</span><span class="dv">32</span>, max_value<span class="op">=</span><span class="dv">512</span>, step<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dense(units<span class="op">=</span>hp_units1, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    hp_dropout1 <span class="op">=</span> hp.Float(<span class="st">'dropout1'</span>, min_value<span class="op">=</span><span class="fl">0.0</span>, max_value<span class="op">=</span><span class="fl">0.5</span>, step<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dropout(rate<span class="op">=</span>hp_dropout1)(x)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Tuning the number of units in the second dense layer</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    hp_units2 <span class="op">=</span> hp.Int(<span class="st">'units2'</span>, min_value<span class="op">=</span><span class="dv">32</span>, max_value<span class="op">=</span><span class="dv">512</span>, step<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dense(units<span class="op">=</span>hp_units2, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    hp_dropout2 <span class="op">=</span> hp.Float(<span class="st">'dropout2'</span>, min_value<span class="op">=</span><span class="fl">0.0</span>, max_value<span class="op">=</span><span class="fl">0.5</span>, step<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dropout(rate<span class="op">=</span>hp_dropout2)(x)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Tuning the number of units in the third dense layer</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    hp_units3 <span class="op">=</span> hp.Int(<span class="st">'units3'</span>, min_value<span class="op">=</span><span class="dv">32</span>, max_value<span class="op">=</span><span class="dv">512</span>, step<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dense(units<span class="op">=</span>hp_units3, activation<span class="op">=</span><span class="st">'relu'</span>)(x)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>    hp_dropout3 <span class="op">=</span> hp.Float(<span class="st">'dropout3'</span>, min_value<span class="op">=</span><span class="fl">0.0</span>, max_value<span class="op">=</span><span class="fl">0.5</span>, step<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> Dropout(rate<span class="op">=</span>hp_dropout3)(x)</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>)(x)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Tuning the learning rate for the optimizer</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    hp_learning_rate <span class="op">=</span> hp.Choice(<span class="st">'learning_rate'</span>, values<span class="op">=</span>[<span class="fl">1e-2</span>, <span class="fl">1e-3</span>, <span class="fl">1e-4</span>])</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span>Adam(learning_rate<span class="op">=</span>hp_learning_rate),</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>                  loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>                  metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<div id="f57c93bf" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_model(hp):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> nn_classifier(hp, n_features<span class="op">=</span>X_train.shape[<span class="dv">1</span>])</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate the tuner</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>tuner <span class="op">=</span> kt.Hyperband(</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    build_model,</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    objective<span class="op">=</span><span class="st">'val_accuracy'</span>,</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    max_epochs<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    directory<span class="op">=</span><span class="st">'keras_tuner'</span>,</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    project_name<span class="op">=</span><span class="st">'nn_tuning'</span>,</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    factor<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    hyperband_iterations<span class="op">=</span><span class="dv">2</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Reloading Tuner from keras_tuner/nn_tuning/tuner0.json</code></pre>
</div>
</div>
<p><br></p>
<p>The next chunk takes some time to execute. It used the previously defined tuner for finding the optimal hyperparameter values. We also included early stopping in case that the validation loss is minimized early.</p>
<p><br></p>
<div id="37da4354" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a callback to stop training early after reaching a certain value for the validation loss</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>stop_early <span class="op">=</span> tf.keras.callbacks.EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Execute the hyperparameter search</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>tuner.search(X_train, y_train, epochs<span class="op">=</span><span class="dv">50</span>, validation_data<span class="op">=</span>(X_test, y_test), callbacks<span class="op">=</span>[stop_early])</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the optimal hyperparameters</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>best_hps <span class="op">=</span> tuner.get_best_hyperparameters(num_trials<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"""</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="ss">The hyperparameter search is complete. The optimal number of units in the first densely-connected</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="ss">layer is </span><span class="sc">{</span>best_hps<span class="sc">.</span>get(<span class="st">'units1'</span>)<span class="sc">}</span><span class="ss">, in the second layer is </span><span class="sc">{</span>best_hps<span class="sc">.</span>get(<span class="st">'units2'</span>)<span class="sc">}</span><span class="ss">, and in the third layer is </span><span class="sc">{</span>best_hps<span class="sc">.</span>get(<span class="st">'units3'</span>)<span class="sc">}</span><span class="ss">.</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="ss">The optimal dropout rates are </span><span class="sc">{</span>best_hps<span class="sc">.</span>get(<span class="st">'dropout1'</span>)<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>best_hps<span class="sc">.</span>get(<span class="st">'dropout2'</span>)<span class="sc">}</span><span class="ss">, and </span><span class="sc">{</span>best_hps<span class="sc">.</span>get(<span class="st">'dropout3'</span>)<span class="sc">}</span><span class="ss">.</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="ss">The optimal learning rate for the optimizer is </span><span class="sc">{</span>best_hps<span class="sc">.</span>get(<span class="st">'learning_rate'</span>)<span class="sc">}</span><span class="ss">.</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="ss">"""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
The hyperparameter search is complete. The optimal number of units in the first densely-connected
layer is 512, in the second layer is 128, and in the third layer is 416.
The optimal dropout rates are 0.4, 0.1, and 0.2.
The optimal learning rate for the optimizer is 0.01.
</code></pre>
</div>
</div>
<p><br></p>
<p>As the previous cell’s output shows, we received optimal values for the number of units in each layer, the dropout rates, and the Adam opimizer’s learning rate. Ultimately, we fit our original model with the optimal hyperparameters. As we can see, the performance stays relatively constant in comparison with our previous model.</p>
<p><br></p>
<div id="2e1f460a" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build the model with the optimal hyperparameters and train it on the data</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tuner.hypermodel.build(best_hps)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">50</span>, validation_data<span class="op">=</span>(X_test, y_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1:08 591ms/step - accuracy: 0.4062 - loss: 0.6967 32/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6064 - loss: 0.6360     62/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6420 - loss: 0.6107 93/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6554 - loss: 0.6002116/116 ━━━━━━━━━━━━━━━━━━━━ 1s 3ms/step - accuracy: 0.6630 - loss: 0.5942 - val_accuracy: 0.7248 - val_loss: 0.5341
Epoch 2/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6562 - loss: 0.5527 25/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7183 - loss: 0.5441  50/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7102 - loss: 0.5478 75/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7099 - loss: 0.5497101/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7117 - loss: 0.5495116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7132 - loss: 0.5491 - val_accuracy: 0.7240 - val_loss: 0.5362
Epoch 3/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.6562 - loss: 0.6802 26/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6889 - loss: 0.5891  52/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6898 - loss: 0.5792 78/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6940 - loss: 0.5745104/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6990 - loss: 0.5700116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7007 - loss: 0.5682 - val_accuracy: 0.7220 - val_loss: 0.5295
Epoch 4/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.7500 - loss: 0.6255 25/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7201 - loss: 0.5837  51/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7174 - loss: 0.5750 77/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7208 - loss: 0.5650103/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7222 - loss: 0.5601116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7226 - loss: 0.5588 - val_accuracy: 0.7163 - val_loss: 0.5352
Epoch 5/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.7500 - loss: 0.5249 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7560 - loss: 0.5110  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7472 - loss: 0.5217 79/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7422 - loss: 0.5271104/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7384 - loss: 0.5316116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7367 - loss: 0.5338 - val_accuracy: 0.7285 - val_loss: 0.5223
Epoch 6/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.7812 - loss: 0.5259 26/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7361 - loss: 0.5680  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7330 - loss: 0.5632 79/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7325 - loss: 0.5608105/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7320 - loss: 0.5587116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7320 - loss: 0.5574 - val_accuracy: 0.7053 - val_loss: 0.5501
Epoch 7/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.7500 - loss: 0.5031 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6920 - loss: 0.5686  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7024 - loss: 0.5582 80/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7070 - loss: 0.5559106/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7107 - loss: 0.5533116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7116 - loss: 0.5527 - val_accuracy: 0.7260 - val_loss: 0.5336
Epoch 8/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6562 - loss: 0.5842 22/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7117 - loss: 0.5538  48/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7189 - loss: 0.5509 74/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7241 - loss: 0.5481101/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7254 - loss: 0.5474116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7258 - loss: 0.5472 - val_accuracy: 0.7280 - val_loss: 0.5258
Epoch 9/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6875 - loss: 0.6027 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7183 - loss: 0.5446  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7236 - loss: 0.5325 79/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7214 - loss: 0.5343105/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7204 - loss: 0.5350116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7208 - loss: 0.5348 - val_accuracy: 0.7293 - val_loss: 0.5244
Epoch 10/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6875 - loss: 0.4935 28/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7322 - loss: 0.5131  55/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7316 - loss: 0.5244 81/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7317 - loss: 0.5278108/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7327 - loss: 0.5296116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7329 - loss: 0.5303 - val_accuracy: 0.7293 - val_loss: 0.5293
Epoch 11/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.7500 - loss: 0.5361 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7352 - loss: 0.5274  54/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7398 - loss: 0.5302 80/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7401 - loss: 0.5334106/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7398 - loss: 0.5348116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7392 - loss: 0.5353 - val_accuracy: 0.7154 - val_loss: 0.5491
Epoch 12/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.8750 - loss: 0.4636 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7363 - loss: 0.5397  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7291 - loss: 0.5461 80/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7263 - loss: 0.5478107/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7250 - loss: 0.5480116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7251 - loss: 0.5475 - val_accuracy: 0.7301 - val_loss: 0.5283
Epoch 13/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6250 - loss: 0.8070 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7139 - loss: 0.5634  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7165 - loss: 0.5553 79/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7176 - loss: 0.5533105/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7197 - loss: 0.5508116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7207 - loss: 0.5500 - val_accuracy: 0.7321 - val_loss: 0.5215
Epoch 14/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.7188 - loss: 0.4898 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7698 - loss: 0.5040  52/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7480 - loss: 0.5256 79/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7399 - loss: 0.5321105/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7374 - loss: 0.5345116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7369 - loss: 0.5348 - val_accuracy: 0.7211 - val_loss: 0.5293
Epoch 15/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.7812 - loss: 0.4526 28/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7341 - loss: 0.5190  54/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7288 - loss: 0.5315 80/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7275 - loss: 0.5356107/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7261 - loss: 0.5382116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7262 - loss: 0.5385 - val_accuracy: 0.7256 - val_loss: 0.5305
Epoch 16/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.7500 - loss: 0.4919 28/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7358 - loss: 0.5390  54/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7375 - loss: 0.5378 80/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7362 - loss: 0.5363107/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7343 - loss: 0.5363116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7337 - loss: 0.5367 - val_accuracy: 0.7252 - val_loss: 0.5219
Epoch 17/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.7812 - loss: 0.4652 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7520 - loss: 0.5075  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7449 - loss: 0.5166 79/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7428 - loss: 0.5185105/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7413 - loss: 0.5213116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7406 - loss: 0.5226 - val_accuracy: 0.7280 - val_loss: 0.5228
Epoch 18/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.7188 - loss: 0.4849 28/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7289 - loss: 0.5403  55/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7236 - loss: 0.5465 81/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7253 - loss: 0.5438107/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7261 - loss: 0.5430116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7265 - loss: 0.5424 - val_accuracy: 0.7301 - val_loss: 0.5416
Epoch 19/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.8125 - loss: 0.5372 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7428 - loss: 0.5240  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7364 - loss: 0.5298 81/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7320 - loss: 0.5344106/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7294 - loss: 0.5370116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7294 - loss: 0.5369 - val_accuracy: 0.7252 - val_loss: 0.5239
Epoch 20/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.7188 - loss: 0.4758 28/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7299 - loss: 0.5484  54/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7275 - loss: 0.5533 80/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7311 - loss: 0.5483106/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7327 - loss: 0.5458116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7332 - loss: 0.5448 - val_accuracy: 0.7293 - val_loss: 0.5242
Epoch 21/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.7500 - loss: 0.5325 28/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7448 - loss: 0.5266  54/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7429 - loss: 0.5292 80/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7385 - loss: 0.5327106/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7368 - loss: 0.5342116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7365 - loss: 0.5345 - val_accuracy: 0.7346 - val_loss: 0.5218
Epoch 22/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.8438 - loss: 0.3739 26/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7617 - loss: 0.4720  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7425 - loss: 0.4994 77/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7376 - loss: 0.5090101/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7364 - loss: 0.5142116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7358 - loss: 0.5168 - val_accuracy: 0.7341 - val_loss: 0.5213
Epoch 23/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.5938 - loss: 0.6723 25/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7074 - loss: 0.5786  50/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7249 - loss: 0.5596 74/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7273 - loss: 0.5535 99/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7283 - loss: 0.5501116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7287 - loss: 0.5478 - val_accuracy: 0.7276 - val_loss: 0.5232
Epoch 24/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 14ms/step - accuracy: 0.7188 - loss: 0.5644 25/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7234 - loss: 0.5477  49/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7283 - loss: 0.5410 74/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7293 - loss: 0.5391 99/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7303 - loss: 0.5383116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7301 - loss: 0.5386 - val_accuracy: 0.7317 - val_loss: 0.5183
Epoch 25/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.7500 - loss: 0.5826 26/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7509 - loss: 0.5277  51/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7449 - loss: 0.5302 77/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7418 - loss: 0.5324103/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7398 - loss: 0.5342116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7390 - loss: 0.5350 - val_accuracy: 0.7268 - val_loss: 0.5292
Epoch 26/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6875 - loss: 0.5461 26/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7027 - loss: 0.5561  52/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7094 - loss: 0.5538 77/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7149 - loss: 0.5491104/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7201 - loss: 0.5445116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7217 - loss: 0.5431 - val_accuracy: 0.7289 - val_loss: 0.5324
Epoch 27/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6562 - loss: 0.5515 28/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6963 - loss: 0.5457  55/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7141 - loss: 0.5372 82/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7199 - loss: 0.5353108/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7227 - loss: 0.5355116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7234 - loss: 0.5357 - val_accuracy: 0.7354 - val_loss: 0.5321
Epoch 28/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.7188 - loss: 0.6131 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7288 - loss: 0.5429  54/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7251 - loss: 0.5430 81/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7269 - loss: 0.5400107/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7286 - loss: 0.5375116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7292 - loss: 0.5367 - val_accuracy: 0.7305 - val_loss: 0.5225
Epoch 29/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.6250 - loss: 0.6116 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6898 - loss: 0.5830  54/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7065 - loss: 0.5684 81/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7131 - loss: 0.5604107/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7159 - loss: 0.5567116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7168 - loss: 0.5555 - val_accuracy: 0.7244 - val_loss: 0.5305
Epoch 30/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.6562 - loss: 0.5165 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6996 - loss: 0.5484  54/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7066 - loss: 0.5449 78/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7099 - loss: 0.5438104/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7130 - loss: 0.5430116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7141 - loss: 0.5429 - val_accuracy: 0.7276 - val_loss: 0.5265
Epoch 31/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.7812 - loss: 0.5821 26/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7315 - loss: 0.5394  52/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7345 - loss: 0.5342 79/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7348 - loss: 0.5331107/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7343 - loss: 0.5321116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7340 - loss: 0.5323 - val_accuracy: 0.7305 - val_loss: 0.5354
Epoch 32/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6875 - loss: 0.6333 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7181 - loss: 0.5528  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7179 - loss: 0.5503 79/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7196 - loss: 0.5502105/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7222 - loss: 0.5496116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7232 - loss: 0.5490 - val_accuracy: 0.7276 - val_loss: 0.5191
Epoch 33/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6875 - loss: 0.4996 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7678 - loss: 0.4673  56/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7554 - loss: 0.4881 84/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7504 - loss: 0.4983111/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7475 - loss: 0.5053116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7468 - loss: 0.5068 - val_accuracy: 0.7268 - val_loss: 0.5448
Epoch 34/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.7188 - loss: 0.5336 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7504 - loss: 0.5185  52/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7465 - loss: 0.5232 78/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7434 - loss: 0.5262105/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7408 - loss: 0.5290116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7400 - loss: 0.5303 - val_accuracy: 0.7276 - val_loss: 0.5293
Epoch 35/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6875 - loss: 0.5848 26/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7467 - loss: 0.5216  52/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7341 - loss: 0.5301 78/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7309 - loss: 0.5314104/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7295 - loss: 0.5322116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7290 - loss: 0.5327 - val_accuracy: 0.7341 - val_loss: 0.5202
Epoch 36/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 14ms/step - accuracy: 0.7188 - loss: 0.5341 25/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7560 - loss: 0.5052  48/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7517 - loss: 0.5083 74/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7489 - loss: 0.5115100/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7460 - loss: 0.5148116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7443 - loss: 0.5168 - val_accuracy: 0.7366 - val_loss: 0.5327
Epoch 37/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.6562 - loss: 0.5813 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7328 - loss: 0.5487  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7349 - loss: 0.5444 79/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7340 - loss: 0.5430108/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7341 - loss: 0.5418116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7341 - loss: 0.5415 - val_accuracy: 0.7341 - val_loss: 0.5215
Epoch 38/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6875 - loss: 0.5430 29/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6900 - loss: 0.5528  57/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6990 - loss: 0.5490 85/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7069 - loss: 0.5447111/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7116 - loss: 0.5419116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7125 - loss: 0.5414 - val_accuracy: 0.7268 - val_loss: 0.5371
Epoch 39/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.7812 - loss: 0.4789 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7732 - loss: 0.5018  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7496 - loss: 0.5136 80/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7443 - loss: 0.5158106/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7415 - loss: 0.5180116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7402 - loss: 0.5192 - val_accuracy: 0.7305 - val_loss: 0.5242
Epoch 40/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.8438 - loss: 0.3997 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7512 - loss: 0.5157  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7451 - loss: 0.5281 79/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7416 - loss: 0.5319106/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7397 - loss: 0.5331116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7391 - loss: 0.5332 - val_accuracy: 0.7297 - val_loss: 0.5192
Epoch 41/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.6562 - loss: 0.6030 28/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6962 - loss: 0.5603  54/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7122 - loss: 0.5504 77/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7182 - loss: 0.5479 93/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7217 - loss: 0.5465116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7251 - loss: 0.5448 - val_accuracy: 0.7297 - val_loss: 0.5183
Epoch 42/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6875 - loss: 0.5016 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7526 - loss: 0.5071  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7484 - loss: 0.5167 79/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7469 - loss: 0.5199106/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7451 - loss: 0.5214116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7438 - loss: 0.5225 - val_accuracy: 0.7313 - val_loss: 0.5248
Epoch 43/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6250 - loss: 0.6189 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6785 - loss: 0.5785  53/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6949 - loss: 0.5671 79/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7029 - loss: 0.5624105/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7091 - loss: 0.5578116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7115 - loss: 0.5559 - val_accuracy: 0.7297 - val_loss: 0.5254
Epoch 44/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.6875 - loss: 0.5720 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7147 - loss: 0.5472  54/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7156 - loss: 0.5461 81/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7189 - loss: 0.5452107/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7217 - loss: 0.5430116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7226 - loss: 0.5422 - val_accuracy: 0.7293 - val_loss: 0.5255
Epoch 45/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.7812 - loss: 0.4507 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7279 - loss: 0.5408  52/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7211 - loss: 0.5448 79/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7226 - loss: 0.5415106/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7254 - loss: 0.5381116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7260 - loss: 0.5375 - val_accuracy: 0.7276 - val_loss: 0.5389
Epoch 46/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.8125 - loss: 0.5217 26/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7552 - loss: 0.5437  52/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7495 - loss: 0.5384 74/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7448 - loss: 0.5378 96/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7425 - loss: 0.5371116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7412 - loss: 0.5365 - val_accuracy: 0.7329 - val_loss: 0.5172
Epoch 47/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.7188 - loss: 0.4508 25/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7251 - loss: 0.5200  50/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7326 - loss: 0.5267 75/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7322 - loss: 0.5309100/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7316 - loss: 0.5329116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7316 - loss: 0.5332 - val_accuracy: 0.7289 - val_loss: 0.5186
Epoch 48/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 14ms/step - accuracy: 0.6875 - loss: 0.5576 26/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7111 - loss: 0.5343  51/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7120 - loss: 0.5366 76/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7162 - loss: 0.5351100/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7178 - loss: 0.5354116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7187 - loss: 0.5357 - val_accuracy: 0.7260 - val_loss: 0.5218
Epoch 49/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - accuracy: 0.7812 - loss: 0.3832 27/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7431 - loss: 0.5050  52/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7292 - loss: 0.5256 75/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7229 - loss: 0.5344100/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7219 - loss: 0.5372116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - accuracy: 0.7217 - loss: 0.5378 - val_accuracy: 0.7073 - val_loss: 0.5306
Epoch 50/50
  1/116 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - accuracy: 0.7500 - loss: 0.5124 28/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.6979 - loss: 0.5587  54/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7041 - loss: 0.5542 80/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7103 - loss: 0.5506107/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7131 - loss: 0.5500116/116 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - accuracy: 0.7142 - loss: 0.5493 - val_accuracy: 0.7350 - val_loss: 0.5290</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="part-3-mitigating-bias" class="level1">
<h1>Part 3: Mitigating bias</h1>
<p>After having detected and replicated the bias, we now want to introduce different mitigation strategies - we’ll begin with two preprocessing techniques, followed by one prost-processing technique - let’s dive right in and see what we can do to get fairer results!</p>
<section id="data-download-1" class="level2">
<h2 class="anchored" data-anchor-id="data-download-1">3.1 Data Download</h2>
<p><em>First</em> step, as usual, is to get our data:</p>
<div id="caabb2f0" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>df_compas_bias <span class="op">=</span> pd.read_csv(<span class="st">"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv"</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>df_compas_bias.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">name</th>
<th data-quarto-table-cell-role="th">first</th>
<th data-quarto-table-cell-role="th">last</th>
<th data-quarto-table-cell-role="th">compas_screening_date</th>
<th data-quarto-table-cell-role="th">sex</th>
<th data-quarto-table-cell-role="th">dob</th>
<th data-quarto-table-cell-role="th">age</th>
<th data-quarto-table-cell-role="th">age_cat</th>
<th data-quarto-table-cell-role="th">race</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">v_decile_score</th>
<th data-quarto-table-cell-role="th">v_score_text</th>
<th data-quarto-table-cell-role="th">v_screening_date</th>
<th data-quarto-table-cell-role="th">in_custody</th>
<th data-quarto-table-cell-role="th">out_custody</th>
<th data-quarto-table-cell-role="th">priors_count.1</th>
<th data-quarto-table-cell-role="th">start</th>
<th data-quarto-table-cell-role="th">end</th>
<th data-quarto-table-cell-role="th">event</th>
<th data-quarto-table-cell-role="th">two_year_recid</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>miguel hernandez</td>
<td>miguel</td>
<td>hernandez</td>
<td>2013-08-14</td>
<td>Male</td>
<td>1947-04-18</td>
<td>69</td>
<td>Greater than 45</td>
<td>Other</td>
<td>...</td>
<td>1</td>
<td>Low</td>
<td>2013-08-14</td>
<td>2014-07-07</td>
<td>2014-07-14</td>
<td>0</td>
<td>0</td>
<td>327</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>3</td>
<td>kevon dixon</td>
<td>kevon</td>
<td>dixon</td>
<td>2013-01-27</td>
<td>Male</td>
<td>1982-01-22</td>
<td>34</td>
<td>25 - 45</td>
<td>African-American</td>
<td>...</td>
<td>1</td>
<td>Low</td>
<td>2013-01-27</td>
<td>2013-01-26</td>
<td>2013-02-05</td>
<td>0</td>
<td>9</td>
<td>159</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>4</td>
<td>ed philo</td>
<td>ed</td>
<td>philo</td>
<td>2013-04-14</td>
<td>Male</td>
<td>1991-05-14</td>
<td>24</td>
<td>Less than 25</td>
<td>African-American</td>
<td>...</td>
<td>3</td>
<td>Low</td>
<td>2013-04-14</td>
<td>2013-06-16</td>
<td>2013-06-16</td>
<td>4</td>
<td>0</td>
<td>63</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>5</td>
<td>marcu brown</td>
<td>marcu</td>
<td>brown</td>
<td>2013-01-13</td>
<td>Male</td>
<td>1993-01-21</td>
<td>23</td>
<td>Less than 25</td>
<td>African-American</td>
<td>...</td>
<td>6</td>
<td>Medium</td>
<td>2013-01-13</td>
<td>NaN</td>
<td>NaN</td>
<td>1</td>
<td>0</td>
<td>1174</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>6</td>
<td>bouthy pierrelouis</td>
<td>bouthy</td>
<td>pierrelouis</td>
<td>2013-03-26</td>
<td>Male</td>
<td>1973-01-22</td>
<td>43</td>
<td>25 - 45</td>
<td>Other</td>
<td>...</td>
<td>1</td>
<td>Low</td>
<td>2013-03-26</td>
<td>NaN</td>
<td>NaN</td>
<td>2</td>
<td>0</td>
<td>1102</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>5 rows × 53 columns</p>
</div>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="data-preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="data-preprocessing">3.1 Data Preprocessing</h2>
<p>To further work with the data, we need to clean it up and only keep variables that we want to use for our analysis. The following code leaves us with only the relevant variables: We want to focus our tutorial on racial bias in the COMPAS dataset, thus we only keep the data for “African-American” and “Caucasian” individuals.Further, we map the age variables to numeric values, convert “sex” and “charge_degree” (F: Felony M: Misdemeanor) to binary variables. Last but not least, we drop the “start2 and”end” variables after calculating the duration and adding it as a new variable.</p>
<p><br></p>
<div id="5994614a" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Drop columns that we don't need</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>columns_to_drop <span class="op">=</span> [<span class="st">'id'</span>, <span class="st">'name'</span>, <span class="st">'first'</span>, <span class="st">'last'</span>, <span class="st">'compas_screening_date'</span>, <span class="st">'dob'</span>, <span class="st">'age'</span>, <span class="st">'c_jail_in'</span>, <span class="st">'c_jail_out'</span>,</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'c_case_number'</span>, <span class="st">'c_offense_date'</span>, <span class="st">'c_arrest_date'</span>, <span class="st">'c_charge_desc'</span>, <span class="st">'days_b_screening_arrest'</span>,</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'decile_score'</span>, <span class="st">'r_case_number'</span>, <span class="st">'r_days_from_arrest'</span>, <span class="st">'r_offense_date'</span>, <span class="st">'c_days_from_compas'</span>,</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'r_charge_degree'</span>, <span class="st">'r_charge_desc'</span>, <span class="st">'r_jail_in'</span>, <span class="st">'r_jail_out'</span>, <span class="st">'priors_count.1'</span>, <span class="st">'violent_recid'</span>,</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'is_violent_recid'</span>, <span class="st">'vr_case_number'</span>, <span class="st">'vr_charge_degree'</span>, <span class="st">'vr_offense_date'</span>, <span class="st">'vr_charge_desc'</span>,</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'type_of_assessment'</span>, <span class="st">'decile_score.1'</span>, <span class="st">'score_text'</span>, <span class="st">'is_recid'</span>, <span class="st">'v_type_of_assessment'</span>,</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'screening_date'</span>, <span class="st">'v_decile_score'</span>, <span class="st">'v_score_text'</span>, <span class="st">'v_screening_date'</span>, <span class="st">'in_custody'</span>, <span class="st">'out_custody'</span>,</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>                   <span class="st">'event'</span>]</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>df_compas_bias_w <span class="op">=</span> df_compas_bias.drop(columns<span class="op">=</span>[col <span class="cf">for</span> col <span class="kw">in</span> columns_to_drop <span class="cf">if</span> col <span class="kw">in</span> df_compas_bias.columns])</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co">### Keep only white and black individuals</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>race_map <span class="op">=</span> {<span class="st">'African-American'</span>:<span class="dv">0</span>, <span class="st">'Caucasian'</span>:<span class="dv">1</span>, <span class="st">'Asian'</span>:<span class="dv">2</span>, <span class="st">'Hispanic'</span>:<span class="dv">3</span>, <span class="st">'Native American'</span>:<span class="dv">4</span>, <span class="st">'Other'</span>:<span class="dv">5</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>df_compas_bias_w[<span class="st">'race'</span>] <span class="op">=</span> df_compas_bias_w[<span class="st">'race'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: race_map[x])</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>df_compas_bias_w <span class="op">=</span> df_compas_bias_w[(df_compas_bias_w.race <span class="op">==</span> <span class="fl">0.</span>) <span class="op">|</span> (df_compas_bias_w.race <span class="op">==</span> <span class="fl">1.</span>)]</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Map age categories to numeric values</span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>age_map <span class="op">=</span> {<span class="st">'Less than 25'</span>: <span class="dv">0</span>, <span class="st">'25 - 45'</span>: <span class="dv">1</span>, <span class="st">'Greater than 45'</span>: <span class="dv">2</span>}</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>df_compas_bias_w[<span class="st">'age_cat'</span>] <span class="op">=</span> df_compas_bias_w[<span class="st">'age_cat'</span>].<span class="bu">map</span>(age_map)</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert sex to binary values (Male: 0, Female: 1)</span></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>sex_map <span class="op">=</span> {<span class="st">'Male'</span>: <span class="dv">0</span>, <span class="st">'Female'</span>: <span class="dv">1</span>}</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>df_compas_bias_w[<span class="st">'sex'</span>] <span class="op">=</span> df_compas_bias_w[<span class="st">'sex'</span>].<span class="bu">map</span>(sex_map)</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert charge degree to binary values (F: 1, M: 0)</span></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>charge_degree_map <span class="op">=</span> {<span class="st">'F'</span>: <span class="fl">1.</span>, <span class="st">'M'</span>: <span class="fl">0.</span>}</span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>df_compas_bias_w[<span class="st">'c_charge_degree'</span>] <span class="op">=</span> df_compas_bias_w[<span class="st">'c_charge_degree'</span>].<span class="bu">map</span>(charge_degree_map)</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate duration in days and drop the original 'end' and 'start' columns</span></span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>df_compas_bias_w[<span class="st">'duration'</span>] <span class="op">=</span> (df_compas_bias_w[<span class="st">'end'</span>] <span class="op">-</span> df_compas_bias_w[<span class="st">'start'</span>])</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a><span class="co">#erase start and end</span></span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>df_compas_bias_w <span class="op">=</span> df_compas_bias_w.drop(columns<span class="op">=</span>[<span class="st">'start'</span>, <span class="st">'end'</span>])</span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a>df_compas_bias_w.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sex</th>
<th data-quarto-table-cell-role="th">age_cat</th>
<th data-quarto-table-cell-role="th">race</th>
<th data-quarto-table-cell-role="th">juv_fel_count</th>
<th data-quarto-table-cell-role="th">juv_misd_count</th>
<th data-quarto-table-cell-role="th">juv_other_count</th>
<th data-quarto-table-cell-role="th">priors_count</th>
<th data-quarto-table-cell-role="th">c_charge_degree</th>
<th data-quarto-table-cell-role="th">two_year_recid</th>
<th data-quarto-table-cell-role="th">duration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1.0</td>
<td>1</td>
<td>150</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>1.0</td>
<td>1</td>
<td>63</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1.0</td>
<td>0</td>
<td>1174</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">6</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>14</td>
<td>1.0</td>
<td>1</td>
<td>35</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0.0</td>
<td>0</td>
<td>745</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p><br></p>
<p>As a next step, we want to separate our independent variables (X) from our target variable (Y) , namely “two_year_recid” (a Binary variable indicating whether the defendant is rearrested at within two years). Also, we use the MinMaxScaler from scikit-learn to normalize our features and the fit_transform method to rescale the features. We then have a look at our data, to see, if everything worked out well.</p>
<p><br></p>
<div id="eeff412d" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Separate features (X) and target variable (y)</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_compas_bias_w.drop(columns<span class="op">=</span>[<span class="st">'two_year_recid'</span>]).values</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_compas_bias_w[<span class="st">'two_year_recid'</span>].values</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Rescale the features for better performance</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first few rows of the modified DataFrame</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>df_compas_bias_w.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sex</th>
<th data-quarto-table-cell-role="th">age_cat</th>
<th data-quarto-table-cell-role="th">race</th>
<th data-quarto-table-cell-role="th">juv_fel_count</th>
<th data-quarto-table-cell-role="th">juv_misd_count</th>
<th data-quarto-table-cell-role="th">juv_other_count</th>
<th data-quarto-table-cell-role="th">priors_count</th>
<th data-quarto-table-cell-role="th">c_charge_degree</th>
<th data-quarto-table-cell-role="th">two_year_recid</th>
<th data-quarto-table-cell-role="th">duration</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1.0</td>
<td>1</td>
<td>150</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>1.0</td>
<td>1</td>
<td>63</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1.0</td>
<td>0</td>
<td>1174</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">6</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>14</td>
<td>1.0</td>
<td>1</td>
<td>35</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0.0</td>
<td>0</td>
<td>745</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="preprocessing-mitigation-techniques" class="level2">
<h2 class="anchored" data-anchor-id="preprocessing-mitigation-techniques">3.3 Preprocessing Mitigation Techniques</h2>
<p>In the next steps, we will predict, whether an individual will recidivate - in other words, we’ll precict the target variable, “two_year_recid”. To do this, we firstly split our data in a train and a test set. Then, we fit a logistic regression and print the accuracy and some other metrics.</p>
<p><br></p>
<div id="dbef1bc4" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">### Split to train / test</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co">### Fit logistic regression and print accuracy</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> LogisticRegression(random_state<span class="op">=</span><span class="dv">42</span>).fit(X_train, y_train)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> np.<span class="bu">sum</span>(y_pred <span class="op">==</span> y_test) <span class="op">/</span> <span class="bu">len</span>(y_test)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy ="</span>, np.<span class="bu">round</span>(acc, <span class="dv">3</span>))</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Precision</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>precision <span class="op">=</span> precision_score(y_test, y_pred)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Precision ="</span>, np.<span class="bu">round</span>(precision, <span class="dv">3</span>))</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Recall</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>recall <span class="op">=</span> recall_score(y_test, y_pred)</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Recall ="</span>, np.<span class="bu">round</span>(recall, <span class="dv">3</span>))</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a><span class="co"># F1 Score</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> f1_score(y_test, y_pred)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score ="</span>, np.<span class="bu">round</span>(f1, <span class="dv">3</span>))</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>conf_matrix <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Confusion Matrix:</span><span class="ch">\n</span><span class="st">"</span>, conf_matrix)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy = 0.874
Precision = 0.851
Recall = 0.89
F1 Score = 0.87
Confusion Matrix:
 [[838 136]
 [ 96 775]]</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="ratio-of-african-american-to-caucasians-on-the-original-data-vs.-in-the-precicted-outcomes" class="level2">
<h2 class="anchored" data-anchor-id="ratio-of-african-american-to-caucasians-on-the-original-data-vs.-in-the-precicted-outcomes">Ratio of African-American to Caucasians on the original data vs.&nbsp;in the precicted outcomes</h2>
<p>Let’s have look at the distributions in our data, which plays an important role when dealing with fairness measures - as we learned in the first part of this tutorial. The code calculates the ratio of African-Americans in the data - apparently, for every Caucasian prisoner, there are approximately 1.51 African-American prisoners. The model predicts that African-American prisoners are 2.15 times more likely to reoffend than Caucasian prisoners. <strong>This ratio being higher than the actual ratio of African-American to Caucasian prisoners, indicates a potential bias in the predictions towards expecting higher recidivism among African-American individuals.</strong></p>
<div id="13f5813e" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Identifying African-American and Caucasian individuals in the test set</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>afr_am <span class="op">=</span> (X_test[:, <span class="dv">2</span>] <span class="op">==</span> <span class="dv">0</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>white <span class="op">=</span> (X_test[:, <span class="dv">2</span>] <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions for African-American and Caucasian individuals</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>pred_afr_am <span class="op">=</span> y_pred[afr_am]</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>pred_white <span class="op">=</span> y_pred[white]</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating ratios</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>afr_am_to_whites_ratio <span class="op">=</span> afr_am.<span class="bu">sum</span>() <span class="op">/</span> white.<span class="bu">sum</span>()</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>predicted_reoffense_afr_am_to_whites_ratio <span class="op">=</span> pred_afr_am.<span class="bu">sum</span>() <span class="op">/</span> pred_white.<span class="bu">sum</span>()</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Printing the ratios</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Black to white prisoners ratio:"</span>, <span class="bu">round</span>(afr_am_to_whites_ratio, <span class="dv">2</span>))</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted reoffense blacks to whites ratio:"</span>, <span class="bu">round</span>(predicted_reoffense_afr_am_to_whites_ratio, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Black to white prisoners ratio: 1.51
Predicted reoffense blacks to whites ratio: 2.15</code></pre>
</div>
</div>
<section id="using-disparate-impact-repairing-preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="using-disparate-impact-repairing-preprocessing">3.3.1 Using Disparate Impact Repairing (preprocessing)</h3>
<p><strong>Disparate Impact</strong> is a fairness metric used to assess the equality of outcomes between two distinct groups: an unprivileged group and a privileged group. It <strong>measures the ratio of the proportion of individuals receiving favorable outcomes in the unprivileged group to that in the privileged group.</strong></p>
<p><strong>Disparate impact remover</strong> is a <strong>preprocessing technique that edits feature values to increase group fairness</strong> while preserving rank-ordering within groups</p>
<p><span class="math display">\[
\frac{\Pr(Y=1|D=\text{unprivileged})}{\Pr(Y=1|D=\text{privileged})}
\]</span></p>
<p><br></p>
<p>To use the remover, let’s first create two dataframes, one for the privileged group (“Caucasian”) and one for the unprivileged group (“African-American”). Next, we want to plot the distribution of outcomes for each of the two groups and visually see this disparity:</p>
<p><br></p>
<div id="eded0f69" class="cell" data-execution_count="30">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter the DataFrame into privileged and unprivileged groups</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>unprivileged <span class="op">=</span> df_compas_bias_w[df_compas_bias_w[<span class="st">'race'</span>] <span class="op">==</span> <span class="dv">0</span>]</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>privileged <span class="op">=</span> df_compas_bias_w[df_compas_bias_w[<span class="st">'race'</span>] <span class="op">==</span> <span class="dv">1</span>]</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the matplotlib figure</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the distribution for the unprivileged group</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>sns.distplot(unprivileged[<span class="st">'two_year_recid'</span>], hist<span class="op">=</span><span class="va">False</span>, label<span class="op">=</span><span class="st">'Unprivileged (African-American)'</span>)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the distribution for the privileged group</span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>sns.distplot(privileged[<span class="st">'two_year_recid'</span>], hist<span class="op">=</span><span class="va">False</span>, label<span class="op">=</span><span class="st">'Privileged (Caucasian)'</span>)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Add title and labels</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Distribution of Outcomes for Privileged and Unprivileged Groups'</span>)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Outcome (two_year_recid)'</span>)</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the plot</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-31-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="index_files/figure-html/cell-31-output-1.png" width="839" height="554" class="figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p><br></p>
<p>Next, we are creating a StandardDataset object using the AIF360 library, which is designed for fairness-aware machine learningand can be then used with various algorithms and metrics provided by AIF360 to assess and mitigate bias in machine learning models.</p>
<p><br></p>
<div id="02d2ca7a" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>protected <span class="op">=</span> <span class="st">'race'</span> <span class="co">#We chose race as the protected attribute because we are interested in the disparity between African-Americans and Caucasians</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a StandardDataset object</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>df_protected <span class="op">=</span> Dataset(df_compas_bias_w, <span class="co">#The dataset</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>             label_name<span class="op">=</span><span class="st">'two_year_recid'</span>, <span class="co">#The label or target variable that we want to predict</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>             favorable_classes<span class="op">=</span>[<span class="dv">0</span>], <span class="co">#The class we want to consider favorable (0 means no recidivism)</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>             protected_attribute_names<span class="op">=</span>[protected], <span class="co">#The attribute we want to test for disparity</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>             privileged_classes<span class="op">=</span>[[<span class="dv">1</span>]], categorical_features<span class="op">=</span>[],   <span class="co"># 0 -&gt; Black, 1 -&gt; White to match the order of our dataset</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>             features_to_keep<span class="op">=</span>[<span class="st">'race'</span>, <span class="st">'priors_count'</span>, <span class="st">'duration'</span>]) <span class="co">#The features we want to keep in the dataset because they are relevant for our model</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<div id="bbc11071" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> MinMaxScaler(copy<span class="op">=</span><span class="va">False</span>) <span class="co">#We create a scaler object</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the dataset into test and train sets like we did before</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>test, train <span class="op">=</span> df_protected.split([<span class="fl">0.33</span>], seed<span class="op">=</span><span class="dv">42</span>) <span class="co">#We use a seed to make sure we get the same split every time</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting the scaler on the training features and transforming the training features using the same scaler</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>train.features <span class="op">=</span> scaler.fit_transform(train.features) <span class="co">#We fit the scaler on the training features</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Transforming the test features using the same scaler as the one fitted on the training features</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>test.features <span class="op">=</span> scaler.transform(test.features) <span class="co">#We transform the test features using the same scaler</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Getting the index of the protected attribute in the feature names list</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> train.feature_names.index(protected) <span class="co">#We get the index of the protected attribute in the feature names list</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p>The <strong>“repair level” parameter quantifies the extent to which you want to adjust the dataset to correct for disparities between privileged and unprivileged groups.</strong></p>
<p>In the follwoing code chunk, we calculate the disparate impact for both privileged (e.g., Caucasians) and unprivileged (e.g., African-Americans) groups, <strong>storing the results in a list for each repair level.</strong></p>
<p><br></p>
<div id="4cba75dd" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize a list to store the disparate impact values</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>DIs <span class="op">=</span> []</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate over each level of repair</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> level <span class="kw">in</span> tqdm(np.linspace(<span class="fl">0.</span>, <span class="fl">1.</span>, <span class="dv">11</span>)):</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize DisparateImpactRemover with the current level</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    di <span class="op">=</span> DisparateImpactRemover(repair_level<span class="op">=</span>level) <span class="co">#We initialize the DisparateImpactRemover with the current level</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit and transform the training data</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>    train_repd <span class="op">=</span> di.fit_transform(train) <span class="co">#We fit and transform the training data</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transform the test data (do not fit the test data)</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>    test_repd <span class="op">=</span> di.fit_transform(test) <span class="co">#We transform the test data (do not fit the test data)</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove the protected attribute before training the model</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>    X_tr <span class="op">=</span> np.delete(train_repd.features, index, axis<span class="op">=</span><span class="dv">1</span>) <span class="co">#We remove the protected attribute before training the model</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>    X_te <span class="op">=</span> np.delete(test_repd.features, index, axis<span class="op">=</span><span class="dv">1</span>) <span class="co">#We remove the protected attribute before training the model</span></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>    y_tr <span class="op">=</span> train_repd.labels.ravel() <span class="co">#We get the labels for the training set</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize and fit the logistic regression model</span></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>    lmod <span class="op">=</span> LogisticRegression(class_weight<span class="op">=</span><span class="st">'balanced'</span>, solver<span class="op">=</span><span class="st">'liblinear'</span>) <span class="co">#We initialize and fit the logistic regression model with class_weight='balanced' to account for the imbalance in the dataset</span></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>    lmod.fit(X_tr, y_tr) <span class="co">#We fit the model</span></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predict on the test set and copy the results to a new dataset</span></span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>    test_repd_pred <span class="op">=</span> test_repd.copy() <span class="co">#We predict on the test set and copy the results to a new dataset</span></span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>    test_repd_pred.labels <span class="op">=</span> lmod.predict(X_te) <span class="co">#We predict on the test set and copy the results to a new dataset</span></span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate and store the disparate impact</span></span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> [{protected: <span class="dv">1</span>}] <span class="co">#We calculate and store the disparate impact for the privileged group (in our case Caucasians)</span></span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a>    u <span class="op">=</span> [{protected: <span class="dv">0</span>}] <span class="co">#We calculate and store the disparate impact for the unprivileged group (in our case African-Americans)</span></span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true" tabindex="-1"></a>    cm <span class="op">=</span> BinaryLabelDatasetMetric(test_repd_pred, privileged_groups<span class="op">=</span>p, unprivileged_groups<span class="op">=</span>u) <span class="co">#We calculate and store the disparate impact for the privileged and unprivileged groups</span></span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true" tabindex="-1"></a>    DIs.append(cm.disparate_impact()) <span class="co">#We calculate and store the disparate impact for the privileged and unprivileged groups</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>  0%|          | 0/11 [00:00&lt;?, ?it/s]  9%|▉         | 1/11 [00:00&lt;00:03,  3.21it/s] 27%|██▋       | 3/11 [00:00&lt;00:01,  7.90it/s] 45%|████▌     | 5/11 [00:00&lt;00:00,  8.15it/s] 64%|██████▎   | 7/11 [00:00&lt;00:00, 10.57it/s] 82%|████████▏ | 9/11 [00:00&lt;00:00, 12.71it/s]100%|██████████| 11/11 [00:00&lt;00:00, 11.19it/s]</code></pre>
</div>
</div>
<p><br></p>
<p>The graph we’ll create next illustrates the efficacy of the Disparate Impact Remover at different repair levels for reducing racial bias within the context of predicting two-year recidivism. As the repair level increases from 0 (no adjustment) to 1 (full adjustment), the disparate impact metric approaches 1.0, which signifies fair treatment between races; each blue dot is a data point that shows how the fairness of the model, as measured by the disparate impact, changes as we apply different levels of bias mitigation.</p>
<p>Initially, <strong>with no repair, the metric is close to 0.8, indicating substantial bias against the unprivileged group (likely African-Americans). With full repair, the bias is reduced, but not entirely eliminated</strong>, suggesting some residual unfairness remains or that the repair cannot fully compensate for the existing disparities within the data. The graph underscores the challenge of achieving complete fairness, as represented by the elusive ideal disparate impact value of 1.0, even as efforts are made to correct for bias in predictive modeling for criminal justice.</p>
<p><br></p>
<div id="dfff2fdb" class="cell" data-execution_count="34">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming DIs is your list of disparate impact values</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>repair_levels <span class="op">=</span> np.linspace(<span class="fl">0.</span>, <span class="fl">1.</span>, <span class="dv">11</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming DIs is defined before this point</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>DIs <span class="op">=</span> DIs[:<span class="dv">11</span>]</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>plt.plot(repair_levels, DIs, marker<span class="op">=</span><span class="st">'o'</span>, markersize<span class="op">=</span><span class="dv">8</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Disparate Impact'</span>)</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Disparate Impact vs. Repair Level'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Repair Level'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Disparate Impact'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>plt.axhline(y<span class="op">=</span><span class="fl">1.0</span>, color<span class="op">=</span><span class="st">'g'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Ideal Value'</span>)</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="fl">0.8</span>, <span class="fl">0.8</span>], <span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'-.'</span>, label<span class="op">=</span><span class="st">'Threshold'</span>)</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<div id="fee0a088" class="cell" data-execution_count="35">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on test using only the features at indices -3 and -1</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> lmod.predict(X_test[:, [<span class="op">-</span><span class="dv">3</span>, <span class="op">-</span><span class="dv">1</span>]])</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Boolean masks for African-American and Caucasian individuals</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>afr_am_mask <span class="op">=</span> (X_test[:, <span class="dv">2</span>] <span class="op">==</span> <span class="dv">0</span>)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>white_mask <span class="op">=</span> (X_test[:, <span class="dv">2</span>] <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions for African-American and Caucasian individuals</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>pred_afr_am <span class="op">=</span> y_pred[afr_am_mask]</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>pred_white <span class="op">=</span> y_pred[white_mask]</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating the ratio of predicted reoffenses</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>predicted_reoffense_afr_am_to_whites_ratio <span class="op">=</span> pred_afr_am.<span class="bu">sum</span>() <span class="op">/</span> pred_white.<span class="bu">sum</span>()</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Printing the predicted reoffense ratio</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted reoffense blacks to whites ratio:"</span>, np.<span class="bu">round</span>(predicted_reoffense_afr_am_to_whites_ratio, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted reoffense blacks to whites ratio: 2.07</code></pre>
</div>
</div>
<p><br></p>
<p>And good news: The Ratio dropped from 2.15 to 2.07! So, reparation has worked, we have a less biased result. But, let’s be honest, this is not a huge improvement, there still seems to be a decent amount of bias. So, let’s try out some other techniques to improve the fairness of the model even further!</p>
</section>
</section>
<section id="reweighting-the-data-preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="reweighting-the-data-preprocessing">3.3.2 Reweighting the Data (Preprocessing)</h2>
<p>First, let’s have a look at the difference in mean outcomes metric of the AIF360 library for unprivileged and privileged groups. A positive value indicates a bias in favor of the privileged group, while a negative value indicates a bias against the unprivileged group. In our case, the latter is the case, with a difference in mean outcomes of -0.126</p>
<div id="370f315e" class="cell" data-execution_count="36">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> aif360.metrics <span class="im">import</span> BinaryLabelDatasetMetric</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define unprivileged and privileged groups.</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>privileged_groups <span class="op">=</span> [{<span class="st">'race'</span>: <span class="dv">1</span>}]</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>unprivileged_groups <span class="op">=</span> [{<span class="st">'race'</span>: <span class="dv">0</span>}]</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the metric for the original training dataset</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>metric_orig_train <span class="op">=</span> BinaryLabelDatasetMetric(train, <span class="co"># train from protected dataset</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>                                             unprivileged_groups<span class="op">=</span>unprivileged_groups, <span class="co"># Consideres to be at disadvantage (e.g., Blacks)</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>                                             privileged_groups<span class="op">=</span>privileged_groups) <span class="co"># Considered to be at an advantage (e.g., Caucasians)</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the difference in mean outcomes between unprivileged and privileged groups</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>mean_diff <span class="op">=</span> metric_orig_train.mean_difference() <span class="co"># difference in probabilities of favorable outcomes between the privileged and unprivileged groups.</span></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a><span class="co">#A positive value indicates a bias in favor of the privileged group, while a negative value indicates a bias against the unprivileged group.</span></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Difference in mean outcomes between blacks and whites = </span><span class="sc">%f</span><span class="st">"</span> <span class="op">%</span> mean_diff)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Difference in mean outcomes between blacks and whites = -0.125928</code></pre>
</div>
</div>
<p><br></p>
<p>Next, we apply a second mitigation strategy by <strong>performing reweighing on the training dataset</strong> to ensure that the total sum of instance weights for the transformed training dataset (transf_train.instance_weights.sum()) is approximately equal to the total sum of instance weights for the original training dataset (train.instance_weights.sum()). The check is done using an absolute difference and comparing it against a small number, 1e-6, to account for any minor floating-point arithmetic discrepancies.</p>
<p>The result “True” indicates that the reweighing algorithm is functioning as intended in this regard: it’s <strong>modifying individual instance weights to address disparities without changing the overall weight sum.</strong> This is important to ensure that the dataset’s overall statistical properties remain consistent while individual instances are weighted differently to mitigate bias.</p>
<div id="c26f0308" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>RW <span class="op">=</span> Reweighing(unprivileged_groups<span class="op">=</span>unprivileged_groups,</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>               privileged_groups<span class="op">=</span>privileged_groups)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>RW.fit(train)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>transf_train <span class="op">=</span> RW.transform(train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="bea1c8cb" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co">### Testing</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">abs</span>(transf_train.instance_weights.<span class="bu">sum</span>()<span class="op">-</span>train.instance_weights.<span class="bu">sum</span>())<span class="op">&lt;</span><span class="fl">1e-6</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>True</code></pre>
</div>
</div>
<p><br></p>
<div id="2fef92ff" class="cell" data-execution_count="39">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>metric_orig_train <span class="op">=</span> BinaryLabelDatasetMetric(train,</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>                                             unprivileged_groups<span class="op">=</span>unprivileged_groups,</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>                                             privileged_groups<span class="op">=</span>privileged_groups)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>orig_mean_difference <span class="op">=</span> metric_orig_train.mean_difference()</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>metric_transf_train <span class="op">=</span> BinaryLabelDatasetMetric(transf_train,</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>                                               unprivileged_groups<span class="op">=</span>unprivileged_groups,</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>                                               privileged_groups<span class="op">=</span>privileged_groups)</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>transf_mean_difference <span class="op">=</span> metric_transf_train.mean_difference()</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Difference in mean outcomes between transformed blacks and whites = </span><span class="sc">%f</span><span class="st">"</span> <span class="op">%</span> metric_transf_train.mean_difference())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Difference in mean outcomes between transformed blacks and whites = -0.000000</code></pre>
</div>
</div>
<p><br></p>
<p>The following plot shows that the transformation of the data does not change the overall statistic properties - the distribution of features stays the same after the transformation.</p>
<p><br></p>
<div id="7ff900cd" class="cell" data-execution_count="40">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>original_labels <span class="op">=</span> train.labels.ravel()</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>transformed_labels <span class="op">=</span> transf_train.labels.ravel()</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>original_feature <span class="op">=</span> train.features[:, train.feature_names.index(<span class="st">'priors_count'</span>)]</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>transformed_feature <span class="op">=</span> transf_train.features[:, transf_train.feature_names.index(<span class="st">'priors_count'</span>)]</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting distributions</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot distribution of labels</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>sns.histplot(original_labels, ax<span class="op">=</span>axes[<span class="dv">0</span>, <span class="dv">0</span>], color<span class="op">=</span><span class="st">"blue"</span>, kde<span class="op">=</span><span class="va">True</span>, stat<span class="op">=</span><span class="st">"density"</span>, linewidth<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Original Labels'</span>)</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>sns.histplot(transformed_labels, ax<span class="op">=</span>axes[<span class="dv">0</span>, <span class="dv">1</span>], color<span class="op">=</span><span class="st">"green"</span>, kde<span class="op">=</span><span class="va">True</span>, stat<span class="op">=</span><span class="st">"density"</span>, linewidth<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'Transformed Labels'</span>)</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot distribution of a key feature</span></span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>sns.histplot(original_feature, ax<span class="op">=</span>axes[<span class="dv">1</span>, <span class="dv">0</span>], color<span class="op">=</span><span class="st">"blue"</span>, kde<span class="op">=</span><span class="va">True</span>, stat<span class="op">=</span><span class="st">"density"</span>, linewidth<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_title(<span class="st">'Original Feature Distribution'</span>)</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>sns.histplot(transformed_feature, ax<span class="op">=</span>axes[<span class="dv">1</span>, <span class="dv">1</span>], color<span class="op">=</span><span class="st">"green"</span>, kde<span class="op">=</span><span class="va">True</span>, stat<span class="op">=</span><span class="st">"density"</span>, linewidth<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_title(<span class="st">'Transformed Feature Distribution'</span>)</span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section>
<section id="train-logistic-regression-with-reweighed-dataset" class="level2">
<h2 class="anchored" data-anchor-id="train-logistic-regression-with-reweighed-dataset">Train Logistic Regression with reweighed dataset</h2>
<p>Now, <strong>let’s see, if we can train a fairer model, using this preprocessing technique</strong> of reweighting - promising to make our results less bias. First, we neet to train with the tranformed data and then predict our outcome on the transformed test dataset.</p>
<div id="8089fc18" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>scale_transf <span class="op">=</span> StandardScaler()</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>X_reweighed_train <span class="op">=</span> scale_transf.fit_transform(transf_train.features)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>y_reweighed_train <span class="op">=</span> transf_train.labels.ravel()</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>lmod <span class="op">=</span> LogisticRegression()</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>lmod.fit(X_reweighed_train, y_reweighed_train,</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>        sample_weight<span class="op">=</span>transf_train.instance_weights)</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> lmod.predict(X_reweighed_train)</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>transf_test <span class="op">=</span> RW.transform(test)</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>scale_transf <span class="op">=</span> StandardScaler()</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>X_reweighed_test <span class="op">=</span> scale_transf.fit_transform(transf_test.features)</span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>y_reweighed_test <span class="op">=</span> transf_test.labels.ravel()</span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on test</span></span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> lmod.predict(X_reweighed_test)</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>X_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>array([[0.        , 0.        , 0.        , ..., 0.02631579, 1.        ,
        0.40499307],
       [0.        , 0.5       , 1.        , ..., 0.        , 1.        ,
        0.82385576],
       [0.        , 1.        , 0.        , ..., 0.26315789, 1.        ,
        0.24479889],
       ...,
       [0.        , 0.5       , 0.        , ..., 0.05263158, 1.        ,
        0.18862691],
       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,
        0.93273232],
       [1.        , 0.5       , 0.        , ..., 0.42105263, 1.        ,
        0.60679612]])</code></pre>
</div>
</div>
<p><br></p>
<p>We want to print the calculated ratios, providing insights into the relative proportions of African-American to Caucasian individuals and the predicted reoffense ratios based on the model’s predictions on the transformed data, as we did for the original data in the beginning. And wohoo! The <strong>predictions are now closer to the ratio, meaning that our prediction got less biased.</strong> And: we didn’t have to sacrifice accuracy for that!</p>
<p><br></p>
<div id="7e2905eb" class="cell" data-execution_count="42">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create boolean masks for African-American and Caucasian groups</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Make sure these masks are created from the dataset used for the predictions</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>afr_am_mask <span class="op">=</span> (transf_test.features[:, <span class="dv">0</span>] <span class="op">==</span> <span class="dv">0</span>)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>white_mask <span class="op">=</span> (transf_test.features[:, <span class="dv">0</span>] <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the masks to the predictions</span></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>pred_afr_am <span class="op">=</span> y_pred[afr_am_mask]</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>pred_white <span class="op">=</span> y_pred[white_mask]</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the Black to White Prisoners Ratio</span></span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Count of African-American individuals divided by count of Caucasian individuals</span></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>ratio_afr_am_white <span class="op">=</span> np.<span class="bu">sum</span>(afr_am_mask) <span class="op">/</span> np.<span class="bu">sum</span>(white_mask)</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the Predicted Reoffense Ratio for Blacks to Whites</span></span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum of predicted reoffenses for African-Americans divided by sum for Caucasians</span></span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>ratio_pred_reoffense <span class="op">=</span> np.<span class="bu">sum</span>(pred_afr_am <span class="op">==</span> <span class="dv">1</span>) <span class="op">/</span> np.<span class="bu">sum</span>(pred_white <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Black to white prisoners ratio:"</span>, np.<span class="bu">round</span>(ratio_afr_am_white, <span class="dv">2</span>))</span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Predicted reoffense blacks to whites ratio:"</span>, np.<span class="bu">round</span>(ratio_pred_reoffense, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Black to white prisoners ratio: 1.5
Predicted reoffense blacks to whites ratio: 1.85</code></pre>
</div>
</div>
<div id="f4150773" class="cell" data-execution_count="43">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> lmod.predict(X_reweighed_test)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> np.<span class="bu">sum</span>(y_pred <span class="op">==</span> y_reweighed_test) <span class="op">/</span> <span class="bu">len</span>(y_reweighed_test)</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy ="</span>, np.<span class="bu">round</span>(acc, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy = 0.875</code></pre>
</div>
</div>
<div id="d019c71c" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>privileged_groups_new <span class="op">=</span> [{protected: <span class="dv">1</span>}]</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>unprivileged_groups_new <span class="op">=</span> [{protected: <span class="dv">0</span>}]</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> BinaryLabelDatasetMetric(transf_test.copy(), <span class="co">#</span></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>                              privileged_groups<span class="op">=</span>privileged_groups_new,</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>                              unprivileged_groups<span class="op">=</span>unprivileged_groups_new)</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>DIs.append(cm.disparate_impact())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p>When we apply the reweighted dataset to train a model and subsequently calculate fairness metrics like Disparate Impact (DI), we typically expect the DI values to move towards 1, signaling reduced bias. The marked increase in DI at this full repair level indicates that the algorithm has substantially adjusted the instance weights, aiming to correct for disparities.</p>
<p><br></p>
<div id="276a779c" class="cell" data-execution_count="45">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming DIs is your list of disparate impact values with the appropriate length</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot with increased marker size and line width</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>plt.plot(np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">12</span>), DIs, marker<span class="op">=</span><span class="st">'o'</span>, markersize<span class="op">=</span><span class="dv">8</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Disparate Impact'</span>)</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Green line for the ideal value of DI = 1</span></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">1</span>, <span class="dv">1</span>], <span class="st">'g'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Ideal Value'</span>)</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Red line for threshold</span></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="fl">0.8</span>, <span class="fl">0.8</span>], <span class="st">'r'</span>, linestyle<span class="op">=</span><span class="st">'-.'</span>, label<span class="op">=</span><span class="st">'Threshold'</span>)</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>plt.ylim([<span class="fl">0.7</span>, <span class="fl">1.1</span>])</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Setting font size for labels and title</span></span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Disparate Impact (DI)'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Repair Level'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Adding grid, legend, and tight layout</span></span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-25"><a href="#cb58-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the plot</span></span>
<span id="cb58-26"><a href="#cb58-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="post-processing-mitigation-strategy" class="level2">
<h2 class="anchored" data-anchor-id="post-processing-mitigation-strategy">Post-processing Mitigation Strategy</h2>
<section id="reject-option-classification" class="level3">
<h3 class="anchored" data-anchor-id="reject-option-classification">Reject Option Classification</h3>
<p>Last but not least we want to present a post-processing strategy to mitigate bias. The goal of Reject Option Classification is to improve the fairness of predictions made by a classifier. Let’s give you an overview of this technique:</p>
<ul>
<li><p><strong>Classifier Prediction</strong>: First, you have a classifier that has been trained on your dataset and makes predictions about new instances.</p></li>
<li><p><strong>Confidence Interval</strong>: <strong>Reject Option Classification operates on a confidence interval around the decision boundary of the classifier.</strong> This is where the classifier’s certainty about its predictions is lower.</p></li>
<li><p><strong>Protected Attribute</strong>: It uses a protected attribute (in our case: race) to determine where bias might be present in these uncertain predictions.</p></li>
<li><p><strong>Favorable Outcomes</strong>: For instances within the confidence interval, if they belong to the unprivileged group, the algorithm can change an unfavorable outcome to a favorable one. Conversely, for the privileged group, it can change a favorable outcome to an unfavorable one.</p></li>
<li><p><strong>Fairness Enhancement</strong>: The idea is to <strong>“reject” the initial decision (hence the name) in favor of one that will lead to a more balanced distribution</strong> of positive outcomes between the privileged and unprivileged groups.</p></li>
<li><p><strong>Balancing Performance and Fairness</strong>: This method aims to balance the overall performance of the classifier (in terms of accuracy, precision, etc.) with fairness considerations. It seeks to ensure that the positive predictive value (the probability that subjects with a positive screening test truly have the disease) is similar across groups.</p></li>
</ul>
<div id="d8c02440" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Identifying the Favorable Outcome Index</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>pos_ind <span class="op">=</span> np.where(lmod.classes_ <span class="op">==</span> transf_train.favorable_label)[<span class="dv">0</span>][<span class="dv">0</span>] <span class="co">#We identify the favorable outcome index</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Fit the scaler on the training data and transform the training features</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>scale_transf <span class="op">=</span> StandardScaler() <span class="co">#We fit the scaler on the training data and transform the training features</span></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>X_reweighed_train <span class="op">=</span> scale_transf.fit_transform(transf_train.features) <span class="co">#We fit the scaler on the training data and transform the training features</span></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Transform the test features using the same scaler</span></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a>X_reweighed_test <span class="op">=</span> scale_transf.transform(transf_test.features) <span class="co">#We transform the test features using the same scaler</span></span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a><span class="co">#Copy the datasets</span></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a>transf_train_post <span class="op">=</span> transf_train.copy() <span class="co">#We copy the datasets</span></span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a>transf_test_post <span class="op">=</span> transf_test.copy() <span class="co">#We copy the datasets</span></span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a><span class="co">#Predict probabilities and assign scores for the training and test sets</span></span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a>transf_train_post.scores <span class="op">=</span> lmod.predict_proba(X_reweighed_train)[:, pos_ind].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="co">#We predict probabilities and assign scores for the training and test sets</span></span>
<span id="cb59-17"><a href="#cb59-17" aria-hidden="true" tabindex="-1"></a>transf_test_post.scores <span class="op">=</span> lmod.predict_proba(X_reweighed_test)[:, pos_ind].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="co">#We predict probabilities and assign scores for the training and test sets</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="59c64f08" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>metric_ub <span class="op">=</span> <span class="fl">0.05</span> <span class="co">#We set the upper bound for the metric</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>metric_lb <span class="op">=</span> <span class="op">-</span><span class="fl">0.05</span> <span class="co">#We set the lower bound for the metric</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>ROC <span class="op">=</span> RejectOptionClassification(unprivileged_groups<span class="op">=</span>unprivileged_groups, <span class="co">#We set the upper bound for the metric</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>                                 privileged_groups<span class="op">=</span>privileged_groups, <span class="co">#We set the lower bound for the metric</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>                                 low_class_thresh<span class="op">=</span><span class="fl">0.01</span>, <span class="co">#Range of decision thresholds to consider for potential adjustment.</span></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>                                 high_class_thresh<span class="op">=</span><span class="fl">0.99</span>, <span class="co">#Range of decision thresholds to consider for potential adjustment.</span></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>                                  num_class_thresh<span class="op">=</span><span class="dv">100</span>, <span class="co">#Number of decision thresholds to be considered within the specified range</span></span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>                                  num_ROC_margin<span class="op">=</span><span class="dv">50</span>, <span class="co">#Number of margins to be examined around the decision threshold where ROC will adjust the classifier's predictions.</span></span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>                                  metric_name<span class="op">=</span> <span class="st">'Statistical parity difference'</span>, <span class="co">#Metric used to measure fairness for determining thresholds</span></span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a>                                  metric_ub<span class="op">=</span>metric_ub, metric_lb<span class="op">=</span>metric_lb) <span class="co">#Upper and lower bound for the fairness metric used to determine thresholds</span></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>ROC <span class="op">=</span> ROC.fit(transf_test, transf_test_post)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The technique learns how to adjust the decision thresholds based on the scores and labels in transf_test_post such that the fairness metric (Statistical parity difference in this case) falls between the bounds specified earlier (metric_ub and metric_lb). The dataset transf_test is used as a reference for the original decision making, which transf_test_post presumably improves upon.</p>
<div id="d32266f9" class="cell" data-execution_count="48">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal classification threshold (with fairness constraints) = </span><span class="sc">%.4f</span><span class="st">"</span> <span class="op">%</span> ROC.classification_threshold)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal ROC margin = </span><span class="sc">%.4f</span><span class="st">"</span> <span class="op">%</span> ROC.ROC_margin)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Optimal classification threshold (with fairness constraints) = 0.8217
Optimal ROC margin = 0.0146</code></pre>
</div>
</div>
<p>ROC algorithm has identified 0.8217 as the decision threshold that best balances the classifier’s performance with the fairness constraints that were set. Optimal ROC margin = 0.0146. This margin is where the algorithm is most active in adjusting predictions to improve fairness. if an instance belonging to the unprivileged group has a score slightly below the threshold, it might be pushed above the threshold to receive a favorable outcome. Conversely, an instance from the privileged group with a score just above the threshold might be pulled below it to receive an unfavorable outcome. the Algorithm has found a way to adjust the classifier’s predictions to conform to the fairness constraints without excessively compromising its predictive performance</p>
<p>The purpose of this function is to evaluate the performance of a classification model from both a standard accuracy perspective and a fairness perspective.</p>
<div id="a9ef94ff" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_metrics(dataset_true, dataset_pred,</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>                    unprivileged_groups, privileged_groups,</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>                    disp<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">""" Compute the key metrics """</span></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>    classified_metric_pred <span class="op">=</span> ClassificationMetric(dataset_true, dataset_pred,</span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>                                                  unprivileged_groups<span class="op">=</span>unprivileged_groups,</span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>                                                  privileged_groups<span class="op">=</span>privileged_groups)</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize an empty OrderedDict</span></span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute all required metrics at once</span></span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>    metrics <span class="op">=</span> OrderedDict([</span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Balanced accuracy"</span>, <span class="fl">0.5</span> <span class="op">*</span> (classified_metric_pred.true_positive_rate() <span class="op">+</span></span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>                                     classified_metric_pred.true_negative_rate())),</span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Statistical parity difference"</span>, classified_metric_pred.statistical_parity_difference()),</span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Disparate impact"</span>, classified_metric_pred.disparate_impact()),</span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Average odds difference"</span>, classified_metric_pred.average_odds_difference()),</span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Equal opportunity difference"</span>, classified_metric_pred.equal_opportunity_difference()),</span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Theil index"</span>, classified_metric_pred.theil_index())</span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> disp:</span>
<span id="cb63-21"><a href="#cb63-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Display metrics in a formatted way</span></span>
<span id="cb63-22"><a href="#cb63-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> metric_name, metric_value <span class="kw">in</span> metrics.items():</span>
<span id="cb63-23"><a href="#cb63-23" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>metric_name<span class="sc">}</span><span class="ss"> = </span><span class="sc">{</span>metric_value<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb63-24"><a href="#cb63-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-25"><a href="#cb63-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="7cc84bba" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Metrics for the transformed test set</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>dataset_transf_test_post <span class="op">=</span> ROC.predict(transf_test_post)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>metric_test_aft <span class="op">=</span> compute_metrics(transf_test, dataset_transf_test_post,</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>                unprivileged_groups, privileged_groups)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Balanced accuracy = 0.8963
Statistical parity difference = -0.0066
Disparate impact = 0.9852
Average odds difference = -0.0173
Equal opportunity difference = -0.0381
Theil index = 0.1148</code></pre>
</div>
</div>
<p>Using this technique, we get very nice results for both: Our model’s performance and its fairness measures.</p>
<p><strong>Balanced Accuracy (0.8963)</strong> :</p>
<p>Good overall accuracy of the model. Balanced accuracy takes into account both the true positive rate and true negative rate.</p>
<p><strong>Statistical Parity Difference (-0.0066)</strong></p>
<p>It indicates that the probability of a positive outcome (favorable prediction) is nearly equal for both privileged and unprivileged groups</p>
<p><strong>Disparate Impact (0.9852)</strong></p>
<p>A value close to 1 indicates fair treatment between the groups. Specifically, a value of 1 would imply perfect fairness. The model’s predictions do not disproportionately favor one group over the other</p>
<p><strong>Average Odds Difference (-0.0173)</strong></p>
<p>Equality of odds between unprivileged and privileged groups. A value of 0 would mean perfect equality. The value -0.0173 indicates a small bias against the unprivileged group in terms of false positive and true positive rates, but this bias is relatively minor now.</p>
<p><strong>Equal Opportunity Difference (-0.0381)</strong></p>
<p>True positive rates between groups. A value of 0 represents equal opportunity. The value -0.0381 suggests a slight bias against the unprivileged group in terms of having true positives or favorable outcomes.</p>
<p><strong>Theil Index (0.1148)</strong></p>
<p>Theil index is a measure of inequality. A value of 0 indicates perfect equality, while higher values show greater inequality. A value of 0.1148 indicates some inequality in the model’s predictions, but it’s not excessively high</p>
</section>
</section>
<section id="results-and-discussion" class="level2">
<h2 class="anchored" data-anchor-id="results-and-discussion">Results and Discussion</h2>
<p>The tutorial introduced how to detect bias and helps the user to replicate a biased CNN in order to understand that bias is something, you always have to keep in mind when training your model.</p>
<p>In the last and most central part of the tutorial we introduced different approaches to mitigate bias. To conclude, we can state that <strong>we successfully debiased the data</strong>, as the last list of performance and fairness metric demonstrates. Beginning with relatively high bias, we applied - first, we used the <strong>disparate impact remover, showing some, but not an exceptional improvement</strong> in bias metrics. - We could reach a better result, applying our second preprocessing strategy, namely <strong>reweighting our data</strong> before training our model with it. - Last but not least, we applied a post processing technique, <strong>Reject Option Classification, that also lead to good results, debiasing our data.</strong></p>
<p>All of these steps demonstrate that there are <strong>different strategies for each part of our data and model pipeline </strong>to adress bias and find strategies to come to fairer results.</p>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<p>The greatest limitation of this tutorial potentially comes from the chosen data source: The COMPAS data already comes in a quite tidy format and previous analyses already identified the most pressing issues of the data set. When applying the detection and mitigation techniques demonstrated in this tutorial, <strong>students and researcher should be aware that alternative data sets need to be carefully cleaned</strong>before calculating bias metrices and applying mitigation strategies.</p>
<p>Moreover, this tutorial focuses on one specific data input type. When <strong>other data types</strong> are considered (e.g.&nbsp;image, video, or time-series), detection and mitigation strategies potentially need to be adapted.</p>
<p>As introduced in the tutorial memo, <strong>there are numerous distinct types of biases</strong> that can occur in the machine/deep learning pipeline. This tutorial focused on biased data, especially on representation bias. Applied to different data sets, students and researchers should also check for other types of bias (e.g.&nbsp;measurement bias). Additionally, not only the data should be tested for bias, but also implemented models and model evaluating should be critically exmined.</p>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<p>This tutorial serves as a first introduction to the topic of bias and fairness - we hope that it gave a good overview of the related issues and possible solutions to tackle them. As next steps we propose that users of the tutorial look for <strong>another dataset and try to apply the newly acquired tools</strong> (unfortuately it is not a challenge to find biased datasets on Kaggle or other online platforms).</p>
<p>To dig deeper in the deep learning application it could be interesting to check out the topic of bias and fairness in other data types like images and text data. It would have exceeded the scope of our tutorial but there are very interesting approaches of bias mitigation in Natural Language Processing, for example the approach of text pertubation to train fairer models (https://ai.meta.com/blog/measure-fairness-and-mitigate-ai-bias/). <strong>For policy application, text data is very important thus we can only recommend the users to get familiar with such techniques.</strong></p>
<p>To conclude, <strong>we know that we could only show a very small part of bias detection and mitigation strategies</strong> - so we don’t expect the users to be experts for this area coming out of this tutorial. <strong>More importantly we hope that we might have shifted the user’s view on the importance of bias related issues</strong>. This could be a first step to raise awareness for his crucial part of machine and deep learning - which so far is too often ommitted or neglected.</p>
<hr>
</section>
</section>
<section id="references" class="level1">
<h1>References</h1>
<hr>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
References
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Regean, Mary. 2021. “Understanding bias and fairness in AI system”. <a href="https://towardsdatascience.com/understanding-bias-and-fairness-in-aisystems-6f7fbfe267f3">URL</a></p></li>
<li><p>Anaconda, 2021 State of Data Science Report. <a href="https://know.anaconda.com/rs/387-XNW-688/images/Anaconda-2021-SODS-Report-Final.pdf">URL</a></p></li>
<li><p>Clark, Andrew. September 19, 2022. “Top bias metrics and how they work”. Monitaur. <a href="https://www.monitaur.ai/blog-posts/top-bias-metricsand-how-they-work">URL</a></p></li>
<li><p>Feldman et al.&nbsp;„Certifying and Removing Disparate Impact“. Proceedings of the 21th ACM SIGKDD International Conference on KnowledgeDiscovery and Data Mining, ACM, 2015, S. 259–68. DOI.org (Crossref), <a href="https://doi.org/10.1145/2783258.2783311">URL</a>.</p></li>
<li><p>Towards datascience, “AI Fairness — Explanation of Disparate Impact Remover”. <a href="https://towardsdatascience.com/ai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1">URL</a></p></li>
<li><p>Lee, Nicol Turner, Paul Resnick, and Genie Barton. “Algorithmic bias detection and mitigation: Best practices and policies to reduce consumer harms.” Brookings Institute: Washington, DC, USA 2 (2019)</p></li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Cite this page: Roa, J. (2023, April 16). <em>Understanding R Objects: Data Structures and Classes in R</em>. /. <a href="https://www.hertiecodingclub.com/learn/rstudio/rstudio101/">URL</a></p>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://creativecommons.org/licenses/by/2.0/">
<p><i class="fa-regular fa-copyright fa-s" aria-label="copyright"></i> 2024</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
<p>· <a href="https://quarto.org/"><img src="https://quarto.org/quarto.png" class="img-fluid" alt="Quarto" width="65"></a> engine ·</p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://github.com">
<p><i class="fa-brands fa-github fa-lg" aria-label="github"></i></p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://twitter.com">
<p><i class="fa-brands fa-x-twitter fa-lg" aria-label="x-twitter"></i></p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://www.linkedin.com">
<p><i class="fa-brands fa-linkedin fa-lg" aria-label="linkedin"></i></p>
</a>
  </li>  
</ul>
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"openEffect":"fade","skin":"lightwidth","selector":".lightbox","closeEffect":"fade","loop":false,"descPosition":"left"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




<script src="../../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>