[
  {
    "objectID": "for_instructors/instructors.html",
    "href": "for_instructors/instructors.html",
    "title": "{{< fa solid scale-balanced >}} Ethics <span style='font-size: 18px;'>&#x2715;</span> Data Science {{< fa solid code-branch >}}",
    "section": "",
    "text": "Welcome to the “For Instructors” section of “Data Science X Ethics” – a dedicated space where education meets innovation at the crossroads of data science and ethical responsibility. As educators shaping the next generation of data scientists, your role in integrating ethical considerations into the technical curriculum is more crucial than ever. In this era of rapid technological advancement, teaching data science is not just about coding, algorithms, and data analysis; it’s equally about instilling a strong ethical foundation in your students. Click here to access the Instructor’s Guide for “Data Science X Ethics.”"
  },
  {
    "objectID": "for_instructors/instructors.html#for-instructors",
    "href": "for_instructors/instructors.html#for-instructors",
    "title": "{{< fa solid scale-balanced >}} Ethics <span style='font-size: 18px;'>&#x2715;</span> Data Science {{< fa solid code-branch >}}",
    "section": "For instructors",
    "text": "For instructors\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nData Science\n\n\nSubtitle or Brief Description\n\n\n\nCategory1\n\n\nCategory2\n\n\nCategory3\n\n\n\n\n\n\nInvalid Date\n\n\nYour Name\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nEthics\n\n\nSubtitle or Brief Description\n\n\n\nCategory1\n\n\nCategory2\n\n\nCategory3\n\n\n\n\n\n\nInvalid Date\n\n\nYour Name\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "for_instructors/guide/ethics/index.html",
    "href": "for_instructors/guide/ethics/index.html",
    "title": "Ethics",
    "section": "",
    "text": "Your important content or announcement goes here."
  },
  {
    "objectID": "for_instructors/guide/ethics/index.html#important-section-title",
    "href": "for_instructors/guide/ethics/index.html#important-section-title",
    "title": "Ethics",
    "section": "",
    "text": "Your important content or announcement goes here."
  },
  {
    "objectID": "for_instructors/guide/ethics/index.html#subsection-title",
    "href": "for_instructors/guide/ethics/index.html#subsection-title",
    "title": "Ethics",
    "section": "Subsection Title",
    "text": "Subsection Title\nDetails about the subsection. This can include code snippets, explanations, or any relevant information.\n\n# R code goes here\n\n# Example\n\nx &lt;- 1:10\n\ny &lt;- x^2\n\nplot(x, y)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nCite this page: Lehmann, L. (2023, April 18). Introduction to Social Media Scraping. Hertie Coding Club. URL"
  },
  {
    "objectID": "ethics/ethics/example/index.html",
    "href": "ethics/ethics/example/index.html",
    "title": "Your Document Title",
    "section": "",
    "text": "Your important content or announcement goes here."
  },
  {
    "objectID": "ethics/ethics/example/index.html#important-section-title",
    "href": "ethics/ethics/example/index.html#important-section-title",
    "title": "Your Document Title",
    "section": "",
    "text": "Your important content or announcement goes here."
  },
  {
    "objectID": "ethics/ethics/example/index.html#subsection-title",
    "href": "ethics/ethics/example/index.html#subsection-title",
    "title": "Your Document Title",
    "section": "Subsection Title",
    "text": "Subsection Title\nDetails about the subsection. This can include code snippets, explanations, or any relevant information.\n\n# R code goes here\n\n# Example\n\nx &lt;- 1:10\n\ny &lt;- x^2\n\nplot(x, y)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nCite this page: Lehmann, L. (2023, April 18). Introduction to Social Media Scraping. Hertie Coding Club. URL"
  },
  {
    "objectID": "ethics/ethics/approaches/index.html",
    "href": "ethics/ethics/approaches/index.html",
    "title": "Frameworks",
    "section": "",
    "text": "Main idea\n\n\n\nData science ethics is often seen through the frameworks of responsibility or bias. We add to this the moral practice framework.\n\n\n\n\n\n\n\n\nTheory warning\n\n\n\nThis module is very theoretical: meta-theoretical. It offers a hypothesis about the space of theories of data science ethics.\n\n\n\nIntroduction\nSuppose you could magically make one of three things happen.\n\nData science will get a code of ethics and all data scientists will have to take a professional oath on this code.\nData science will solve bias. Data scientists check their implicit biases, teams are more diverse, and data is more representative and inclusive.\nData science will champion moral reasoning. Data scientists recognize ethical dilemmas, explain them, and work with others to solve them.\n\nEach of these are good options. Here, we want to make a case for the third.\nEach of these options stands for a different framework of data science ethics. Each is backed up by a different view of what kinds of ethical challenges data science raises. As such, each of the three options is a set of tools that fits with its respective view of the challenges. We call these three frameworks the responsibility, bias, and practice approach.\nIt’s important to be clear about your framework for the ethics of data science. Depending on what kind of ethical challenges you think data science raises, you need to chose your tools appropriately.\n\n\n\n\n\n\nTip\n\n\n\nDepending on your framework, you do the ethics of data science differently.\n\n\nThis module enables you to see the bigger picture in the ethics of data science. And to make your choice of tools more deliberately.\n\n\nResponsibility Approach\nThe first framework to the ethics of data science centers on people. It says that the general problem in the ethics of data science has to to with data scientists themselves. Data scientists lack a sense of responsibility.\nAccordingly, proponents of this approach, such as Cathy O’Neill, argue that data scientists should take a professional oath. Such an oath, taken with the right intention, is a key part of building a sense a professional responsibility. Such oaths are familiar from other professions, such as medicine, engineering, or public administration.\nA sense of professional responsibility can be built in different ways. For starters, data scientists need to know about the consequences of their work. Data scientists might lack a sense of responsibility, not only because they don’t care enough, but because they don’t know enough. A high technical complexity, large-scale division of labor, and ideologies might cloud the view of the results of what one is contributing to. And it’s not always easy to know, ahead of time, how a data science project will play out in practice. And even if we could, an individuals can often make very little difference. That means: A sense of responsibility, to be effective, needs to be collectively shared and organized — not an easy thing to do!\nThe good news is: A lot is being done to build such a shared sense of responsibility in data science. It’s hard for data scientists these days not to be confronted with the harms their work may cause. Data science degrees now regularly include education on ethics. And we see emerging legislation to create incentives for data science to care about ethical issues, such as the EU’s AI Act. In this way, a sense of responsibility can be incentivised extrinsically, it must not emerge from the individuals or the profession.\nIn sum, the responsibility approach to the ethics of data science contends that the ethics of data science should be about people and how they organize themselves. The job of ethics, on this approach, is to make data scientists care and make them aware of the consequences of their work. The strategies to achieve this include ethics codes, professional oaths, interdisciplinary collaboration, collaborative governance, and regulation.\n\n\nBias Approach\nA second framework centers on bias—or rather: biases, since bias comes in many different forms. One important form of bias is cognitive. The ethics of data science might be about the cognitive biases, or at least, the biases of its practitioners. As one prominent slogan goes: “All models are biased because humans are biased.” In addition, an ethics of data science that focuses on bias may also proceed on a structural route. Here the focus is not on biases—implicit or explicit, cognitive or behavioral—of individuals but on the biases reflected in the data. Here the slogan could be that “all models are biased because reality is biased.” That is, data represents the injustices and inequities that are out there in our very imperfect world. By the principle of garbage in and garbage out, data science then encodes these biases, entrenches them, or even makes them worse.\nAgain, there is much to this picture. Again, the lessons it imparts were painfully learned. As often with moral progress, society at large and the profession of data science in particular stand in the debt of minority scholars who took on the labor of pointing out what should be obvious. Often failing to “get through,” often belittled, discounted, or dismissed.\nData science has a lot to do with bias. But issues of bias are still at most one part of the ethics of data science. Constructing a measure of “teacher effectiveness” (e.g. as difference of average grades over time), raises methodological and ethical problems that have only little to do with cognitive or structural biases. Likewise, predicting crime or recidivism is beset with biases; but the ethical problems might have to do with the power of the police or the legitimacy of pre-trial detention more broadly than the historic injustice that is reflected in the data.\nAs the word “reflected” already suggests, biases in the data are often not themselves the problem but are indicative or are evidence for the problems that lead to these biases in the first place. The ethics of data science thus should speak to these underlying issues and not only to the bias surfaced in data.\n\n\nMoral Practice Approach\nWe are partial to a third answer. The ethics of data science should center on the practice of data science. Data science is hard—not just technically but also morally. It involves moral dilemmas. These dilemmas often hide behind seemingly technical issues. But the dilemmas are real and it does not good to hide them. In other words: “Data Science is a Moral Practice” is the slogan of this third approach.\nWhen training a model to predict welfare fraud, data scientists need to balance false positives and false negatives. What should be the “exchange rate” between such errors? Similarly, data scientists regularly face a trade-off between accuracy and fairness. This trade-off present itself, for example, in the question of whether, when wanting to predict recidivism, data on arrests for minor, non-violent offenses—where bias is particularly prominent—should be included.\nThat data science is a moral practice becomes particularly clear when we take data science to be much more than data analysis. Communication plays an important—and often neglected—role in data science. Ethical questions abound in communicating in data science and outside of data analysis more broadly. Are there some projects that a data science team must not take on? How should limits of a product be communicated? How much should be done to protect privacy?\nThe moral practice approach contends that you find such thorny questions at each step in the lifecycle of a data science project. Data scientists face moral dilemmas. That is, they face decisions to which moral considerations are relevant and these considerations pull in opposite directions. Each option has moral reasons in its favor but also against it. The moral practice approach to data science seeks to understand these dilemmas to allow data scientists—or anyone interested—to reason through these dilemmas together, to disagree better, and come to a decision on firmer ground.\nPerhaps the time for the moral practice approach has not yet come. For one, bias and a lack of professional responsibility still pervade data science and all societies at large. As such, we urgently need both the responsibility and the bias approach to the ethics of data science. Moreover, the current social and political environment seems rather inhospitable to an open discourse and moral reasoning. The moral practice approach, however, assumes that decisions are made rationally, that individuals are willing to reason about their decisions, and that moral reasoning can play a role in deliberations. Its assumptions hence seem idealistic, naïve, or Panglossian.\nWe disagree. Moral reasoning can work under the right conditions. It is up to every leader to create these conditions. And we positively reject the cynicism behind the suggestion that “this is not going to work anyway.” Moreover, this is a book for the long term. Data science raises old issues—about privacy, justice, and knowledge—anew. These issues are not going away. By contrast, we can hope that the problems that are currently urgent, of problematic biases and a lacking professional responsibility, will be overcome with time.\n\n\nThe Difference a Framework Makes\nHow you approach the ethics of data science is a big decision. Each approach comes with own set of strategies or processes — and things you need to learn and understand.\nHere are some of the different things you would do on each of the three frameworks.\n\n\n\n\n\n\n\n\nResponsibility\nBias\nMoral Practice\n\n\n\n\n\nprofessional oath\nawareness of harms caused by data science projects\nethics codes\n\n\nrepresentative data collection\ntests for construct validity to avoid biased proxy variables\nteam diversity\ntraining and nudging against (implicit) cognitive bias\n\n\nmoral vocabulary\ncommunication skills\nmoral reasoning\nresearch ethics\n\n\n\n\nThe three frameworks are not exclusive in principle. But given realistic limitations you’ll have to prioritize which framework to follow in a given situation."
  },
  {
    "objectID": "data_science/I2DS/i2ds2021/index.html",
    "href": "data_science/I2DS/i2ds2021/index.html",
    "title": "I2DS Tools for Data Science Workshop 2021",
    "section": "",
    "text": "The Introduction to Data Science (IDS) course at the Hertie School in Berlin, Germany, is designed to provide students with a comprehensive understanding of data science principles, techniques, and tools. As part of the course curriculum, students actively engage in organizing workshops and activities to enhance their practical skills and share their knowledge with others.\n \nThese student-led activities, such as the workshop on Tools for Data Science with R, serve as valuable opportunities for participants to gain hands-on experience and learn directly from their peers. The I2DS course encourages students to take the lead in organizing and delivering these workshops, fostering a collaborative learning environment.\n\n\n\n Go to I2DS Tools 2021"
  },
  {
    "objectID": "data_science/data_science.html",
    "href": "data_science/data_science.html",
    "title": "{{< fa solid scale-balanced >}} Ethics <span style='font-size: 18px;'>&#x2715;</span> Data Science {{< fa solid code-branch >}}",
    "section": "",
    "text": "In today’s data-driven world, the power of data science transcends industries, influencing decisions, shaping strategies, and transforming futures. Yet, for many, the field remains shrouded in jargon and complexity. That’s where we step in. Whether you’re a professional looking to leverage data in your field, a student eager to expand your horizons, or simply a data enthusiast, our platform is designed with you in mind.\nThrough a blend of engaging articles, interactive tutorials, and real-world examples, we break down key data science concepts into digestible pieces. From the basics of data analysis and visualization to the intricacies of machine learning and artificial intelligence, we provide a comprehensive learning journey that’s both enjoyable and informative. Our goal is to empower you with the knowledge and skills you need to thrive in the data-driven world."
  },
  {
    "objectID": "data_science/data_science.html#data-science",
    "href": "data_science/data_science.html#data-science",
    "title": "{{< fa solid scale-balanced >}} Ethics <span style='font-size: 18px;'>&#x2715;</span> Data Science {{< fa solid code-branch >}}",
    "section": "Data Science",
    "text": "Data Science\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nYour Document Title\n\n\nSubtitle or Brief Description\n\n\n\nIntermediate\n\n\nCategory2\n\n\nCategory3\n\n\n\n\n\n\nInvalid Date\n\n\nYour Name\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nBias in AI: detection and mitigation\n\n\nEnable users to detect and mitigate bias, using the example of the COMPAS Recidivism Risk Score Data and Analysis Dataset. Users will be equiped with concrete strategies to first detect, and secondly mitigate bias\n\n\n\nAdvanced\n\n\nBias in AI\n\n\nMitigation\n\n\n\n\n\n\nDec 5, 2023\n\n\nJorge Roa, Carlo Greß, Hannah Schweren\n\n\n11 min\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Social Media Scraping\n\n\nLearn the basic tools for scraping Twitter Data in R\n\n\n\nBeginner\n\n\nWebscraping\n\n\nText\n\n\n\n\n\n\nApr 18, 2023\n\n\nLukas Lehmann\n\n\n12 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data_science/ds/objects/index.html",
    "href": "data_science/ds/objects/index.html",
    "title": "Bias in AI: detection and mitigation",
    "section": "",
    "text": "This notebook offers a detailed guide that includes both code and explanations aimed at enabling users to identify and counteract bias within data, specifically using the COMPAS Recidivism Risk Score Data and Analysis Dataset as a case study. It provides users with practical strategies to first detect and then mitigate bias, laying a foundational approach for handling biases effectively in algorithmic processes. The tutorial is designed as an introductory step towards fostering an understanding of the biases that can infiltrate algorithms and promoting the development of ethical AI practices. This is particularly critical in contexts where algorithmic decisions intersect with policy-making, potentially influencing societal outcomes. Through this guide, users will not only learn to recognize biases but also implement measures to address these biases, thereby enhancing the fairness and integrity of AI systems in public and private sectors."
  },
  {
    "objectID": "data_science/ds/objects/index.html#numeric-values",
    "href": "data_science/ds/objects/index.html#numeric-values",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Numeric values",
    "text": "Numeric values\nA numeric object can be stored as a number.\n\nx &lt;- 6\n\nclass(x)\n\n[1] \"numeric\"\n\nx\n\n[1] 6"
  },
  {
    "objectID": "data_science/ds/objects/index.html#character-values",
    "href": "data_science/ds/objects/index.html#character-values",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Character values",
    "text": "Character values\nStores a sequence of characters, such as letters, numbers, and symbols. A character value is created by enclosing the sequence of characters within quotation marks, either single or double.\n\ncharacter &lt;- \"Welcome to the Hertie Coding Club\"   # creating a character value\n\nCharacter values can be combined using the paste() or paste0() functions, which concatenate two or more character values into a single character value.\n\nx &lt;- \"Welcome to\"\ny &lt;- \"the Hertie Coding Club\"\nz &lt;- paste(x, y, sep = \": \")\n\n\nclass(z)\n\n[1] \"character\"\n\nz\n\n[1] \"Welcome to: the Hertie Coding Club\""
  },
  {
    "objectID": "data_science/ds/objects/index.html#create-a-numeric-vector",
    "href": "data_science/ds/objects/index.html#create-a-numeric-vector",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Create a numeric vector",
    "text": "Create a numeric vector\n\nx &lt;- c(1, 2, 3, 4, 5)\n\nx\n\n[1] 1 2 3 4 5"
  },
  {
    "objectID": "data_science/ds/objects/index.html#access-elements-of-a-vector",
    "href": "data_science/ds/objects/index.html#access-elements-of-a-vector",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Access elements of a vector",
    "text": "Access elements of a vector\nReturns the second element of x, which is 2\n\nx[2] \n\n[1] 2"
  },
  {
    "objectID": "data_science/ds/objects/index.html#perform-arithmetic-operations",
    "href": "data_science/ds/objects/index.html#perform-arithmetic-operations",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Perform arithmetic operations",
    "text": "Perform arithmetic operations\nAdds 2 to each element of x, resulting in the vector c(3, 4, 5, 6, 7)\n\nx + 2 \n\n[1] 3 4 5 6 7"
  },
  {
    "objectID": "data_science/ds/objects/index.html#find-the-length-of-a-vector",
    "href": "data_science/ds/objects/index.html#find-the-length-of-a-vector",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Find the length of a vector:",
    "text": "Find the length of a vector:\n\nlength(x) \n\n[1] 5"
  },
  {
    "objectID": "data_science/ds/objects/index.html#modify-a-vector",
    "href": "data_science/ds/objects/index.html#modify-a-vector",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Modify a vector",
    "text": "Modify a vector\nChanges the third element of x to 10\n\nx[3] &lt;- 10\n\nx\n\n[1]  1  2 10  4  5"
  },
  {
    "objectID": "data_science/ds/objects/index.html#apply-functions-to-a-vector",
    "href": "data_science/ds/objects/index.html#apply-functions-to-a-vector",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Apply functions to a vector",
    "text": "Apply functions to a vector\nReturns the sum of the elements in x, which is 22\n\nsum(x) \n\n[1] 22\n\n\nReturns the mean (average) of the elements in x, which is 4.4\n\nmean(x)\n\n[1] 4.4\n\n\nReturns the maximum value in x, which is 10\n\nmax(x)\n\n[1] 10\n\n\nReturns the minimum value in x, which is 1\n\nmin(x)\n\n[1] 1\n\n\n \nIn addition to numeric values, you can put a wide variety of other data types in a vector in R. Here are some examples:"
  },
  {
    "objectID": "data_science/ds/objects/index.html#character-values-1",
    "href": "data_science/ds/objects/index.html#character-values-1",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Character values",
    "text": "Character values\n\nnames &lt;- c(\"Hertie School\", \"Berlin\", \"Public Policy\")\n\nnames\n\n[1] \"Hertie School\" \"Berlin\"        \"Public Policy\""
  },
  {
    "objectID": "data_science/ds/objects/index.html#logical-values",
    "href": "data_science/ds/objects/index.html#logical-values",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Logical values",
    "text": "Logical values\n\nflags &lt;- c(TRUE, FALSE, TRUE)\n\nflags\n\n[1]  TRUE FALSE  TRUE"
  },
  {
    "objectID": "data_science/ds/objects/index.html#times",
    "href": "data_science/ds/objects/index.html#times",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Times:",
    "text": "Times:\n\ntimes &lt;- as.POSIXct(c(\"2022-01-01 10:00:00\", \"2022-01-01 11:00:00\", \"2022-01-01 12:00:00\"))\n\ntimes\n\n[1] \"2022-01-01 10:00:00 CET\" \"2022-01-01 11:00:00 CET\"\n[3] \"2022-01-01 12:00:00 CET\""
  },
  {
    "objectID": "data_science/ds/objects/index.html#a-list-with-different-type-of-vectors",
    "href": "data_science/ds/objects/index.html#a-list-with-different-type-of-vectors",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "A list with different type of vectors",
    "text": "A list with different type of vectors\n\nmy_list &lt;- list(numbers = c(1, 2, 3), names = c(\"Alejandro\", \"Eduardo\", \"Fernanda\"), statement = c(TRUE, FALSE, TRUE))\n\nmy_list\n\n$numbers\n[1] 1 2 3\n\n$names\n[1] \"Alejandro\" \"Eduardo\"   \"Fernanda\" \n\n$statement\n[1]  TRUE FALSE  TRUE"
  },
  {
    "objectID": "data_science/ds/objects/index.html#access-an-element-of-the-list-using-indexing",
    "href": "data_science/ds/objects/index.html#access-an-element-of-the-list-using-indexing",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Access an element of the list using indexing",
    "text": "Access an element of the list using indexing\nWe can access an element of the list using indexing, which is really useful when you are doing functions and storing results or calling them.\nHere this returns the second element of my_list, which is the character vector “names”\n\nmy_list[[2]]\n\n[1] \"Alejandro\" \"Eduardo\"   \"Fernanda\" \n\n\nor also we can access an element of the list using named indexing:\n\nmy_list[[\"names\"]]\n\n[1] \"Alejandro\" \"Eduardo\"   \"Fernanda\""
  },
  {
    "objectID": "data_science/ds/objects/index.html#add-a-new-element-to-the-list",
    "href": "data_science/ds/objects/index.html#add-a-new-element-to-the-list",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Add a new element to the list:",
    "text": "Add a new element to the list:\nAdds a new numeric vector “ages” to my_list\n\nmy_list[[\"ages\"]] &lt;- c(25, 30, 35)\n\nWe can do the same even with a dataframe inside a list\n\ndf &lt;- data.frame(name = c(\"Alejandro\", \"Eduardo\", \"Marifer\"), \n                 age = c(30, 27, 17)) # Create the dataframe\n\nmy_list[[\"my_df\"]] &lt;- df\n\nmy_list\n\n$numbers\n[1] 1 2 3\n\n$names\n[1] \"Alejandro\" \"Eduardo\"   \"Fernanda\" \n\n$statement\n[1]  TRUE FALSE  TRUE\n\n$ages\n[1] 25 30 35\n\n$my_df\n       name age\n1 Alejandro  30\n2   Eduardo  27\n3   Marifer  17"
  },
  {
    "objectID": "data_science/ds/objects/index.html#create-a-nested-list-with-two-elements",
    "href": "data_science/ds/objects/index.html#create-a-nested-list-with-two-elements",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Create a nested list with two elements:",
    "text": "Create a nested list with two elements:\n\nnested_list &lt;- list(numbers = c(1, 2, 3), list_2 = list(letter = \"A\", number = 42))\n\nnested_list\n\n$numbers\n[1] 1 2 3\n\n$list_2\n$list_2$letter\n[1] \"A\"\n\n$list_2$number\n[1] 42\n\n\nFor access a nested element of the list:\n\nnested_list[[\"list_2\"]][[\"number\"]]  \n\n[1] 42\n\n\nAs you can see, we can access the outputs of the list we want. This is useful since you can apply functions to retrieve your data from a nested list or access to a specific output of your model, for example."
  },
  {
    "objectID": "data_science/ds/objects/index.html#createing-a-matrix",
    "href": "data_science/ds/objects/index.html#createing-a-matrix",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Createing a matrix",
    "text": "Createing a matrix\nCreate a matrix with three rows and four columns:\n\nm_example &lt;- matrix(1:12, nrow = 3, ncol = 4)\n\nm_example\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12"
  },
  {
    "objectID": "data_science/ds/objects/index.html#access-an-element-of-the-matrix-using-indexing",
    "href": "data_science/ds/objects/index.html#access-an-element-of-the-matrix-using-indexing",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Access an element of the matrix using indexing",
    "text": "Access an element of the matrix using indexing\nReturns the element in the second row and third column of my_matrix, which is 7\n\nm_example[2, 3] \n\n[1] 8"
  },
  {
    "objectID": "data_science/ds/objects/index.html#modify-an-element-of-the-matrix",
    "href": "data_science/ds/objects/index.html#modify-an-element-of-the-matrix",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Modify an element of the matrix",
    "text": "Modify an element of the matrix\nChanges the element in the first row and fourth column of my_matrix to 20\n\nm_example[1, 4] &lt;- 20  \n\nm_example\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   20\n[2,]    2    5    8   11\n[3,]    3    6    9   12"
  },
  {
    "objectID": "data_science/ds/objects/index.html#create-an-array-with-three-dimensions",
    "href": "data_science/ds/objects/index.html#create-an-array-with-three-dimensions",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Create an array with three dimensions",
    "text": "Create an array with three dimensions\n\narr_example &lt;- array(1:24, dim = c(2, 3, 4))\n\narr_example\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]    7    9   11\n[2,]    8   10   12\n\n, , 3\n\n     [,1] [,2] [,3]\n[1,]   13   15   17\n[2,]   14   16   18\n\n, , 4\n\n     [,1] [,2] [,3]\n[1,]   19   21   23\n[2,]   20   22   24"
  },
  {
    "objectID": "data_science/ds/objects/index.html#access-an-element-of-the-array-using-indexing",
    "href": "data_science/ds/objects/index.html#access-an-element-of-the-array-using-indexing",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Access an element of the array using indexing",
    "text": "Access an element of the array using indexing\nReturns the element in the second row, third column, and fourth layer of my_array, which is 23\n\narr_example[2, 3, 4]\n\n[1] 24"
  },
  {
    "objectID": "data_science/ds/objects/index.html#modify-an-element-of-the-array",
    "href": "data_science/ds/objects/index.html#modify-an-element-of-the-array",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Modify an element of the array",
    "text": "Modify an element of the array\nChanges the element in the second row, second column, and first layer of arr_example to 10\n\narr_example[2, 2, 1] &lt;- 10 \n\narr_example\n\n, , 1\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2   10    6\n\n, , 2\n\n     [,1] [,2] [,3]\n[1,]    7    9   11\n[2,]    8   10   12\n\n, , 3\n\n     [,1] [,2] [,3]\n[1,]   13   15   17\n[2,]   14   16   18\n\n, , 4\n\n     [,1] [,2] [,3]\n[1,]   19   21   23\n[2,]   20   22   24"
  },
  {
    "objectID": "data_science/ds/objects/index.html#create-a-data-frame-multiple-ways",
    "href": "data_science/ds/objects/index.html#create-a-data-frame-multiple-ways",
    "title": "Understanding R Objects: Naming, Data Structures and Classes in R",
    "section": "Create a Data Frame: multiple ways",
    "text": "Create a Data Frame: multiple ways\n1.- Using data.frame() function: This is the most common way to create a data frame in R. You can put as many vectors (variables) as you want.\n\ndf &lt;- data.frame(x = c(1, 2, 3), \n                 y = c(\"a\", \"b\", \"c\"), \n                 z = c(TRUE, FALSE, TRUE))\n\n2.- Using read_csv2() function: You can also create a data frame by importing data from an external file using the read.table() or read.csv() function.\n\ndf &lt;- read.table(\"data.txt\", header = TRUE)\n\n3.- Using read_excel() function from the readxl package\n\nlibrary(readxl)\ndf &lt;- read_excel(\"data.xlsx\")\n\n4.- Using tibble() function from the tibble package\n\nlibrary(tibble)\ndf &lt;- tibble(x = c(1, 2, 3), y = c(\"a\", \"b\", \"c\"), z = c(TRUE, FALSE, TRUE))\n\nYou can check our other tutorials to handle data frames and start practicing. We also recommend these books from the website for you to go into more detail.\n\n\n\n\n  \n\n    \n      \n    \n    \n    \n  \n\n  \n\n    \n      \n    \n    \n    \n  \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data_science/i2ds.html",
    "href": "data_science/i2ds.html",
    "title": "I2DS Tools for Data Science",
    "section": "",
    "text": "A workshop on tools for data science with R. Run by students of the course Introduction to Data Science (IDS) at the Hertie School, Berlin, Germany. All content produced and prepared by students of the Master of Data Science for Public Policy, the Master of Public Policy, and the Master of International Affairs.\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nI2DS Tools for Data Science Workshop 2021\n\n\nA workshop on tools for data science with R. Run by students of the course Introduction to Data Science (IDS) at the Hertie School, Berlin, Germany.\n\n\n\nI2DS\n\n\nR\n\n\nHertie School\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI2DS Tools for Data Science Workshop 2022\n\n\nA workshop on tools for data science with R. Run by students of the course Introduction to Data Science (IDS) at the Hertie School, Berlin, Germany.\n\n\n\nI2DS\n\n\nR\n\n\nHertie School\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "references/reference.html",
    "href": "references/reference.html",
    "title": "{{< fa solid scale-balanced >}} Ethics <span style='font-size: 18px;'>&#x2715;</span> Data Science {{< fa solid code-branch >}}",
    "section": "",
    "text": "Examples of using Observable with reactable in Quarto, based on the Observable JS Penguins example from the Quarto documentation.\nSource code: observable-reactable.qmd"
  },
  {
    "objectID": "references/reference.html#using-observable-inputs-to-filter-reactable",
    "href": "references/reference.html#using-observable-inputs-to-filter-reactable",
    "title": "{{< fa solid scale-balanced >}} Ethics <span style='font-size: 18px;'>&#x2715;</span> Data Science {{< fa solid code-branch >}}",
    "section": "Using Observable Inputs to filter reactable",
    "text": "Using Observable Inputs to filter reactable\n\nviewof billLengthMin = Inputs.range(\n  [32, 50], \n  { value: 35, step: 1, label: \"Bill length (min):\" }\n)\n\nviewof islands = Inputs.checkbox(\n  [\"Torgersen\", \"Biscoe\", \"Dream\"], \n  { value: [\"Torgersen\", \"Biscoe\"], label: \"Islands:\" }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReactable.setFilter('tbl', 'bill_length', billLengthMin)\n\n\n\n\n\n\n\nReactable.setFilter('tbl', 'island', islands)"
  },
  {
    "objectID": "references/reference.html#using-reactable-to-filter-observable-charts",
    "href": "references/reference.html#using-reactable-to-filter-observable-charts",
    "title": "{{< fa solid scale-balanced >}} Ethics <span style='font-size: 18px;'>&#x2715;</span> Data Science {{< fa solid code-branch >}}",
    "section": "Using reactable to filter Observable charts",
    "text": "Using reactable to filter Observable charts\n\n// Create an Observable value that automatically tracks the table's filtered data\nfilteredData = Generators.observe(change =&gt; {\n  return Reactable.onStateChange('tbl-input', state =&gt; {\n    change(state.sortedData)\n  })\n})\n\n\n\n\n\n\n\n\n\n\n\n\nPenguin body mass by sex and species\n\nPlot.rectY(filteredData, \n  Plot.binX(\n    { y: \"count\" }, \n    { x: \"body_mass\", fill: \"species\", thresholds: 20 }\n  ))\n  .plot({\n    facet: {\n      data: filteredData,\n      x: \"sex\",\n      y: \"species\",\n      marginRight: 80\n    },\n    marks: [\n      Plot.frame(),\n    ]\n  }\n)"
  },
  {
    "objectID": "data_science/ds/example/index.html",
    "href": "data_science/ds/example/index.html",
    "title": "Your Document Title",
    "section": "",
    "text": "Your important content or announcement goes here."
  },
  {
    "objectID": "data_science/ds/example/index.html#important-section-title",
    "href": "data_science/ds/example/index.html#important-section-title",
    "title": "Your Document Title",
    "section": "",
    "text": "Your important content or announcement goes here."
  },
  {
    "objectID": "data_science/ds/example/index.html#subsection-title",
    "href": "data_science/ds/example/index.html#subsection-title",
    "title": "Your Document Title",
    "section": "Subsection Title",
    "text": "Subsection Title\nDetails about the subsection. This can include code snippets, explanations, or any relevant information.\n\n# R code goes here\n\n# Example\n\nx &lt;- 1:10\n\ny &lt;- x^2\n\nplot(x, y)"
  },
  {
    "objectID": "data_science/ds/social_media_scraping/index.html",
    "href": "data_science/ds/social_media_scraping/index.html",
    "title": "Introduction to Social Media Scraping",
    "section": "",
    "text": "NEWS\n\n\n\nWith the next Twitter regulations, The free package comes with rate-limited access to v2 tweet posting and media upload endpoints, with a posting limit of 1,500 tweets per month at the app level. If you want to access to posting tweets are up to 3,000 per month, and for reading, it’s up to 10,000 tweets per month, you will need to pay 100 USD per month. However, you can sill acces to databases and use this tutorial to analyze text in general."
  },
  {
    "objectID": "data_science/ds/social_media_scraping/index.html#loading-in-packages-and-authorizing-rtweet",
    "href": "data_science/ds/social_media_scraping/index.html#loading-in-packages-and-authorizing-rtweet",
    "title": "Introduction to Social Media Scraping",
    "section": "Loading in packages and authorizing rtweet",
    "text": "Loading in packages and authorizing rtweet\nSo the first thing we want to do is load in the packages we’ll be using to scrape and manipulate our data. The most important of those is rtweet, which is the one we’ll be using to interact with the Twitter API.\nIn order to scrape tweets, you’ll need a Twitter developer account and have to make a Twitter app. This is actually a pretty simple process (and won’t require any coding). Here’s a step-by-step guide\n\npacman::p_load(rtweet, tidyverse, ggplot2, utils, tm, SnowballC, caTools, \n               rpart, topicmodels, tidytext, wordcloud, lexicon, reshape2,\n               sentimentr)\n\nRunning the code above (without the #’s) will prompt a dialogue box to pop up on your screen asking you for a bearer token. You can find that on the Twitter developer page. I made the last two lines into comments so that this can be knit into HTML smoothly."
  },
  {
    "objectID": "data_science/ds/social_media_scraping/index.html#corpus",
    "href": "data_science/ds/social_media_scraping/index.html#corpus",
    "title": "Introduction to Social Media Scraping",
    "section": "Corpus",
    "text": "Corpus\nIn natural language processing (NLP), a corpus is a collection of written or spoken language that is used as a basis for analysis. A corpus can be made up of many different types of texts, including books, articles, speeches, social media posts, and more. Here, we will make a corpus of documents using just the full_text part of green tweets\n\ncorpus1 &lt;- Corpus(VectorSource(green$full_text))\n\nNow we need to clean our text a bit. Change to lower case and remove punctuation!\n\ncorpus1 &lt;- tm_map(corpus1, tolower)\ncorpus1 &lt;- tm_map(corpus1, removePunctuation)\n#We need to remove stop words to get meaningful results from this exercise. \n#We'll remove words like \"me\", \"is\", \"was\"\nstopwords(\"english\")[1:50]\n\n [1] \"i\"          \"me\"         \"my\"         \"myself\"     \"we\"        \n [6] \"our\"        \"ours\"       \"ourselves\"  \"you\"        \"your\"      \n[11] \"yours\"      \"yourself\"   \"yourselves\" \"he\"         \"him\"       \n[16] \"his\"        \"himself\"    \"she\"        \"her\"        \"hers\"      \n[21] \"herself\"    \"it\"         \"its\"        \"itself\"     \"they\"      \n[26] \"them\"       \"their\"      \"theirs\"     \"themselves\" \"what\"      \n[31] \"which\"      \"who\"        \"whom\"       \"this\"       \"that\"      \n[36] \"these\"      \"those\"      \"am\"         \"is\"         \"are\"       \n[41] \"was\"        \"were\"       \"be\"         \"been\"       \"being\"     \n[46] \"have\"       \"has\"        \"had\"        \"having\"     \"do\"        \n\ncorpus1 &lt;- tm_map(corpus1, removeWords, (stopwords(\"english\")))\n#We need to clean the words in the corpus further by \"stemming\" words\n#A word like \"understand\" and \"understands\" will both become \"understand\"\ncorpus1 &lt;- tm_map(corpus1, stemDocument)"
  },
  {
    "objectID": "data_science/ds/social_media_scraping/index.html#document-term-matrix",
    "href": "data_science/ds/social_media_scraping/index.html#document-term-matrix",
    "title": "Introduction to Social Media Scraping",
    "section": "Document Term Matrix",
    "text": "Document Term Matrix\nSo, a DTM is a way of representing a collection of text documents quantitativelythat allows us to do some cool stuff with them. It’s basically a matrix where the rows correspond to the documents in the collection, and the columns correspond to the unique words or terms that appear in the documents. Each cell in the matrix represents the frequency of a particular term in a particular document.\n\n#creates a document term matrix, which is necessary for building a topic model\nDTM1 &lt;- DocumentTermMatrix(corpus1)\n#Here we can see the most frequently used terms\nfrequent_ge_20 &lt;- findFreqTerms(DTM1, lowfreq = 100)\nfrequent_ge_20\n\n [1] \"amp\"       \"green\"     \"like\"      \"store\"     \"day\"       \"…\"        \n [7] \"’s\"        \"light\"     \"one\"       \"year\"      \"figur\"     \"red\"      \n[13] \"buddha\"    \"fasc1nat\"  \"four\"      \"f…\"        \"philippin\" \"pray\"     \n[19] \"purchas\"   \"spent\"     \"woman\""
  },
  {
    "objectID": "data_science/ds/social_media_scraping/index.html#lets-create-the-topic-model-well-start-with-5-topics",
    "href": "data_science/ds/social_media_scraping/index.html#lets-create-the-topic-model-well-start-with-5-topics",
    "title": "Introduction to Social Media Scraping",
    "section": "Let’s create the topic model! We’ll start with 5 topics",
    "text": "Let’s create the topic model! We’ll start with 5 topics\nThe code snippet performs topic modeling on a corpus of text data represented as a Document-Term Matrix (DTM) using the Latent Dirichlet Allocation (LDA) algorithm. The LDA() function from the topic models package is used to create a model with 7 topics and a specified random seed for reproducibility. The resulting model is stored in the green_lda1 object.\n\n#Perform LDA topic modeling on a Document-Term Matrix (DTM) with 7 topics\ngreen_lda1 &lt;- LDA(DTM1, k = 7, control = list(seed = 1234))\n\n#Print the model summary\ngreen_lda1\n\nA LDA_VEM topic model with 7 topics.\n\n#Convert the model's beta matrix to a tidy format\ngreen_topics1 &lt;- tidy(green_lda1, matrix = \"beta\")\n\ngreen_top_terms1 &lt;- green_topics1 %&gt;%\n  group_by(topic) %&gt;% #Group the terms by topic\n  slice_max(beta, n = 10) %&gt;% #Top 10 terms with the highest probabilities\n  ungroup() %&gt;% #Remove the grouping attribute from the data frame\n  arrange(topic, -beta) #Sort the data frame by topic index and term probability"
  },
  {
    "objectID": "data_science/ds/social_media_scraping/index.html#word-cloud-of-biden-tweets",
    "href": "data_science/ds/social_media_scraping/index.html#word-cloud-of-biden-tweets",
    "title": "Introduction to Social Media Scraping",
    "section": "Word Cloud of Biden Tweets",
    "text": "Word Cloud of Biden Tweets\n\nCode# Create custom color palette\nmy_palette &lt;- brewer.pal(8, \"Dark2\")\n\n# Create word cloud with larger font size and custom layout\nwordcloud(words_data2$word, \n          words_data2$n, \n          max.words = 200, \n          colors = my_palette, \n          scale = c(5, 0.3),\n          random.order = FALSE,\n          rot.per = 0.25,\n          random.color = TRUE,\n          main = \"Word Cloud of Biden Tweets\")"
  },
  {
    "objectID": "data_science/ds/social_media_scraping/index.html#comparison-cloud-of-biden-tweets-by-sentiment",
    "href": "data_science/ds/social_media_scraping/index.html#comparison-cloud-of-biden-tweets-by-sentiment",
    "title": "Introduction to Social Media Scraping",
    "section": "Comparison Cloud of Biden Tweets by Sentiment",
    "text": "Comparison Cloud of Biden Tweets by Sentiment\nNow let’s make a word cloud from those tweets but highlight which words are positive and which are negative\n\n#Select and tokenize words\nwords_data &lt;- biden_tweets %&gt;% \n  select(text) %&gt;%\n  unnest_tokens(word, text) \n\n#Get sentiment scores for each word using the bing lexicon\nsentiment_scores &lt;- words_data2 %&gt;%\n  inner_join(get_sentiments(\"bing\"))\n\n#Count the number of words in each sentiment category\nsentiment_counts &lt;- sentiment_scores %&gt;%\n  count(sentiment, sort = TRUE)\n\n#Create a list of profanity words to remove from the dataset\nprofanity_list &lt;- unique(tolower(lexicon::profanity_alvarez))\n\n#Filter out stop words and profanity words from the dataset\nfiltered_words_data &lt;- words_data %&gt;%\n  filter(!word %in% c('https', 't.co', 'he\\'s', 'i\\'m', 'it\\'s', profanity_list))\n\n#Get sentiment scores for each filtered word using the bing lexicon\nfiltered_sentiment_scores &lt;- filtered_words_data %&gt;%\n  inner_join(get_sentiments(\"bing\"))"
  },
  {
    "objectID": "data_science/ds/social_media_scraping/index.html#cloud",
    "href": "data_science/ds/social_media_scraping/index.html#cloud",
    "title": "Introduction to Social Media Scraping",
    "section": "Cloud",
    "text": "Cloud\n\nCode#Count the number of filtered words with each sentiment score\nword_sentiment_counts &lt;- filtered_sentiment_scores %&gt;%\n  count(word, sentiment, sort = TRUE) %&gt;%\n  acast(word ~ sentiment, value.var = \"n\", fill = 0)\n\n#Create a comparison cloud using the word and sentiment counts\ncomparison.cloud(word_sentiment_counts, \n                  colors = c(\"red\", \"blue\"),\n                  max.words = Inf)"
  },
  {
    "objectID": "data_science/I2DS/i2ds2022/index.html",
    "href": "data_science/I2DS/i2ds2022/index.html",
    "title": "I2DS Tools for Data Science Workshop 2022",
    "section": "",
    "text": "The Introduction to Data Science (IDS) course at the Hertie School in Berlin, Germany, is designed to provide students with a comprehensive understanding of data science principles, techniques, and tools. As part of the course curriculum, students actively engage in organizing workshops and activities to enhance their practical skills and share their knowledge with others.\n \nThese student-led activities, such as the workshop on Tools for Data Science with R, serve as valuable opportunities for participants to gain hands-on experience and learn directly from their peers. The I2DS course encourages students to take the lead in organizing and delivering these workshops, fostering a collaborative learning environment.\n\n\n\n Go to I2DS Tools 2022"
  },
  {
    "objectID": "ethics/ethics.html",
    "href": "ethics/ethics.html",
    "title": "{{< fa solid scale-balanced >}} Ethics <span style='font-size: 18px;'>&#x2715;</span> Data Science {{< fa solid code-branch >}}",
    "section": "",
    "text": "Welcome to the “Ethics” section of “Data Science X Ethics,” where we delve deep into the heart of responsible innovation and the ethical use of data and technology. In the rapidly evolving landscape of data science, ethical considerations are not just an add-on; they are foundational to creating technology that serves humanity with respect and integrity.\nThis section is dedicated to exploring the complex ethical questions that arise in the field of data science. It’s here that we confront the challenges of balancing innovation with privacy, algorithmic fairness with efficiency, and the pursuit of knowledge with respect for individual rights. Our goal is to provide you with insights, resources, and thought-provoking content that illuminate the ethical dimensions of working with data."
  },
  {
    "objectID": "ethics/ethics.html#ethics",
    "href": "ethics/ethics.html#ethics",
    "title": "{{< fa solid scale-balanced >}} Ethics <span style='font-size: 18px;'>&#x2715;</span> Data Science {{< fa solid code-branch >}}",
    "section": "Ethics",
    "text": "Ethics\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nFrameworks\n\n\nThree frameworks for Data Science Ethics — and why you should think about how you approach the ethics of data science\n\n\n\nFoundational Concepts\n\n\nBias\n\n\nMethodology\n\n\n\n\n\n\nFeb 22, 2024\n\n\nJohannes Himmelreich\n\n\n13 min\n\n\n\n\n\n\n\n\n\n\n\n\nYour Document Title\n\n\nSubtitle or Brief Description\n\n\n\nCategory1\n\n\nCategory2\n\n\nCategory3\n\n\n\n\n\n\nInvalid Date\n\n\nYour Name\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy\n\n\nWhat is it good for?\n\n\n\nFoundational Concept\n\n\nPrivacy\n\n\nData Collection\n\n\n\n\n\n\nFeb 26, 2024\n\n\nJohannes Himmelreich\n\n\n3 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "ethics/ethics/privacy/index.html",
    "href": "ethics/ethics/privacy/index.html",
    "title": "Privacy",
    "section": "",
    "text": "Main idea\n\n\n\nYou have no idea what privacy is. But you still know what you need to do to protect it."
  },
  {
    "objectID": "ethics/ethics/privacy/index.html#information-problems",
    "href": "ethics/ethics/privacy/index.html#information-problems",
    "title": "Privacy",
    "section": "Information problems",
    "text": "Information problems\nSometimes, you know how limited your privacy is. You remember there were privacy settings in that app that you just couldn’t bother to check. And you know that online advertisers track you. And you know that you signed something at your doctor’s office about sharing your patient data.\nBut often, privacy today is violated unwittingly. For one, it’s basically impossible to be aware of all the ways in which your data is collected, analyzed, and shared. Similarly, nobody can possibly read all the terms and conditions and privacy policies that they are agreeing to.\nIn short, there is an information problem: Individuals don’t know — and, to some extent, cannot know — all they need to know to safeguard their privacy. And, arguably, we shouldn’t spend much of our time and mental energy on protecting our privacy."
  },
  {
    "objectID": "ethics/ethics/privacy/index.html#choice-problems",
    "href": "ethics/ethics/privacy/index.html#choice-problems",
    "title": "Privacy",
    "section": "Choice problems",
    "text": "Choice problems\nThe second part of the state of individual privacy today has to do with choices. We cannot throw away all of our devices, like Ron Swanson does. The options that we have to protect our privacy, even when we are aware of them, is practically limited. Metadata collection that is required by law is hard to opt out of. Even tech-savvy individuals are outgunned by the professional data, surveillance, and security industry.\nAnd then, we also have a cognitive system that is easy to exploit. As such, websites and apps use various forms of deception to get you to do things.1 You end up subscribing to a service without knowing, agreeing to terms without having read them, or clicking “Continue” because the other button, “No,” was made hard to see.\n\n\n\n\n\nDeceptive design\n\n\nIn sum, privacy is inadvertently infringed on a regular basis in two respects\n\nIndividuals hold false beliefs about the state of their privacy and the options in front of them\nIndividuals have limited options to safeguard their privacy\n\nThese two points are practically necessary. That is, given how things are, these are two starting points that we cannot change. You can only read so many terms and conditions, if you can read any, and there is only so much you can do."
  },
  {
    "objectID": "ethics/ethics/privacy/index.html#footnotes",
    "href": "ethics/ethics/privacy/index.html#footnotes",
    "title": "Privacy",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee https://www.deceptive.design↩︎"
  },
  {
    "objectID": "for_instructors/guide/ds/index.html",
    "href": "for_instructors/guide/ds/index.html",
    "title": "Data Science",
    "section": "",
    "text": "Your important content or announcement goes here."
  },
  {
    "objectID": "for_instructors/guide/ds/index.html#important-section-title",
    "href": "for_instructors/guide/ds/index.html#important-section-title",
    "title": "Data Science",
    "section": "",
    "text": "Your important content or announcement goes here."
  },
  {
    "objectID": "for_instructors/guide/ds/index.html#subsection-title",
    "href": "for_instructors/guide/ds/index.html#subsection-title",
    "title": "Data Science",
    "section": "Subsection Title",
    "text": "Subsection Title\nDetails about the subsection. This can include code snippets, explanations, or any relevant information.\n\n# R code goes here\n\n# Example\n\nx &lt;- 1:10\n\ny &lt;- x^2\n\nplot(x, y)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nCite this page: Lehmann, L. (2023, April 18). Introduction to Social Media Scraping. Hertie Coding Club. URL"
  },
  {
    "objectID": "data_science/ds/objects/index.html#background-and-prerequisites",
    "href": "data_science/ds/objects/index.html#background-and-prerequisites",
    "title": "Bias in AI: detection and mitigation",
    "section": "Background and Prerequisites",
    "text": "Background and Prerequisites\nThis tutorial is designed for users with a basic understanding of Python and Deep Learning. Users should have a foundational understanding of key concepts in machine learning and neural networks. Familiarity with Python is essential. Additionally, a grasp of linear algebra and calculus will be beneficial for understanding the mathematical underpinnings of deep learning algorithms.\n\nA solid understanding of model training is crucial, as well as knowledge of common machine learning libraries such as Keras and scikit-learn. Users should also be aware of the ethical and policy considerations surrounding machine learning applications, particularly in relation to bias and fairness.\nLastly, a conceptual understanding of how neural networks operate, including layers, activation functions, and backpropagation, will enhance the learning experience of the user. Overall, a basic background in machine learning fundamentals will help users to engage more effectively with our tutorial.\n\n\n!pip install pandas numpy matplotlib\n!pip install Aequitas\n!pip install keras_tuner\n!pip install aif360\n!pip install BlackBoxAuditing\n!pip install tensorflow\n\n\n# Data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"white\", palette=\"muted\", color_codes=True, context=\"talk\")\nfrom IPython import display\n\n# Data manipulation\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\n# Aequitas library used to audit models for discrimination and bias\nfrom aequitas.group import Group\nfrom aequitas.bias import Bias\nfrom aequitas.fairness import Fairness\nfrom aequitas.plotting import Plot\nimport matplotlib.pyplot as plt\nimport warnings; warnings.simplefilter('ignore')\n\n# Machine and deep learning libraries\nimport tensorflow as tf\nfrom keras.layers import Input, Dense, Dropout\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nimport keras_tuner as kt\nfrom keras import Input, Model\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import Adam\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n\n# AI fairness library\nfrom aif360.algorithms.preprocessing import DisparateImpactRemover\nfrom aif360.datasets import StandardDataset as Dataset\nfrom aif360.metrics import BinaryLabelDatasetMetric\nfrom aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\nfrom aif360.algorithms.preprocessing.reweighing import Reweighing\nfrom collections import OrderedDict\nfrom aif360.metrics import ClassificationMetric"
  },
  {
    "objectID": "data_science/ds/objects/index.html#data-download",
    "href": "data_science/ds/objects/index.html#data-download",
    "title": "Bias in AI: detection and mitigation",
    "section": "1.1 Data Download",
    "text": "1.1 Data Download\n\n# Load the data\n\ndf_compas_aeq = pd.read_csv(\"https://raw.githubusercontent.com/dssg/aequitas/master/examples/data/compas_for_aequitas.csv\")\ndf_compas_aeq.head()\n\n\n\n\n\n\n\n\n\nentity_id\nscore\nlabel_value\nrace\nsex\nage_cat\n\n\n\n\n0\n1\n0.0\n0\nOther\nMale\nGreater than 45\n\n\n1\n3\n0.0\n1\nAfrican-American\nMale\n25 - 45\n\n\n2\n4\n0.0\n1\nAfrican-American\nMale\nLess than 25\n\n\n3\n5\n1.0\n0\nAfrican-American\nMale\nLess than 25\n\n\n4\n6\n0.0\n0\nOther\nMale\n25 - 45"
  },
  {
    "objectID": "data_science/ds/objects/index.html#exploratory-data-visualization",
    "href": "data_science/ds/objects/index.html#exploratory-data-visualization",
    "title": "Bias in AI: detection and mitigation",
    "section": "Exploratory Data Visualization",
    "text": "Exploratory Data Visualization\n\nDistribution of Defendants by Demographics (Race, Age, Sex) and Risk Scores\n\nAs a first step, we are exploring the distribution of our defendant data with regards to demographic characteristics and the calculated risk scores. As we can see, African-Americans, Caucasians, males, and defendants aged 25-45 are the subgroups that are highly represented in the data. Additionally, we can already see from the plots that African-Americans and defendants aged under 25 are the only subgroups where the majority has been assigned a high risk score.\n\n\nCode\nReds_palette = sns.diverging_palette(204, 0, n=2)\n\n# Create a figure with 3 subplots (3 rows, 1 column)\nfig, axes = plt.subplots(3, 1, figsize=(8, 16))\n\n# race\nby_race = sns.countplot(\n    ax=axes[0],\n    x=\"race\",\n    hue=\"score\",\n    data=df_compas_aeq,\n    palette=Reds_palette\n)\n\naxes[0].set_title(\"Distribution of Defendants by Race and Risk Score (Decile)\")\naxes[0].set_xlabel(\"Race\")\naxes[0].set_ylabel(\"Count\")\naxes[0].legend(loc='upper right', title='Risk Score Decile')\naxes[0].grid(True, linestyle='--', linewidth=0.5)\naxes[0].tick_params(axis='x', rotation=45)\n\n# sex\nby_sex = sns.countplot(\n    ax=axes[1],\n    x=\"sex\",\n    hue=\"score\",\n    data=df_compas_aeq,\n    palette=Reds_palette\n)\n\n# Add title and labels\naxes[1].set_title(\"Distribution of Defendants by Sex and Risk Score (Decile)\")\naxes[1].set_xlabel(\"Sex\")\naxes[1].set_ylabel(\"Count\")\n\n# sex\naxes[1].legend(loc='upper right', title='Risk Score')\naxes[1].grid(True, linestyle='--', linewidth=0.5)\naxes[1].tick_params(axis='x', rotation=45)\n\n# Create countplot for age\nby_age = sns.countplot(\n    ax=axes[2],\n    x=\"age_cat\",\n    hue=\"score\",\n    data=df_compas_aeq,\n    palette=Reds_palette\n)\n\naxes[2].set_title(\"Distribution of Defendants by Age and Risk Score (Decile)\")\naxes[2].set_xlabel(\"Age Category\")\naxes[2].set_ylabel(\"Count\")\n\naxes[2].legend(loc='upper right', title='Risk Score')\n\naxes[2].grid(True, linestyle='--', linewidth=0.5)\n\naxes[2].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\n\nplt.show()"
  },
  {
    "objectID": "data_science/ds/objects/index.html#introducing-the-aequitas-library",
    "href": "data_science/ds/objects/index.html#introducing-the-aequitas-library",
    "title": "Bias in AI: detection and mitigation",
    "section": "Introducing the Aequitas-Library",
    "text": "Introducing the Aequitas-Library\nAfter eyeballing our data set and noticing that there might be some fairness issues, we can now use the Aequitas library to calculate common metrics that indicate biases in subgroups. More specifically, we are using the library’s Group() class that evaluates biases across all demographic subgroups in the dataset. Note here that the library requires the input data to have columns named “score” and “label_value”. These columns are by default used to calculate the bias metrics.\nIn order to use Aequitas for your purposes, you should rename the columns that you want to check for potential biases to “score” and “label_value”. Additionally, at least one column needs to include grouping information (in our example, several demographic variables). ID variables as entity_id are by default not treated as grouping variables.\nThe following code chunk calculates these metrices for all demographic subgroups using the get_crosstabs function, based on the risk score and the label_value, which indicates the recidivism.\n\n\nCode\ng = Group()\nxtab, _ = g.get_crosstabs(df_compas_aeq)\nxtab\n\n\n\n\n\n\n\n\n\n\nmodel_id\nscore_threshold\nk\nattribute_name\nattribute_value\naccuracy\ntpr\ntnr\nfor\nfdr\n...\npprev\nfp\nfn\ntn\ntp\ngroup_label_pos\ngroup_label_neg\ngroup_size\ntotal_entities\nprev\n\n\n\n\n0\n0\nbinary 0/1\n3317\nrace\nAfrican-American\n0.638258\n0.720147\n0.551532\n0.349540\n0.370285\n...\n0.588203\n805\n532\n990\n1369\n1901\n1795\n3696\n7214\n0.514340\n\n\n1\n0\nbinary 0/1\n3317\nrace\nAsian\n0.843750\n0.666667\n0.913043\n0.125000\n0.250000\n...\n0.250000\n2\n3\n21\n6\n9\n23\n32\n7214\n0.281250\n\n\n2\n0\nbinary 0/1\n3317\nrace\nCaucasian\n0.669927\n0.522774\n0.765457\n0.288125\n0.408665\n...\n0.348003\n349\n461\n1139\n505\n966\n1488\n2454\n7214\n0.393643\n\n\n3\n0\nbinary 0/1\n3317\nrace\nHispanic\n0.660911\n0.443966\n0.785185\n0.288591\n0.457895\n...\n0.298273\n87\n129\n318\n103\n232\n405\n637\n7214\n0.364207\n\n\n4\n0\nbinary 0/1\n3317\nrace\nNative American\n0.777778\n0.900000\n0.625000\n0.166667\n0.250000\n...\n0.666667\n3\n1\n5\n9\n10\n8\n18\n7214\n0.555556\n\n\n5\n0\nbinary 0/1\n3317\nrace\nOther\n0.665782\n0.323308\n0.852459\n0.302013\n0.455696\n...\n0.209549\n36\n90\n208\n43\n133\n244\n377\n7214\n0.352785\n\n\n6\n0\nbinary 0/1\n3317\nsex\nFemale\n0.653763\n0.608434\n0.678930\n0.242537\n0.487310\n...\n0.423656\n288\n195\n609\n303\n498\n897\n1395\n7214\n0.356989\n\n\n7\n0\nbinary 0/1\n3317\nsex\nMale\n0.653721\n0.629132\n0.675799\n0.330100\n0.364637\n...\n0.468465\n994\n1021\n2072\n1732\n2753\n3066\n5819\n7214\n0.473105\n\n\n8\n0\nbinary 0/1\n3317\nage_cat\n25 - 45\n0.647846\n0.626257\n0.666216\n0.323112\n0.385135\n...\n0.468240\n741\n706\n1479\n1183\n1889\n2220\n4109\n7214\n0.459723\n\n\n9\n0\nbinary 0/1\n3317\nage_cat\nGreater than 45\n0.704315\n0.427711\n0.832096\n0.241117\n0.459391\n...\n0.250000\n181\n285\n897\n213\n498\n1078\n1576\n7214\n0.315990\n\n\n10\n0\nbinary 0/1\n3317\nage_cat\nLess than 25\n0.617397\n0.739583\n0.458647\n0.424528\n0.360360\n...\n0.653368\n360\n225\n305\n639\n864\n665\n1529\n7214\n0.565075\n\n\n\n\n11 rows × 27 columns\n\n\n\n\n\nAdditionally, we can use list_absolute_metrics() for an improved overview grouped by the demographics and with rounded values for the metrics.\n\n\n\nCode\nabsolute_metrics = g.list_absolute_metrics(xtab)\nxtab[['attribute_name', 'attribute_value'] + absolute_metrics].round(2)\n\n\n\n\n\n\n\n\n\n\nattribute_name\nattribute_value\naccuracy\ntpr\ntnr\nfor\nfdr\nfpr\nfnr\nnpv\nprecision\nppr\npprev\nprev\n\n\n\n\n0\nrace\nAfrican-American\n0.64\n0.72\n0.55\n0.35\n0.37\n0.45\n0.28\n0.65\n0.63\n0.66\n0.59\n0.51\n\n\n1\nrace\nAsian\n0.84\n0.67\n0.91\n0.12\n0.25\n0.09\n0.33\n0.88\n0.75\n0.00\n0.25\n0.28\n\n\n2\nrace\nCaucasian\n0.67\n0.52\n0.77\n0.29\n0.41\n0.23\n0.48\n0.71\n0.59\n0.26\n0.35\n0.39\n\n\n3\nrace\nHispanic\n0.66\n0.44\n0.79\n0.29\n0.46\n0.21\n0.56\n0.71\n0.54\n0.06\n0.30\n0.36\n\n\n4\nrace\nNative American\n0.78\n0.90\n0.62\n0.17\n0.25\n0.38\n0.10\n0.83\n0.75\n0.00\n0.67\n0.56\n\n\n5\nrace\nOther\n0.67\n0.32\n0.85\n0.30\n0.46\n0.15\n0.68\n0.70\n0.54\n0.02\n0.21\n0.35\n\n\n6\nsex\nFemale\n0.65\n0.61\n0.68\n0.24\n0.49\n0.32\n0.39\n0.76\n0.51\n0.18\n0.42\n0.36\n\n\n7\nsex\nMale\n0.65\n0.63\n0.68\n0.33\n0.36\n0.32\n0.37\n0.67\n0.64\n0.82\n0.47\n0.47\n\n\n8\nage_cat\n25 - 45\n0.65\n0.63\n0.67\n0.32\n0.39\n0.33\n0.37\n0.68\n0.61\n0.58\n0.47\n0.46\n\n\n9\nage_cat\nGreater than 45\n0.70\n0.43\n0.83\n0.24\n0.46\n0.17\n0.57\n0.76\n0.54\n0.12\n0.25\n0.32\n\n\n10\nage_cat\nLess than 25\n0.62\n0.74\n0.46\n0.42\n0.36\n0.54\n0.26\n0.58\n0.64\n0.30\n0.65\n0.57\n\n\n\n\n\n\n\n\n\nNext, we can use the information on the metrics that have been calculated by the previous chunk to plot the present biases. For that purpose, the Plot() class is used and stored in a variable. Afterwards, this variable can be used to plot the metrics of interest. The next code chunk exemplarily plots the false positive rate for all subgroups. In the context of our data, false positive cases are present when defendants are classified high risk although they did not recidivate. As we can see from the plot below, these cases are especially present amoung younger as well as among African- and Native Americans.\nAdditionally, the colors by default indicate how many respondents are included in the respective subgroup. The exact number can also be retrieved from the bar labels. Referring to the group sizes, you can see that the two races with they highest FPR are of significantly different size: While there are only 18 Native Americans included in our data, a total of nearly 3,700 African-American defendants are present.\n\n\nCode\naqp = Plot()\nfpr = aqp.plot_group_metric(xtab, 'fpr')\n\n\n\n\n\n\n\n\n\n\nFor better readability, and when only interested in the rates rather then the absolute numbers, we can switch the axes and rotate the x-axis labels:\n\n\n\nCode\nxtab_df = xtab[['attribute_name', 'attribute_value'] + absolute_metrics].round(2).set_index(['attribute_name', 'attribute_value'])\nxtab_df = xtab_df.reset_index()\n\n# Create a figure for the plot\nplt.figure(figsize=(9, 6))\n\n# Create a bar plot for FPR\nax = sns.barplot(x='attribute_value', y='fpr', hue='attribute_name', data=xtab_df, palette='coolwarm', dodge=True)\nax.set_xticklabels(ax.get_xticklabels(), rotation=60, ha='right')\n\n\n# Add title and labels\nplt.title('False Positive Rate (FPR) by Attribute')\nplt.xlabel('Attribute Value')\nplt.ylabel('FPR')\n\n# Rotate x-axis labels for better readability\nplt.xticks(rotation=60)\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "data_science/ds/objects/index.html#distribution-of-defendants-by-demographics-and-recidivism",
    "href": "data_science/ds/objects/index.html#distribution-of-defendants-by-demographics-and-recidivism",
    "title": "Bias in AI: detection and mitigation",
    "section": "Distribution of Defendants by Demographics and Recidivism",
    "text": "Distribution of Defendants by Demographics and Recidivism\nNext, we are looking at the same demographic subgroups and whether the defendants actually committed crime again. We can already see, that there seems to be a mismatch between the assigned risk scores and the recidivism patterns.\n\n\nCode\ncoolwarm_two_colors = sns.color_palette(\"coolwarm\", n_colors=2)\ncoolwarm_palette = sns.color_palette(\"coolwarm\", as_cmap=True)\n\n\n# Create a figure with 3 subplots (3 rows, 1 column)\nfig, axes = plt.subplots(3, 1, figsize=(8, 16))\n\n# Create countplot for race\nlabel_by_race = sns.countplot(\n    ax=axes[0],\n    x=\"race\",\n    hue=\"label_value\",\n    data=df_compas_aeq,\n    palette=coolwarm_two_colors\n)\n\n# Add title and labels for race\naxes[0].set_title(\"Levels of recidivism by Race\")\naxes[0].set_xlabel(\"Race\")\naxes[0].set_ylabel(\"Count\")\naxes[0].grid(True, linestyle='--', linewidth=0.5)\naxes[0].legend(loc='upper right', title='Recidivism')\naxes[0].tick_params(axis='x', rotation=45)\n\n# Create countplot for sex\nlabel_by_sex = sns.countplot(\n    ax=axes[1],\n    x=\"sex\",\n    hue=\"label_value\",\n    data=df_compas_aeq,\n    palette=coolwarm_two_colors\n)\n\n# Add title and labels for sex\naxes[1].set_title(\"Levels of recidivism by Sex\")\naxes[1].set_xlabel(\"Sex\")\naxes[1].set_ylabel(\"Count\")\naxes[1].grid(True, linestyle='--', linewidth=0.5)\naxes[1].legend(loc='upper right', title='Recidivism')\naxes[1].tick_params(axis='x', rotation=45)\n\n# Create countplot for age category\nlabel_by_age = sns.countplot(\n    ax=axes[2],\n    x=\"age_cat\",\n    hue=\"label_value\",\n    data=df_compas_aeq,\n    palette=coolwarm_two_colors\n)\n\n# Add title and labels for age category\naxes[2].set_title(\"Levels of recidivism by Age Category\")\naxes[2].set_xlabel(\"Age Category\")\naxes[2].set_ylabel(\"Count\")\naxes[2].grid(True, linestyle='--', linewidth=0.5)\naxes[2].legend(loc='upper right', title='Recidivism')\n\n# Adjust layout\nplt.tight_layout()\n\n# Display the plot\nplt.show()"
  }
]