---
title: "The Pathology of Privacy"
subtitle: "What's the state of privacy today? Protecting privacy is a collective effort. It follows that consent is over-rated and ignorance is rational. [DRAFT]"
author:
  - name: Johannes Himmelreich
    id: jh
    orcid: 0000-0002-2163-0082
    email: jrhimmel@syr.edu
    affiliation: 
      - name: Maxwell School at Syracuse University
        city: Syracuse
        state: NY
        url: www.syracuse.edu
date: "2024-02-26"
categories: ["Foundational Concept", "Privacy", "Data Collection"]
toc: true
draft: false
code-link: true
code-copy: true
title-block-banner: true
comments: false
image: images/Social.png #path/to/image.png
include-in-header: meta.html
filters:
   - lightbox
lightbox: 
  match: auto
  effect: fade
  desc-position: left
  css-class: "lightwidth"
---

::: callout-note
## Main idea

Protecting privacy is a collective effort. Individuals can only do so much to protect personal information. This undermines the importance of consent and makes it rational to not know the many ways in which your privacy is violated.
:::

# Introduction

The Parks & Recreation TV series has this character of Ron Swanson who --- other than being very fond of breakfast foods --- is a freedom-loving individualist with a deep disdain for rules or any dependence on others. He also takes privacy *very* seriously.

{{< video https://www.youtube.com/embed/8xn1rO1oQmk >}}

Ron's reaction in this clip is what is surprising and unusual (did I mention he takes privacy *very* seriously). Whereas his *reaction* seems like an exaggeration, the *situation* to which Ron reacts should be familiar to all of us. Especially if you live in a jurisdiction with relatively weak privacy protections, such as the United States, you might wonder once in a while whether, like Ron Swanson, it might be better if you just threw all your devices in the trash. 

But what is it exactly that we'd protect by throwing you phone and you computer away --- what is privacy? And why is it valuable? This post won't answer all these questions (I'll do that in a separate post). Instead, with this post I want us to get clearer on why privacy is so under threat today. I also want to chip away at some conventional wisdom, namely, the idea that consent is the way to protect privacy. I argue that problems for privacy today are such that consent is not a viable solution. 

::: aside 
I'm talking about privacy from the perspective of *ethics* not law and I concentrate on *informational* privacy. By contrast, in the United States, privacy is a prominent legal concept and a foundation of liberalism. 
:::

In short, in this post I discuss why privacy is threatened today and how we should think about defending it. I hope this discussion helps to improve your conversations and discussions about privacy.

# The Pathology of Privacy

I'd bet you probably felt like Ron Swanson yourself some time. Go find out how much companies know about you and how little privacy you have. For example, here is a slide from a presentation by LexisNexis, a data company, advertising the range of source from which they aggregate data for identity verification.

::: column-page-inset-right
![Data used for identity verification by LexisNexis (in 2020)](images/lexis-nexis-network.png){fig-alt="Screenshot of a presentation slide. Logos of various companies — including Visa, Netflix, eBay, BestBuy, and Microsoft — are arranged around a mesh sphere."}
:::

In the United States it is relatively easy to get information on individuals' location, credit score, address, and phone number. To everyone except the cynic --- who is never impressed by bad news -- Ron's shock that "it learns information about me" should be familiar.

Whereas the Ron's shock might be familiar, his reaction is not. We wouldn't throw away our devices to protect privacy at all costs. Practically, you often don't can't protect your information. 

Relatively well-known is the **paradox of privacy**: Despite a desire for privacy, many people share private information freely. What we do isn't aligned with how we talk about or value privacy. Behavior is not aligned with stated commitments and preferences for privacy.

Another less discussed fact is the **pathology of privacy**: You don't really know how your information is shared and there isn't much you can do anyway. 

Whereas the paradox of privacy centers on individuals and their choices, the pathology of privacy focuses on the legal structure and typical psychological dispositions. I'd argue the pathology of privacy gets it right: Protecting information is a structural or collective problem.

Whereas the paradox of privacy insinuates that individuals are inconsistent or irrational, the pathology of privacy suggests the opposite: it's reasonable to *not* worry about privacy. Giving up privacy is a precondition for taking part in social life and technological progress. It is rational to give up privacy in exchange for enjoying progress and human connection while hoping that the structural conditions of privacy improve.

## What do you know?

Sometimes, however, you do know how limited your privacy is. You remember there were privacy settings in that app that you just couldn't bother to check. And you know that online advertisers track you. And you know that you signed something at your doctor's office about sharing your patient data.

But often, privacy today is violated unwittingly. For one, it's basically impossible to be aware of all the ways in which your data is collected, analyzed, and shared. Similarly, nobody can possibly read all the terms and conditions and privacy policies that they are agreeing to.

In short, there is an **information problem**: Individuals don't know — and, to some extent, cannot know — all they need to know to safeguard their privacy. And, arguably, we shouldn't spend much of our time and mental energy on protecting our privacy.

## What can you do?

The second part of the state of individual privacy today has to do with choices. We cannot throw away all of our devices, like Ron Swanson does. The options that we have to protect our privacy, even when we are aware of them, is practically limited. Metadata collection that is required by law is hard to opt out of. Even tech-savvy individuals are outgunned by the professional data, surveillance, and security industry.

And then, we also have a cognitive system that is easy to exploit. As such, websites and apps use various forms of deception to get you to do things.[^1] You end up subscribing to a service without knowing, agreeing to terms without having read them, or clicking "Continue" because the other button, "No," was made hard to see.

[^1]: See <https://www.deceptive.design>

::: column-margin
![Deceptive design](images/alexapattern-01.jpeg){width="337"}
:::

Finally, much information is not unique to individuals. This means that protecting that information is not up to you. How much you can do to protect your privacy has in-principle limits when so many others have --- and can share --- the same information that you consider personal to you. Because much information is shared across a large number of people, no individual can control how their information is shared. This is sometimes called the **externality of data**.

One clear example of this is genetic information. Because most genetic information is shared and not unique to one individual, you can't protect most of your genetic information. You can't stop you aunt or brother from using a genetic testing service. Still, you would consider your genetic information, even parts of it, to be your personal information.

Another example TBC

# What follows?

In sum, **privacy is inadvertently infringed on a regular basis** in two respects

1.  Individuals hold **false beliefs** about the state of their privacy and the options in front of them

2.  Individuals have limited options to safeguard their privacy

These two points are practically necessary. That is, given how things are, these are two starting points that we cannot change. You can only read so many terms and conditions, if you can read any, and there is only so much you can do.

## Privacy as a collective property

TBC

## Against Consent

All of this is bad news for consent.

# What should we do?

The upshot is that we need to rething privacy and how to protect it. I argued that privacy is not up to individuals and that, insofar as that's true, consent can't be a tool for privacy policy. When we think about when it is OK to share information about people, we need to take a different approach. What could that look like?

Data Protection Reasons


